<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models](https://arxiv.org/abs/2506.21627)
*Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉语言模型（VLM）的机器人操纵框架FrankenBot，通过模拟人脑结构实现多功能集成与高效操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能在复杂动态环境中高效完成多种任务的通用机器人操纵系统，需整合任务规划、策略生成等功能，但现有方法通常仅关注单一功能。

Method: 采用分治策略和人脑结构启发，设计FrankenBot框架，将关键功能映射到不同脑区并优化协调机制。

Result: 实验表明，FrankenBot在异常处理、长期记忆和操作效率等方面表现优异，且无需微调或再训练。

Conclusion: FrankenBot通过多功能集成与高效协调，显著提升了机器人操纵系统的性能与稳定性。

Abstract: Developing a general robot manipulation system capable of performing a wide
range of tasks in complex, dynamic, and unstructured real-world environments
has long been a challenging task. It is widely recognized that achieving
human-like efficiency and robustness manipulation requires the robotic brain to
integrate a comprehensive set of functions, such as task planning, policy
generation, anomaly monitoring and handling, and long-term memory, achieving
high-efficiency operation across all functions. Vision-Language Models (VLMs),
pretrained on massive multimodal data, have acquired rich world knowledge,
exhibiting exceptional scene understanding and multimodal reasoning
capabilities. However, existing methods typically focus on realizing only a
single function or a subset of functions within the robotic brain, without
integrating them into a unified cognitive architecture. Inspired by a
divide-and-conquer strategy and the architecture of the human brain, we propose
FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that
achieves both comprehensive functionality and high operational efficiency. Our
framework includes a suite of components, decoupling a part of key functions
from frequent VLM calls, striking an optimal balance between functional
completeness and system efficiency. Specifically, we map task planning, policy
generation, memory management, and low-level interfacing to the cortex,
cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and
design efficient coordination mechanisms for the modules. We conducted
comprehensive experiments in both simulation and real-world robotic
environments, demonstrating that our method offers significant advantages in
anomaly detection and handling, long-term memory, operational efficiency, and
stability -- all without requiring any fine-tuning or retraining.

</details>


### [2] [Ark: An Open-source Python-based Framework for Robot Learning](https://arxiv.org/abs/2506.21628)
*Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: ARK是一个开源的、以Python为中心的机器人框架，旨在简化机器人软件开发，降低学习门槛，并加速自主机器人的研究和商业部署。


<details>
  <summary>Details</summary>
Motivation: 当前机器人软件开发的复杂性（如低级的C/C++需求、分散的工具链和硬件集成）阻碍了商业自主性的进展，而ARK希望通过提供类似现代AI的Python生态系统来解决这一问题。

Method: ARK提供了一个Gym风格的环境接口，支持数据收集、预处理和策略训练，同时无缝切换模拟与物理机器人。其轻量级客户端-服务器架构和可选的C/C++绑定确保了实时性能。

Result: ARK展示了从操作到移动导航的快速原型设计、轻松硬件交换和端到端流程，其文档和案例研究证明了其高效性。

Conclusion: ARK通过统一的Python生态系统降低了机器人开发的入门门槛，加速了自主机器人的研究和商业应用。

Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics
Challenges to the first humanoid-robot kickboxing tournament-yet commercial
autonomy still lags behind progress in machine learning. A major bottleneck is
software: current robot stacks demand steep learning curves, low-level C/C++
expertise, fragmented tooling, and intricate hardware integration, in stark
contrast to the Python-centric, well-documented ecosystems that propelled
modern AI. We introduce ARK, an open-source, Python-first robotics framework
designed to close that gap. ARK presents a Gym-style environment interface that
allows users to collect data, preprocess it, and train policies using
state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy)
while seamlessly toggling between high-fidelity simulation and physical robots.
A lightweight client-server architecture provides networked
publisher-subscriber communication, and optional C/C++ bindings ensure
real-time performance when needed. ARK ships with reusable modules for control,
SLAM, motion planning, system identification, and visualization, along with
native ROS interoperability. Comprehensive documentation and case studies-from
manipulation to mobile navigation-demonstrate rapid prototyping, effortless
hardware swapping, and end-to-end pipelines that rival the convenience of
mainstream machine-learning workflows. By unifying robotics and AI practices
under a common Python umbrella, ARK lowers entry barriers and accelerates
research and commercial deployment of autonomous robots.

</details>


### [3] [TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions](https://arxiv.org/abs/2506.21630)
*Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.RO

TL;DR: 论文提出了一个针对狭窄、小径类越野环境的综合数据集TOMD，并开发了一种动态多尺度数据融合模型，用于准确预测可通行路径。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在非结构化户外环境中检测可通行路径的挑战，特别是在搜索救援和森林火灾等关键应用中。

Method: 引入TOMD数据集，包含多模态传感器数据，并提出动态多尺度数据融合模型，分析不同光照条件下的融合策略。

Result: 结果表明该方法有效，且光照对分割性能有显著影响。

Conclusion: TOMD数据集和提出的模型为未来越野导航研究提供了支持。

Abstract: Detecting traversable pathways in unstructured outdoor environments remains a
significant challenge for autonomous robots, especially in critical
applications such as wide-area search and rescue, as well as incident
management scenarios like forest fires. Existing datasets and models primarily
target urban settings or wide, vehicle-traversable off-road tracks, leaving a
substantial gap in addressing the complexity of narrow, trail-like off-road
scenarios. To address this, we introduce the Trail-based Off-road Multimodal
Dataset (TOMD), a comprehensive dataset specifically designed for such
environments. TOMD features high-fidelity multimodal sensor data -- including
128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements --
collected through repeated traversals under diverse conditions. We also propose
a dynamic multiscale data fusion model for accurate traversable pathway
prediction. The study analyzes the performance of early, cross, and mixed
fusion strategies under varying illumination levels. Results demonstrate the
effectiveness of our approach and the relevance of illumination in segmentation
performance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to
support future research in trail-based off-road navigation.

</details>


### [4] [Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions](https://arxiv.org/abs/2506.21631)
*Tianliang Yao,Bingrui Li,Bo Lu,Zhiqiang Pei,Yixuan Yuan,Peng Qi*

Main category: cs.RO

TL;DR: 提出了一种结合术前3D CTA和术中2D DSA的多模态框架，用于实时3D导丝重建，显著提升了机器人辅助血管内手术的空间感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统2D DSA缺乏深度信息，导致空间模糊性，限制了导丝形状的精确感知。

Method: 通过鲁棒特征提取处理2D DSA噪声，结合可变形图像配准和逆投影算法，实现3D导丝形状的实时重建。

Result: 系统实现了1.76±0.08像素的投影误差和2.93±0.15%的长度偏差，处理速度为39.3±1.5 FPS。

Conclusion: 该方法优化了机器人性能，提高了复杂血管内手术的精确性，有望改善临床效果。

Abstract: Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial
for precise navigation in robot-assisted endovascular interventions.
Conventional 2D Digital Subtraction Angiography (DSA) is limited by the absence
of depth information, leading to spatial ambiguities that hinder reliable
guidewire shape sensing. This paper introduces a novel multimodal framework for
real-time 3D guidewire reconstruction, combining preoperative 3D Computed
Tomography Angiography (CTA) with intraoperative 2D DSA images. The method
utilizes robust feature extraction to address noise and distortion in 2D DSA
data, followed by deformable image registration to align the 2D projections
with the 3D CTA model. Subsequently, the inverse projection algorithm
reconstructs the 3D guidewire shape, providing real-time, accurate spatial
information. This framework significantly enhances spatial awareness for
robotic-assisted endovascular procedures, effectively bridging the gap between
preoperative planning and intraoperative execution. The system demonstrates
notable improvements in real-time processing speed, reconstruction accuracy,
and computational efficiency. The proposed method achieves a projection error
of 1.76$\pm$0.08 pixels and a length deviation of 2.93$\pm$0.15\%, with a frame
rate of 39.3$\pm$1.5 frames per second (FPS). These advancements have the
potential to optimize robotic performance and increase the precision of complex
endovascular interventions, ultimately contributing to better clinical
outcomes.

</details>


### [5] [AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing](https://arxiv.org/abs/2506.21635)
*Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉的无人机着陆偏差预警系统AeroLite-MDNet，通过多尺度融合模块和分割分支提高检测精度，并引入新评价指标AWD和新数据集UAVLandData，实验显示系统性能优越。


<details>
  <summary>Details</summary>
Motivation: 无人机着陆时因GPS信号干扰等问题难以精准着陆，影响操作连续性，需一种可靠方法提升着陆安全性。

Method: 提出AeroLite-MDNet模型，结合多尺度融合模块和分割分支，用于检测着陆偏差和估计方向；引入AWD指标和新数据集UAVLandData。

Result: 系统AWD为0.7秒，偏差检测准确率达98.6%，显著提升着陆可靠性。

Conclusion: AeroLite-MDNet系统有效解决了无人机着陆偏差问题，实验验证了其优越性能。

Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse
applications such as land surveying, material transport, and environmental
monitoring. Following missions like data collection or inspection, UAVs must
land safely at docking stations for storage or recharging, which is an
essential requirement for ensuring operational continuity. However, accurate
landing remains challenging due to factors like GPS signal interference. To
address this issue, we propose a deviation warning system for UAV landings,
powered by a novel vision-based model called AeroLite-MDNet. This model
integrates a multiscale fusion module for robust cross-scale object detection
and incorporates a segmentation branch for efficient orientation estimation. We
introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the
system's sensitivity to landing deviations. Furthermore, we contribute a new
dataset, UAVLandData, which captures real-world landing deviation scenarios to
support training and evaluation. Experimental results show that our system
achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\%,
demonstrating its effectiveness in enhancing UAV landing reliability. Code will
be available at https://github.com/ITTTTTI/Maskyolo.git

</details>


### [6] [Optimal Motion Scaling for Delayed Telesurgery](https://arxiv.org/abs/2506.21689)
*Jason Lim,Florian Richter,Zih-Yun Chiu,Jaeyon Lee,Ethan Quist,Nathan Fisher,Jonathan Chambers,Steven Hong,Michael C. Yip*

Main category: cs.RO

TL;DR: 研究探讨了在长距离通信延迟下机器人远程操作的最佳运动缩放比例，发现个性化模型能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决因网络延迟导致的机器人远程操作性能下降问题，尤其是医疗领域的远程手术。

Method: 通过用户研究分析延迟、缩放比例和操作性能的关系，并开发个性化模型。

Result: 研究发现不同用户和缩放比例在特定延迟下性能差异显著，需个性化优化。

Conclusion: 个性化模型能有效优化远程操作性能，尤其在长延迟环境下。

Abstract: Robotic teleoperation over long communication distances poses challenges due
to delays in commands and feedback from network latency. One simple yet
effective strategy to reduce errors and increase performance under delay is to
downscale the relative motion between the operating surgeon and the robot. The
question remains as to what is the optimal scaling factor, and how this value
changes depending on the level of latency as well as operator tendencies. We
present user studies investigating the relationship between latency, scaling
factor, and performance. The results of our studies demonstrate a statistically
significant difference in performance between users and across scaling factors
for certain levels of delay. These findings indicate that the optimal scaling
factor for a given level of delay is specific to each user, motivating the need
for personalized models for optimal performance. We present techniques to model
the user-specific mapping of latency level to scaling factor for optimal
performance, leading to an efficient and effective solution to optimizing
performance of robotic teleoperation and specifically telesurgery under large
communication delay.

</details>


### [7] [Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation](https://arxiv.org/abs/2506.21732)
*Ameya Salvi,Venkat Krovi*

Main category: cs.RO

TL;DR: 提出了一种基于学习的视觉导航方法，解决了滑移转向车辆在动态操作中的建模和验证问题，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 滑移转向车辆在自动化部署中因缺乏准确的解析模型而受限，尤其是在动态操作中。

Method: 采用端到端学习方法（如模仿学习和深度强化学习），提出了一种结构化的视觉导航框架。

Result: 通过软件模拟、硬件评估和消融研究，验证了该方法在性能上的显著提升。

Conclusion: 该方法为滑移转向车辆的视觉导航提供了一种有效的解决方案，尤其在动态操作中表现优异。

Abstract: Vision-based lane keeping is a topic of significant interest in the robotics
and autonomous ground vehicles communities in various on-road and off-road
applications. The skid-steered vehicle architecture has served as a useful
vehicle platform for human controlled operations. However, systematic modeling,
especially of the skid-slip wheel terrain interactions (primarily in off-road
settings) has created bottlenecks for automation deployment. End-to-end
learning based methods such as imitation learning and deep reinforcement
learning, have gained prominence as a viable deployment option to counter the
lack of accurate analytical models. However, the systematic formulation and
subsequent verification/validation in dynamic operation regimes (particularly
for skid-steered vehicles) remains a work in progress. To this end, a novel
approach for structured formulation for learning visual navigation is proposed
and investigated in this work. Extensive software simulations, hardware
evaluations and ablation studies now highlight the significantly improved
performance of the proposed approach against contemporary literature.

</details>


### [8] [Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface](https://arxiv.org/abs/2506.21853)
*Dewei Wang,Chenjia Ba,Chenhui Li,Jiyuan Shi,Yan Ding,Chi Zhang,Bin Zhao*

Main category: cs.RO

TL;DR: Skill-Nav是一种将四足机器人运动技能与导航结合的分层方法，通过路径点作为接口，利用深度强化学习训练运动策略，实现复杂地形导航。


<details>
  <summary>Details</summary>
Motivation: 四足机器人虽具备卓越的运动能力，但运动技能与导航的结合尚未充分研究，这有望提升其长距离移动能力。

Method: 提出Skill-Nav方法，通过路径点作为接口，训练基于深度强化学习的运动策略，使机器人能自主调整运动技能以到达目标位置并避开障碍。

Result: 实验表明，Skill-Nav能在模拟和现实场景中有效穿越复杂地形并完成导航任务。

Conclusion: Skill-Nav通过路径点接口实现了运动技能与导航的高效结合，为复杂地形导航提供了灵活解决方案。

Abstract: Quadrupedal robots have demonstrated exceptional locomotion capabilities
through Reinforcement Learning (RL), including extreme parkour maneuvers.
However, integrating locomotion skills with navigation in quadrupedal robots
has not been fully investigated, which holds promise for enhancing
long-distance movement capabilities. In this paper, we propose Skill-Nav, a
method that incorporates quadrupedal locomotion skills into a hierarchical
navigation framework using waypoints as an interface. Specifically, we train a
waypoint-guided locomotion policy using deep RL, enabling the robot to
autonomously adjust its locomotion skills to reach targeted positions while
avoiding obstacles. Compared with direct velocity commands, waypoints offer a
simpler yet more flexible interface for high-level planning and low-level
control. Utilizing waypoints as the interface allows for the application of
various general planning tools, such as large language models (LLMs) and path
planning algorithms, to guide our locomotion policy in traversing terrains with
diverse obstacles. Extensive experiments conducted in both simulated and
real-world scenarios demonstrate that Skill-Nav can effectively traverse
complex terrains and complete challenging navigation tasks.

</details>


### [9] [Embodied Domain Adaptation for Object Detection](https://arxiv.org/abs/2506.21860)
*Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub*

Main category: cs.RO

TL;DR: 论文提出了一种无需源数据的领域自适应方法（SFDA），通过时间聚类和多尺度阈值融合改进伪标签，结合对比学习的Mean Teacher框架，显著提升了室内动态环境下的零样本检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决标准闭集方法和开放词汇对象检测（OVOD）在室内环境中因领域偏移和动态条件导致的性能不足问题。

Method: 采用源自由领域自适应（SFDA）方法，通过时间聚类优化伪标签，结合多尺度阈值融合和Mean Teacher框架，利用对比学习进行模型适应。

Result: 在EDAOD基准测试中，零样本检测性能显著提升，能够灵活适应动态室内条件。

Conclusion: 提出的方法有效解决了室内环境中对象检测的领域适应问题，为动态条件下的机器人感知提供了实用解决方案。

Abstract: Mobile robots rely on object detectors for perception and object localization
in indoor environments. However, standard closed-set methods struggle to handle
the diverse objects and dynamic conditions encountered in real homes and labs.
Open-vocabulary object detection (OVOD), driven by Vision Language Models
(VLMs), extends beyond fixed labels but still struggles with domain shifts in
indoor environments. We introduce a Source-Free Domain Adaptation (SFDA)
approach that adapts a pre-trained model without accessing source data. We
refine pseudo labels via temporal clustering, employ multi-scale threshold
fusion, and apply a Mean Teacher framework with contrastive learning. Our
Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates
adaptation under sequential changes in lighting, layout, and object diversity.
Our experiments show significant gains in zero-shot detection performance and
flexible adaptation to dynamic indoor conditions.

</details>


### [10] [A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments](https://arxiv.org/abs/2506.21982)
*Akshay Jaitly,Jack Cline,Siavash Farzan*

Main category: cs.RO

TL;DR: 提出一种混合整数线性规划（MILP）方法，用于多智能体运动规划，通过序列化解决流程嵌入PAAMP，显著减少变量数量并提高求解速度。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体运动规划中传统MILP方法变量多、求解慢的问题，提出更高效的优化框架。

Method: 结合PAAMP和序列化解决流程，使用区域序列限制智能体运动，并通过大M超平面模型确保智能体间分离，减少碰撞约束的变量数量。

Result: 在代表性多智能体场景中，该方法比传统MILP快一个数量级，且能生成无碰撞的平滑轨迹。

Conclusion: 提出的MILP框架在多智能体运动规划中显著提升了效率和性能，适用于复杂场景。

Abstract: We propose a mixed-integer linear program (MILP) for multi-agent motion
planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a
sequence-then-solve pipeline. Region sequences confine each agent to adjacent
convex polytopes, while a big-M hyperplane model enforces inter-agent
separation. Collision constraints are applied only to agents sharing or
neighboring a region, which reduces binary variables exponentially compared
with naive formulations. An L1 path-length-plus-acceleration cost yields smooth
trajectories. We prove finite-time convergence and demonstrate on
representative multi-agent scenarios with obstacles that our formulation
produces collision-free trajectories an order of magnitude faster than an
unstructured MILP baseline.

</details>


### [11] [LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies](https://arxiv.org/abs/2506.22028)
*Ossi Parikka,Roel Pieters*

Main category: cs.RO

TL;DR: 论文提出了一种基于大语言模型（LLM）的语音控制架构LMPVC，用于人机协作（HRC），通过集成策略编程和教学功能，解决了LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代制造业趋向个性化和复杂化，需要更先进的人机协作方法，尤其是语音控制。LLM的发展为此提供了潜力。

Method: 提出LMPVC架构，结合代码生成和策略银行（Policy Bank）系统，实现语音控制、编程和教学功能。

Result: LMPVC能适应不同任务，无需耗时训练，弥补了LLM的不足。

Conclusion: LMPVC为HRC提供了一种高效灵活的语音控制解决方案，代码已开源。

Abstract: Modern industry is increasingly moving away from mass manufacturing, towards
more specialized and personalized products. As manufacturing tasks become more
complex, full automation is not always an option, human involvement may be
required. This has increased the need for advanced human robot collaboration
(HRC), and with it, improved methods for interaction, such as voice control.
Recent advances in natural language processing, driven by artificial
intelligence (AI), have the potential to answer this demand. Large language
models (LLMs) have rapidly developed very impressive general reasoning
capabilities, and many methods of applying this to robotics have been proposed,
including through the use of code generation. This paper presents Language
Model Program Voice Control (LMPVC), an LLM-based prototype voice control
architecture with integrated policy programming and teaching capabilities,
built for use with Robot Operating System 2 (ROS2) compatible robots. The
architecture builds on prior works using code generation for voice control by
implementing an additional programming and teaching system, the Policy Bank. We
find this system can compensate for the limitations of the underlying LLM, and
allow LMPVC to adapt to different downstream tasks without a slow and costly
training process. The architecture and additional results are released on
GitHub (https://github.com/ozzyuni/LMPVC).

</details>


### [12] [Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception](https://arxiv.org/abs/2506.22034)
*Kejia Chen,Celina Dettmering,Florian Pachler,Zhuo Liu,Yue Zhang,Tailai Cheng,Jonas Dirr,Zhenshan Bing,Alois Knoll,Rüdiger Daub*

Main category: cs.RO

TL;DR: 提出了一种基于对象感知和规划的框架，用于实现工业价值链中全面的可变形线性物体（DLO）装配过程。


<details>
  <summary>Details</summary>
Motivation: 工业中DLO（如电缆）的装配具有潜力，但因其变形复杂且行为难以预测，机器人自动化面临挑战。现有研究仅解决孤立子问题，缺乏集成工作流。

Method: 利用视觉和触觉信息跟踪DLO形状及接触状态，结合机器人动作规划，实现从杂乱环境中分拣到多机器人协同装配的完整流程。

Result: 真实多机器人实验验证了方法的有效性及其工业适用性。

Conclusion: 提出的框架为DLO装配提供了集成解决方案，展示了工业应用的潜力。

Abstract: Industrial assembly of deformable linear objects (DLOs) such as cables offers
great potential for many industries. However, DLOs pose several challenges for
robot-based automation due to the inherent complexity of deformation and,
consequentially, the difficulties in anticipating the behavior of DLOs in
dynamic situations. Although existing studies have addressed isolated
subproblems like shape tracking, grasping, and shape control, there has been
limited exploration of integrated workflows that combine these individual
processes. To address this gap, we propose an object-centric perception and
planning framework to achieve a comprehensive DLO assembly process throughout
the industrial value chain. The framework utilizes visual and tactile
information to track the DLO's shape as well as contact state across different
stages, which facilitates effective planning of robot actions. Our approach
encompasses robot-based bin picking of DLOs from cluttered environments,
followed by a coordinated handover to two additional robots that mount the DLOs
onto designated fixtures. Real-world experiments employing a setup with
multiple robots demonstrate the effectiveness of the approach and its relevance
to industrial scenarios.

</details>


### [13] [An Introduction to Zero-Order Optimization Techniques for Robotics](https://arxiv.org/abs/2506.22087)
*Armand Jordana,Jianghan Zhang,Joseph Amigo,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文为零阶优化技术提供数学教程，统一视角理解机器人学中的算法，并推导新RL算法。


<details>
  <summary>Details</summary>
Motivation: 零阶优化技术在机器人学中因处理非可微函数和逃离局部极小值的优势而流行，适用于轨迹优化和策略优化。

Method: 提出随机搜索的数学教程，提供统一视角分类轨迹优化方法，并推导新RL算法。

Result: 通过统一视角，将多种轨迹优化方法归类，并开发出有竞争力的新RL算法。

Conclusion: 零阶优化技术的统一视角为机器人学中的算法理解和创新提供了有效工具。

Abstract: Zero-order optimization techniques are becoming increasingly popular in
robotics due to their ability to handle non-differentiable functions and escape
local minima. These advantages make them particularly useful for trajectory
optimization and policy optimization. In this work, we propose a mathematical
tutorial on random search. It offers a simple and unifying perspective for
understanding a wide range of algorithms commonly used in robotics. Leveraging
this viewpoint, we classify many trajectory optimization methods under a common
framework and derive novel competitive RL algorithms.

</details>


### [14] [Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration](https://arxiv.org/abs/2506.22116)
*Noora Sassali,Roel Pieters*

Main category: cs.RO

TL;DR: 该研究提出了一种基于姿态估计和几何模型的方法，用于在平面工作空间中定位指向目标，并评估其在机器人任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 指向手势在人机协作中广泛应用，但缺乏一种系统的方法来定位指向目标并评估其准确性。

Method: 采用姿态估计和基于肩-腕伸展的几何模型，从RGB-D流中提取手势数据，并结合多模态技术（如物体检测和语音处理）进行验证。

Result: 开发了一个概念验证机器人系统，展示了多模态协作应用的可行性，并提供了工具的性能和局限性分析。

Conclusion: 该方法为多模态机器人系统中的指向手势定位提供了可行解决方案，但仍需进一步优化以适应更复杂场景。

Abstract: Pointing gestures are a common interaction method used in Human-Robot
Collaboration for various tasks, ranging from selecting targets to guiding
industrial processes. This study introduces a method for localizing pointed
targets within a planar workspace. The approach employs pose estimation, and a
simple geometric model based on shoulder-wrist extension to extract gesturing
data from an RGB-D stream. The study proposes a rigorous methodology and
comprehensive analysis for evaluating pointing gestures and target selection in
typical robotic tasks. In addition to evaluating tool accuracy, the tool is
integrated into a proof-of-concept robotic system, which includes object
detection, speech transcription, and speech synthesis to demonstrate the
integration of multiple modalities in a collaborative application. Finally, a
discussion over tool limitations and performance is provided to understand its
role in multimodal robotic systems. All developments are available at:
https://github.com/NMKsas/gesture_pointer.git.

</details>


### [15] [RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric](https://arxiv.org/abs/2506.22170)
*Yu Zhang,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了基于黎曼度量的RM-Dijkstra算法，用于解决移动机器人表面路径规划问题，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: Dijkstra算法在离散图空间中表现优异，但在移动机器人表面路径规划中应用较少，需要改进。

Method: 通过构建新的黎曼度量，将表面路径规划问题转化为2D平面上的几何问题，并确保投影映射为等距浸入。

Result: 仿真测试表明，RM-Dijkstra算法在路径精度和平滑度上优于传统算法，尤其在复杂场景中。

Conclusion: RM-Dijkstra算法有效解决了表面最优路径规划问题，具有实际应用潜力。

Abstract: The Dijkstra algorithm is a classic path planning method, which operates in a
discrete graph space to determine the shortest path from a specified source
point to a target node or all other nodes based on non-negative edge weights.
Numerous studies have focused on the Dijkstra algorithm due to its potential
application. However, its application in surface path planning for mobile
robots remains largely unexplored. In this letter, a surface optimal path
planning algorithm called RM-Dijkstra is proposed, which is based on Riemannian
metric model. By constructing a new Riemannian metric on the 2D projection
plane, the surface optimal path planning problem is therefore transformed into
a geometric problem on the 2D plane with new Riemannian metric. Induced by the
standard Euclidean metric on surface, the constructed new metric reflects
environmental information of the robot and ensures that the projection map is
an isometric immersion. By conducting a series of simulation tests, the
experimental results demonstrate that the RM-Dijkstra algorithm not only
effectively solves the optimal path planning problem on surfaces, but also
outperforms traditional path planning algorithms in terms of path accuracy and
smoothness, particularly in complex scenarios.

</details>


### [16] [ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research](https://arxiv.org/abs/2506.22174)
*Bavo Lesy,Siemen Herremans,Robin Kerstens,Jan Steckel,Walter Daems,Siegfried Mercelis,Ali Anwar*

Main category: cs.RO

TL;DR: ASVSim是一个开源仿真框架，专为内河和港口环境中的自主航运研究设计，结合了船舶动力学和海洋传感器模拟功能。


<details>
  <summary>Details</summary>
Motivation: 运输行业对无人水面车辆（USVs）的需求增加，但缺乏开源高保真仿真框架和数据集。

Method: 基于Cosys-AirSim开发，支持船舶动力学和传感器模拟，生成合成数据集用于训练计算机视觉和强化学习模型。

Result: 通过实验展示了ASVSim在自主导航算法研究和数据集生成方面的潜力。

Conclusion: ASVSim作为开源项目，为海洋工程社区提供了自主导航研究的平台。

Abstract: The transport industry has recently shown significant interest in unmanned
surface vehicles (USVs), specifically for port and inland waterway transport.
These systems can improve operational efficiency and safety, which is
especially relevant in the European Union, where initiatives such as the Green
Deal are driving a shift towards increased use of inland waterways. At the same
time, a shortage of qualified personnel is accelerating the adoption of
autonomous solutions. However, there is a notable lack of open-source,
high-fidelity simulation frameworks and datasets for developing and evaluating
such solutions. To address these challenges, we introduce AirSim For Surface
Vehicles (ASVSim), an open-source simulation framework specifically designed
for autonomous shipping research in inland and port environments. The framework
combines simulated vessel dynamics with marine sensor simulation capabilities,
including radar and camera systems and supports the generation of synthetic
datasets for training computer vision models and reinforcement learning agents.
Built upon Cosys-AirSim, ASVSim provides a comprehensive platform for
developing autonomous navigation algorithms and generating synthetic datasets.
The simulator supports research of both traditional control methods and deep
learning-based approaches. Through limited experiments, we demonstrate the
potential of the simulator in these research areas. ASVSim is provided as an
open-source project under the MIT license, making autonomous navigation
research accessible to a larger part of the ocean engineering community.

</details>


### [17] [KnotDLO: Toward Interpretable Knot Tying](https://arxiv.org/abs/2506.22176)
*Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl*

Main category: cs.RO

TL;DR: KnotDLO是一种无需人工演示或训练的单手可变形线性物体（DLO）打结方法，具有抗遮挡性、可重复性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决DLO打结任务中的遮挡问题、初始配置差异以及需要人工干预的局限性。

Method: 通过当前DLO形状规划抓取和目标路径点，利用分段线性曲线跟踪和几何计算生成中间路径点，实现视觉与控制的解耦。

Result: 在16次实验中，KnotDLO在从未见过的配置下成功打结的成功率为50%。

Conclusion: KnotDLO展示了无需训练和人工干预的DLO打结能力，但成功率有待提升。

Abstract: This work presents KnotDLO, a method for one-handed Deformable Linear Object
(DLO) knot tying that is robust to occlusion, repeatable for varying rope
initial configurations, interpretable for generating motion policies, and
requires no human demonstrations or training. Grasp and target waypoints for
future DLO states are planned from the current DLO shape. Grasp poses are
computed from indexing the tracked piecewise linear curve representing the DLO
state based on the current curve shape and are piecewise continuous. KnotDLO
computes intermediate waypoints from the geometry of the current DLO state and
the desired next state. The system decouples visual reasoning from control. In
16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an
overhand knot from previously unseen configurations.

</details>


### [18] [Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass](https://arxiv.org/abs/2506.22364)
*Joe Johnson,Phanender Chalasani,Arnav Shah,Ram L. Ray,Muthukumar Bagavathiannan*

Main category: cs.RO

TL;DR: 研究提出了一种基于多模态传感器和机器学习的系统，用于精准估计覆盖作物生物量，以优化杂草管理策略。


<details>
  <summary>Details</summary>
Motivation: 精准杂草管理对减少作物产量损失至关重要，但传统方法（如人工检查）效率低下，需要更高效的技术。

Method: 结合光学和LiDAR数据，利用机器学习方法进行数据融合，提高生物量预测精度。

Result: 最佳模型在干生物量估计中达到0.88的决定系数，表现优异。

Conclusion: 该系统为精准农业提供了有效工具，支持可持续杂草管理和耕作实践。

Abstract: Accurate weed management is essential for mitigating significant crop yield
losses, necessitating effective weed suppression strategies in agricultural
systems. Integrating cover crops (CC) offers multiple benefits, including soil
erosion reduction, weed suppression, decreased nitrogen requirements, and
enhanced carbon sequestration, all of which are closely tied to the aboveground
biomass (AGB) they produce. However, biomass production varies significantly
due to microsite variability, making accurate estimation and mapping essential
for identifying zones of poor weed suppression and optimizing targeted
management strategies. To address this challenge, developing a comprehensive CC
map, including its AGB distribution, will enable informed decision-making
regarding weed control methods and optimal application rates. Manual visual
inspection is impractical and labor-intensive, especially given the extensive
field size and the wide diversity and variation of weed species and sizes. In
this context, optical imagery and Light Detection and Ranging (LiDAR) data are
two prominent sources with unique characteristics that enhance AGB estimation.
This study introduces a ground robot-mounted multimodal sensor system designed
for agricultural field mapping. The system integrates optical and LiDAR data,
leveraging machine learning (ML) methods for data fusion to improve biomass
predictions. The best ML-based model for dry AGB estimation achieved a
coefficient of determination value of 0.88, demonstrating robust performance in
diverse field conditions. This approach offers valuable insights for
site-specific management, enabling precise weed suppression strategies and
promoting sustainable farming practices.

</details>
