{"id": "2509.18337", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18337", "abs": "https://arxiv.org/abs/2509.18337", "authors": ["Bo Xiong", "Linghao Zhang", "Chong Wang", "Peng Liang"], "title": "CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation", "comment": "15 pages, 4 images, 6 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Commit messages play a key role in documenting the intent behind code\nchanges. However, they are often low-quality, vague, or incomplete, limiting\ntheir usefulness. Commit Message Generation (CMG) aims to automatically\ngenerate descriptive commit messages from code diffs to reduce developers'\neffort and improve message quality. Although recent advances in LLMs have shown\npromise in automating CMG, their performance remains limited. This paper aims\nto enhance CMG performance by retrieving similar diff-message pairs to guide\nLLMs to generate commit messages that are more precise and informative. We\nproposed CoRaCMG, a Contextual Retrieval-augmented framework for Commit Message\nGeneration, structured in three phases: (1) Retrieve: retrieving the similar\ndiff-message pairs; (2) Augment: combining them with the query diff into a\nstructured prompt; and (3) Generate: generating commit messages corresponding\nto the query diff via LLMs. CoRaCMG enables LLMs to learn project-specific\nterminologies and writing styles from the retrieved diff-message pairs, thereby\nproducing high-quality commit messages. We evaluated our method on various\nLLMs, including closed-source GPT models and open-source DeepSeek models.\nExperimental results show that CoRaCMG significantly boosts LLM performance\nacross four metrics (BLEU, Rouge-L, METEOR, and CIDEr). Specifically,\nDeepSeek-R1 achieves relative improvements of 76% in BLEU and 71% in CIDEr when\naugmented with a single retrieved example pair. After incorporating the single\nexample pair, GPT-4o achieves the highest improvement rate, with BLEU\nincreasing by 89%. Moreover, performance gains plateau after more than three\nexamples are used, indicating diminishing returns. Further analysis shows that\nthe improvements are attributed to the model's ability to capture the\nterminologies and writing styles of human-written commit messages from the\nretrieved example pairs.", "AI": {"tldr": "CoRaCMG\u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u76f8\u4f3c\u7684diff-message\u5bf9\u6765\u6307\u5bfcLLM\u751f\u6210\u66f4\u7cbe\u786e\u3001\u4fe1\u606f\u91cf\u66f4\u5927\u7684\u63d0\u4ea4\u6d88\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u63d0\u4ea4\u6d88\u606f\u5f80\u5f80\u8d28\u91cf\u4f4e\u4e0b\u3001\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002\u867d\u7136LLM\u5728\u81ea\u52a8\u751f\u6210\u63d0\u4ea4\u6d88\u606f\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u6709\u5c40\u9650\uff0c\u9700\u8981\u63d0\u5347\u751f\u6210\u6d88\u606f\u7684\u7cbe\u786e\u6027\u548c\u4fe1\u606f\u91cf\u3002", "method": "\u63d0\u51fa\u4e86CoRaCMG\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a(1)\u68c0\u7d22\u76f8\u4f3c\u7684diff-message\u5bf9\uff1b(2)\u5c06\u68c0\u7d22\u7ed3\u679c\u4e0e\u67e5\u8be2diff\u7ed3\u5408\u6210\u7ed3\u6784\u5316\u63d0\u793a\uff1b(3)\u901a\u8fc7LLM\u751f\u6210\u5bf9\u5e94\u7684\u63d0\u4ea4\u6d88\u606f\u3002\u8be5\u65b9\u6cd5\u4f7fLLM\u80fd\u591f\u4ece\u68c0\u7d22\u5230\u7684\u793a\u4f8b\u5bf9\u4e2d\u5b66\u4e60\u9879\u76ee\u7279\u5b9a\u672f\u8bed\u548c\u5199\u4f5c\u98ce\u683c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoRaCMG\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2aLLM\u6a21\u578b\u5728BLEU\u3001Rouge-L\u3001METEOR\u548cCIDEr\u56db\u4e2a\u6307\u6807\u4e0a\u7684\u6027\u80fd\u3002DeepSeek-R1\u5728\u4f7f\u7528\u5355\u4e2a\u68c0\u7d22\u793a\u4f8b\u5bf9\u65f6\uff0cBLEU\u548cCIDEr\u5206\u522b\u63d0\u5347\u4e8676%\u548c71%\uff1bGPT-4o\u7684BLEU\u63d0\u5347\u4e8689%\u3002\u6027\u80fd\u63d0\u5347\u5728\u8d85\u8fc7\u4e09\u4e2a\u793a\u4f8b\u540e\u8d8b\u4e8e\u5e73\u7a33\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u901a\u8fc7\u8ba9\u6a21\u578b\u4ece\u68c0\u7d22\u5230\u7684\u793a\u4f8b\u5bf9\u4e2d\u5b66\u4e60\u4eba\u7c7b\u7f16\u5199\u7684\u63d0\u4ea4\u6d88\u606f\u7684\u672f\u8bed\u548c\u5199\u4f5c\u98ce\u683c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2509.18361", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.18361", "abs": "https://arxiv.org/abs/2509.18361", "authors": ["Daye Nam", "Malgorzata Salawa", "Satish Chandra"], "title": "Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts", "comment": null, "summary": "Evaluating developer satisfaction with conversational AI assistants at scale\nis critical but challenging. User studies provide rich insights, but are\nunscalable, while large-scale quantitative signals from logs or in-product\nratings are often too shallow or sparse to be reliable. To address this gap, we\npropose and evaluate a new approach: using sentiment analysis of developer\nprompts to identify implicit signals of user satisfaction. With an analysis of\nindustrial usage logs of 372 professional developers, we show that this\napproach can identify a signal in ~8% of all interactions, a rate more than 13\ntimes higher than explicit user feedback, with reasonable accuracy even with an\noff-the-shelf sentiment analysis approach. This new practical approach to\ncomplement existing feedback channels would open up new directions for building\na more comprehensive understanding of the developer experience at scale.", "AI": {"tldr": "\u4f7f\u7528\u5f00\u53d1\u8005\u63d0\u793a\u7684\u60c5\u611f\u5206\u6790\u6765\u8bc4\u4f30\u5f00\u53d1\u8005\u5bf9AI\u52a9\u624b\u7684\u6ee1\u610f\u5ea6\uff0c\u8be5\u65b9\u6cd5\u6bd4\u663e\u5f0f\u7528\u6237\u53cd\u9988\u7387\u9ad813\u500d\u4ee5\u4e0a", "motivation": "\u8bc4\u4f30\u5f00\u53d1\u8005\u5bf9\u5bf9\u8bdd\u5f0fAI\u52a9\u624b\u7684\u6ee1\u610f\u5ea6\u5f88\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\uff0c\u7528\u6237\u7814\u7a76\u4e0d\u53ef\u6269\u5c55\uff0c\u800c\u5927\u89c4\u6a21\u5b9a\u91cf\u4fe1\u53f7\u5f80\u5f80\u592a\u6d45\u6216\u7a00\u758f\u4e0d\u53ef\u9760", "method": "\u5206\u6790372\u540d\u4e13\u4e1a\u5f00\u53d1\u8005\u7684\u5de5\u4e1a\u4f7f\u7528\u65e5\u5fd7\uff0c\u901a\u8fc7\u60c5\u611f\u5206\u6790\u8bc6\u522b\u5f00\u53d1\u8005\u63d0\u793a\u4e2d\u7684\u9690\u5f0f\u6ee1\u610f\u5ea6\u4fe1\u53f7", "result": "\u8be5\u65b9\u6cd5\u80fd\u5728\u7ea68%\u7684\u4ea4\u4e92\u4e2d\u8bc6\u522b\u4fe1\u53f7\uff0c\u6bd4\u663e\u5f0f\u7528\u6237\u53cd\u9988\u7387\u9ad813\u500d\u4ee5\u4e0a\uff0c\u5373\u4f7f\u4f7f\u7528\u73b0\u6210\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u4e5f\u5177\u6709\u5408\u7406\u51c6\u786e\u6027", "conclusion": "\u8fd9\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u8865\u5145\u73b0\u6709\u53cd\u9988\u6e20\u9053\uff0c\u4e3a\u5927\u89c4\u6a21\u7406\u89e3\u5f00\u53d1\u8005\u4f53\u9a8c\u5f00\u8f9f\u65b0\u65b9\u5411"}}
{"id": "2509.18454", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18454", "abs": "https://arxiv.org/abs/2509.18454", "authors": ["Andrzej Bia\u0142ecki", "Piotr Bia\u0142ecki", "Piotr Sowi\u0144ski", "Mateusz Budziak", "Jan Gajewski"], "title": "SC2Tools: StarCraft II Toolset and Dataset API", "comment": null, "summary": "Computer games, as fully controlled simulated environments, have been\nutilized in significant scientific studies demonstrating the application of\nReinforcement Learning (RL). Gaming and esports are key areas influenced by the\napplication of Artificial Intelligence (AI) and Machine Learning (ML) solutions\nat scale. Tooling simplifies scientific workloads and is essential for\ndeveloping the gaming and esports research area.\n  In this work, we present ``SC2Tools'', a toolset containing multiple\nsubmodules responsible for working with, and producing larger datasets. We\nprovide a modular structure of the implemented tooling, leaving room for future\nextensions where needed. Additionally, some of the tools are not StarCraft~2\nexclusive and can be used with other types of data for dataset creation.\n  The tools we present were leveraged in creating one of the largest\nStarCraft~2 tournament datasets to date with a separate PyTorch and PyTorch\nLightning application programming interface (API) for easy access to the data.\n  We conclude that alleviating the burden of data collection, preprocessing,\nand custom code development is essential for less technically proficient\nresearchers to engage in the growing gaming and esports research area. Finally,\nour solution provides some foundational work toward normalizing experiment\nworkflow in StarCraft~2", "AI": {"tldr": "SC2Tools\u662f\u4e00\u4e2a\u7528\u4e8e\u661f\u9645\u4e89\u97382\u6570\u636e\u5206\u6790\u7684\u5de5\u5177\u96c6\uff0c\u65e8\u5728\u7b80\u5316\u6570\u636e\u6536\u96c6\u548c\u5904\u7406\u5de5\u4f5c\uff0c\u4e3a\u6e38\u620f\u548c\u7535\u7ade\u7814\u7a76\u63d0\u4f9b\u4fbf\u5229\u3002", "motivation": "\u8ba1\u7b97\u673a\u6e38\u620f\u4f5c\u4e3a\u5b8c\u5168\u53d7\u63a7\u7684\u6a21\u62df\u73af\u5883\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002\u6e38\u620f\u548c\u7535\u7ade\u9886\u57df\u9700\u8981\u5927\u89c4\u6a21AI\u548c\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6570\u636e\u6536\u96c6\u548c\u9884\u5904\u7406\u5de5\u4f5c\u7e41\u91cd\uff0c\u963b\u788d\u4e86\u6280\u672f\u80fd\u529b\u8f83\u5f31\u7684\u7814\u7a76\u4eba\u5458\u53c2\u4e0e\u3002", "method": "\u5f00\u53d1SC2Tools\u5de5\u5177\u96c6\uff0c\u5305\u542b\u591a\u4e2a\u5b50\u6a21\u5757\uff0c\u91c7\u7528\u6a21\u5757\u5316\u7ed3\u6784\u8bbe\u8ba1\uff0c\u652f\u6301\u661f\u9645\u4e89\u97382\u53ca\u5176\u4ed6\u7c7b\u578b\u6570\u636e\u7684\u5904\u7406\u3002\u63d0\u4f9bPyTorch\u548cPyTorch Lightning API\u63a5\u53e3\u4fbf\u4e8e\u6570\u636e\u8bbf\u95ee\u3002", "result": "\u521b\u5efa\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u661f\u9645\u4e89\u97382\u6bd4\u8d5b\u6570\u636e\u96c6\uff0c\u5de5\u5177\u96c6\u4e0d\u4ec5\u9650\u4e8e\u661f\u9645\u4e89\u97382\uff0c\u8fd8\u53ef\u7528\u4e8e\u5176\u4ed6\u7c7b\u578b\u6570\u636e\u7684\u6570\u636e\u96c6\u521b\u5efa\u3002", "conclusion": "\u51cf\u8f7b\u6570\u636e\u6536\u96c6\u3001\u9884\u5904\u7406\u548c\u81ea\u5b9a\u4e49\u4ee3\u7801\u5f00\u53d1\u7684\u8d1f\u62c5\u5bf9\u4e8e\u6280\u672f\u80fd\u529b\u8f83\u5f31\u7684\u7814\u7a76\u4eba\u5458\u53c2\u4e0e\u6e38\u620f\u548c\u7535\u7ade\u7814\u7a76\u81f3\u5173\u91cd\u8981\u3002\u8be5\u5de5\u5177\u4e3a\u661f\u9645\u4e89\u97382\u5b9e\u9a8c\u5de5\u4f5c\u6d41\u7a0b\u7684\u6807\u51c6\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u4f5c\u3002"}}
{"id": "2509.18548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18548", "abs": "https://arxiv.org/abs/2509.18548", "authors": ["Steven R Brandt", "Max Morris", "Patrick Diehl", "Christopher Bowen", "Jacob Tucker", "Lauren Bristol", "Golden G. Richard III"], "title": "Locking Down Science Gateways", "comment": null, "summary": "The most recent Linux kernels have a new feature for securing applications:\nLandlock. Like Seccomp before it, Landlock makes it possible for a running\nprocess to give up access to resources. For applications running as Science\nGateways, network access is required while starting up MPI, but for the sake of\nsecurity, it should be taken away prior to the reading of user-supplied\nparameter files. We explore the usefulness of Landlock by modifying and locking\ndown three mature scientific codes: The Einstein Toolkit (a code that studies\nthe dynamics of relativistic astrophysics, e.g. neutron star collisions),\nOcto-Tiger (a code for studying the dynamics of non-relativistic astrophysics,\ne.g. white dwarfs), and FUKA (an initial data solver for relativistic codes).\nFinally, we implement a fully-functioning FUKA science gateway that relies on\nLandlock (instead of user authentication) for security.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86Linux\u5185\u6838\u65b0\u5b89\u5168\u7279\u6027Landlock\u5728\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u4fee\u6539\u4e09\u4e2a\u6210\u719f\u79d1\u5b66\u4ee3\u7801\u5e76\u5b9e\u73b0\u57fa\u4e8eLandlock\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236", "motivation": "\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u5728\u542f\u52a8MPI\u65f6\u9700\u8981\u7f51\u7edc\u8bbf\u95ee\uff0c\u4f46\u4e3a\u4e86\u5b89\u5168\u8003\u8651\uff0c\u5728\u8bfb\u53d6\u7528\u6237\u63d0\u4f9b\u7684\u53c2\u6570\u6587\u4ef6\u524d\u5e94\u8be5\u79fb\u9664\u8fd9\u4e9b\u6743\u9650\u3002Landlock\u63d0\u4f9b\u4e86\u6bd4Seccomp\u66f4\u7cbe\u7ec6\u7684\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\u80fd\u529b", "method": "\u4fee\u6539Einstein Toolkit\u3001Octo-Tiger\u548cFUKA\u4e09\u4e2a\u79d1\u5b66\u4ee3\u7801\uff0c\u4f7f\u7528Landlock\u8fdb\u884c\u5b89\u5168\u9501\u5b9a\uff0c\u5e76\u5b9e\u73b0\u4e00\u4e2a\u5b8c\u5168\u529f\u80fd\u7684FUKA\u79d1\u5b66\u7f51\u5173\uff0c\u4f9d\u8d56Landlock\u800c\u975e\u7528\u6237\u8ba4\u8bc1\u6765\u786e\u4fdd\u5b89\u5168", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86Landlock\u5728\u79d1\u5b66\u8ba1\u7b97\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\u673a\u5236", "conclusion": "Landlock\u662f\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u4e2d\u6709\u6548\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u7528\u6237\u8ba4\u8bc1\u65b9\u5f0f"}}
{"id": "2509.18684", "categories": ["cs.PF"], "pdf": "https://arxiv.org/pdf/2509.18684", "abs": "https://arxiv.org/abs/2509.18684", "authors": ["Abdur Razzak", "Atanu Barai", "Nandakishore Santhi", "Abdel-Hameed A. Badawy"], "title": "Static Estimation of Reuse Profiles for Arrays in Nested Loops", "comment": "This paper is accepted at the MEMSYS 2025 conference, 11th\n  International Symposium on Memory Systems, Washington D.C., October 7 -\n  October 8, 2025", "summary": "Efficient memory access patterns play a crucial role in determining the\noverall performance of applications by exploiting temporal and spatial\nlocality, thus maximizing cache locality. The Reuse Distance Histogram (RDH) is\na widely used metric to quantify temporal locality, measuring the distance\nbetween consecutive accesses to the same memory location. Traditionally,\ncalculating RDH requires program execution and memory trace collection to\nobtain dynamic memory access behavior. This trace collection is often\ntime-consuming, resource-intensive, and unsuitable for early-stage optimization\nor large-scale applications. Static prediction, on the other hand, offers a\nsignificant speedup in estimating RDH and cache hit rates. However, these\napproaches lack accuracy, since the predictions come without running the\nprogram and knowing the complete memory access pattern, more specifically when\narrays are used inside nested loops. This paper presents a novel static\nanalysis framework for predicting the reuse profiles of array references in\nprograms with nested loop structures, without requiring any runtime\ninformation. By analyzing loop bounds, access patterns in smaller problem\nsizes, and predictive equations, our method predicts access patterns of arrays\nand estimates reuse distances and cache hit rate at compile time. This paper\nextends our previous study by incorporating more analysis and improving\nprediction by addressing previously unhandled reuse patterns. We evaluate our\ntechnique against a widely accepted traditional trace-driven profiling tool,\nParallel Reuse Distance Analysis (PARDA). The results demonstrate that our\nstatic predictor achieves comparable accuracy while offering\norders-of-magnitude improvement in the analysis speed. This work offers a\npractical alternative to dynamic reuse profiling and paves the way for\nintegration into compilers and static performance modeling tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u5d4c\u5957\u5faa\u73af\u7a0b\u5e8f\u4e2d\u6570\u7ec4\u5f15\u7528\u7684\u91cd\u7528\u6a21\u5f0f\uff0c\u65e0\u9700\u8fd0\u884c\u65f6\u4fe1\u606f\u5373\u53ef\u4f30\u7b97\u91cd\u7528\u8ddd\u79bb\u548c\u7f13\u5b58\u547d\u4e2d\u7387", "motivation": "\u4f20\u7edf\u52a8\u6001\u5185\u5b58\u8ffd\u8e2a\u65b9\u6cd5\u8017\u65f6\u8017\u8d44\u6e90\uff0c\u4e0d\u9002\u5408\u65e9\u671f\u4f18\u5316\u548c\u5927\u89c4\u6a21\u5e94\u7528\uff1b\u73b0\u6709\u9759\u6001\u9884\u6d4b\u65b9\u6cd5\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5d4c\u5957\u5faa\u73af\u4e2d\u7684\u6570\u7ec4\u8bbf\u95ee\u65f6", "method": "\u901a\u8fc7\u5206\u6790\u5faa\u73af\u8fb9\u754c\u3001\u5c0f\u89c4\u6a21\u95ee\u9898\u8bbf\u95ee\u6a21\u5f0f\u548c\u9884\u6d4b\u65b9\u7a0b\uff0c\u5728\u7f16\u8bd1\u65f6\u9884\u6d4b\u6570\u7ec4\u8bbf\u95ee\u6a21\u5f0f\u3001\u91cd\u7528\u8ddd\u79bb\u548c\u7f13\u5b58\u547d\u4e2d\u7387", "result": "\u4e0e\u4e3b\u6d41\u52a8\u6001\u5206\u6790\u5de5\u5177PARDA\u76f8\u6bd4\uff0c\u9759\u6001\u9884\u6d4b\u5668\u8fbe\u5230\u76f8\u5f53\u7cbe\u5ea6\uff0c\u540c\u65f6\u5206\u6790\u901f\u5ea6\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u52a8\u6001\u91cd\u7528\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u548c\u9759\u6001\u6027\u80fd\u5efa\u6a21\u5de5\u5177\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2509.18472", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18472", "abs": "https://arxiv.org/abs/2509.18472", "authors": ["Atanu Barai", "Kamalavasan Kamalakkannan", "Patrick Diehl", "Maxim Moraru", "Jered Dominguez-Trujillo", "Howard Pritchard", "Nandakishore Santhi", "Farzad Fatollahi-Fard", "Galen Shipman"], "title": "Bridging Simulation and Silicon: A Study of RISC-V Hardware and FireSim Simulation", "comment": null, "summary": "RISC-V ISA-based processors have recently emerged as both powerful and\nenergy-efficient computing platforms. The release of the MILK-V Pioneer marked\na significant milestone as the first desktop-grade RISC-V system. With\nincreasing engagement from both academia and industry, such platforms exhibit\nstrong potential for adoption in high-performance computing (HPC) environments.\n  The open-source, FPGA-accelerated FireSim framework has emerged as a flexible\nand scalable tool for architectural exploration, enabling simulation of various\nsystem configurations using RISC-V cores. Despite its capabilities, there\nremains a lack of systematic evaluation regarding the feasibility and\nperformance prediction accuracy of FireSim when compared to physical hardware.\n  In this study, we address this gap by modeling a commercially available\nsingle-board computer and a desktop-grade RISC-V CPU within FireSim. To ensure\nfidelity between simulation and real hardware, we first measure the performance\nof a series of benchmarks to compare runtime behavior under single-core and\nfour-core configurations. Based on the closest matching simulation parameters,\nwe subsequently evaluate performance using a representative mini-application\nand the LAMMPS molecular dynamics code.\n  Our findings indicate that while FireSim provides valuable insights into\narchitectural performance trends, discrepancies remain between simulated and\nmeasured runtimes. These deviations stem from both inherent limitations of the\nsimulation environment and the restricted availability of detailed performance\nspecifications from CPU manufacturers, which hinder precise configuration\nmatching.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86FireSim\u6a21\u62df\u5668\u5bf9RISC-V\u5904\u7406\u5668\u7684\u6027\u80fd\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u5bf9\u6bd4\u6a21\u62df\u7ed3\u679c\u4e0e\u771f\u5b9e\u786c\u4ef6\u6d4b\u8bd5\u53d1\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02", "motivation": "RISC-V\u5904\u7406\u5668\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9FireSim\u6a21\u62df\u5668\u6027\u80fd\u9884\u6d4b\u51c6\u786e\u6027\u7684\u7cfb\u7edf\u8bc4\u4f30", "method": "\u4f7f\u7528FireSim\u6846\u67b6\u6a21\u62df\u5546\u7528RISC-V\u5355\u677f\u8ba1\u7b97\u673a\u548c\u684c\u9762\u7ea7CPU\uff0c\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u5355\u6838\u548c\u56db\u6838\u914d\u7f6e\u4e0b\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u5e76\u4f7f\u7528\u4ee3\u8868\u6027\u5e94\u7528\u548cLAMMPS\u5206\u5b50\u52a8\u529b\u5b66\u4ee3\u7801\u8fdb\u884c\u8bc4\u4f30", "result": "FireSim\u80fd\u591f\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u67b6\u6784\u6027\u80fd\u8d8b\u52bf\u6d1e\u5bdf\uff0c\u4f46\u6a21\u62df\u8fd0\u884c\u65f6\u95f4\u4e0e\u5b9e\u6d4b\u7ed3\u679c\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02", "conclusion": "\u6a21\u62df\u73af\u5883\u7684\u56fa\u6709\u5c40\u9650\u6027\u548cCPU\u5236\u9020\u5546\u63d0\u4f9b\u7684\u8be6\u7ec6\u6027\u80fd\u89c4\u683c\u6709\u9650\uff0c\u963b\u788d\u4e86\u7cbe\u786e\u7684\u914d\u7f6e\u5339\u914d\uff0c\u5bfc\u81f4\u6027\u80fd\u9884\u6d4b\u5b58\u5728\u504f\u5dee"}}
{"id": "2509.18808", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18808", "abs": "https://arxiv.org/abs/2509.18808", "authors": ["Zexun Zhan", "Shuzheng Gao", "Ruida Hu", "Cuiyun Gao"], "title": "SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration. However, existing benchmarks mainly formalize the task as a static,\nsingle-turn problem, overlooking the stepwise requirement changes and iterative\nworkflows in real-world software development. This mismatch limits the\nunderstanding of how well LLMs can support real-world development workflows.\nConstructing such iterative benchmarks is challenging due to the lack of public\ninteraction traces and the difficulty of creating discriminative, turn-specific\ntest cases.\n  To bridge this gap, we present SR-Eval, a benchmark specifically designed to\nassess LLMs on iterative code generation under Stepwise requirements\nRefinement. SR-Eval spans both function-level and repository-level tasks in\nPython and Java, enabling fine-grained and progressive evaluation across\nevolving requirements. The construction of SR-Eval follows a carefully designed\npipeline that first leverages a multi-agent-based requirement generation method\nto simulate the development process and recover the multi-round interaction\nprocess from final requirements, then employs a semantic-aware discriminative\ntest case generation component to ensure discriminative and consistent\nevaluation at each turn. SR-Eval comprises 443 multi-turn tasks and 1,857\nquestions at both function and repository levels. Using SR-Eval, we evaluate 11\nrepresentative LLMs with three prompting strategies that simulate different\nusage patterns. Results show that iterative code generation under stepwise\nrequirement refinement remains highly challenging: the best-performing model\nachieves only 22.67% completion rate on function-level tasks and 20.00% on\nrepository-level tasks. We further observe that prompting strategies\nsubstantially influence performance, highlighting the need for the development\nof advanced methods.", "AI": {"tldr": "SR-Eval\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6Python\u548cJava\u7684\u51fd\u6570\u7ea7\u548c\u4ed3\u5e93\u7ea7\u4efb\u52a1\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4ecd\u4e0d\u7406\u60f3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5c06\u4ee3\u7801\u751f\u6210\u89c6\u4e3a\u9759\u6001\u5355\u8f6e\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9010\u6b65\u9700\u6c42\u53d8\u5316\u548c\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8fd9\u9650\u5236\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u771f\u5b9e\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u80fd\u529b\u7684\u7406\u89e3\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u9700\u6c42\u751f\u6210\u65b9\u6cd5\u6a21\u62df\u5f00\u53d1\u8fc7\u7a0b\uff0c\u4ece\u6700\u7ec8\u9700\u6c42\u6062\u590d\u591a\u8f6e\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u7528\u8bed\u4e49\u611f\u77e5\u7684\u5224\u522b\u6027\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7ec4\u4ef6\u786e\u4fdd\u6bcf\u8f6e\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u548c\u5224\u522b\u6027\u3002", "result": "\u8bc4\u4f3011\u4e2a\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\u540e\u53d1\u73b0\uff0c\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u7684\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u4ecd\u7136\u6781\u5177\u6311\u6218\u6027\uff1a\u6700\u4f73\u6a21\u578b\u5728\u51fd\u6570\u7ea7\u4efb\u52a1\u4e0a\u4ec5\u8fbe\u523022.67%\u5b8c\u6210\u7387\uff0c\u5728\u4ed3\u5e93\u7ea7\u4efb\u52a1\u4e0a\u4e3a20.00%\u3002", "conclusion": "\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u4ecd\u7136\u662f\u4e00\u4e2a\u9ad8\u5ea6\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u63d0\u793a\u7b56\u7565\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5148\u8fdb\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5728\u6b64\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2509.18886", "categories": ["cs.PF", "cs.AR", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18886", "abs": "https://arxiv.org/abs/2509.18886", "authors": ["Marcin Chrapek", "Marcin Copik", "Etienne Mettaz", "Torsten Hoefler"], "title": "Confidential LLM Inference: Performance and Cost Across CPU and GPU TEEs", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed on converged Cloud and\nHigh-Performance Computing (HPC) infrastructure. However, as LLMs handle\nconfidential inputs and are fine-tuned on costly, proprietary datasets, their\nheightened security requirements slow adoption in privacy-sensitive sectors\nsuch as healthcare and finance. We investigate methods to address this gap and\npropose Trusted Execution Environments (TEEs) as a solution for securing\nend-to-end LLM inference. We validate their practicality by evaluating these\ncompute-intensive workloads entirely within CPU and GPU TEEs. On the CPU side,\nwe conduct an in-depth study running full Llama2 inference pipelines (7B, 13B,\n70B) inside Intel's TDX and SGX, accelerated by Advanced Matrix Extensions\n(AMX). We derive 12 insights, including that across various data types, batch\nsizes, and input lengths, CPU TEEs impose under 10% throughput and 20% latency\noverheads, further reduced by AMX. We run LLM inference on NVIDIA H100\nConfidential Compute GPUs, contextualizing our CPU findings and observing\nthroughput penalties of 4-8% that diminish as batch and input sizes grow. By\ncomparing performance, cost, and security trade-offs, we show how CPU TEEs can\nbe more cost-effective or secure than their GPU counterparts. To our knowledge,\nour work is the first to comprehensively demonstrate the performance and\npracticality of modern TEEs across both CPUs and GPUs for enabling confidential\nLLMs (cLLMs).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728CPU\u548cGPU\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u8fd0\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u73b0\u4ee3TEE\u6280\u672f\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u6027\u80fd\u5f00\u9500(CPU<10%\uff0cGPU4-8%)\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u673a\u5bc6LLM\u63a8\u7406", "motivation": "\u968f\u7740LLM\u5904\u7406\u673a\u5bc6\u8f93\u5165\u5e76\u5728\u6602\u8d35\u7684\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5176\u5b89\u5168\u9700\u6c42\u963b\u788d\u4e86\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u9690\u79c1\u654f\u611f\u884c\u4e1a\u7684\u5e94\u7528\uff0c\u9700\u8981\u5bfb\u627e\u89e3\u51b3\u65b9\u6848\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd", "method": "\u4f7f\u7528Intel TDX\u548cSGX CPU TEE\u4ee5\u53caNVIDIA H100\u673a\u5bc6\u8ba1\u7b97GPU TEE\uff0c\u8bc4\u4f30\u5b8c\u6574\u7684Llama2\u63a8\u7406\u7ba1\u9053(7B\u300113B\u300170B)\uff0c\u5e76\u901a\u8fc7\u9ad8\u7ea7\u77e9\u9635\u6269\u5c55(AMX)\u8fdb\u884c\u52a0\u901f", "result": "CPU TEE\u5728\u5404\u79cd\u6570\u636e\u7c7b\u578b\u3001\u6279\u5927\u5c0f\u548c\u8f93\u5165\u957f\u5ea6\u4e0b\u65bd\u52a0\u4f4e\u4e8e10%\u7684\u541e\u5410\u91cf\u548c20%\u7684\u5ef6\u8fdf\u5f00\u9500\uff0cAMX\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u8fd9\u4e9b\u5f00\u9500\uff1bGPU TEE\u7684\u541e\u5410\u91cf\u60e9\u7f5a\u4e3a4-8%\uff0c\u968f\u7740\u6279\u5904\u7406\u548c\u8f93\u5165\u5927\u5c0f\u7684\u589e\u957f\u800c\u51cf\u5c11", "conclusion": "\u901a\u8fc7\u6bd4\u8f83\u6027\u80fd\u3001\u6210\u672c\u548c\u5b89\u5168\u6027\u6743\u8861\uff0cCPU TEE\u53ef\u4ee5\u6bd4GPU TEE\u66f4\u5177\u6210\u672c\u6548\u76ca\u6216\u66f4\u5b89\u5168\uff0c\u8fd9\u662f\u9996\u4e2a\u5168\u9762\u5c55\u793a\u73b0\u4ee3TEE\u5728CPU\u548cGPU\u4e0a\u5b9e\u73b0\u673a\u5bc6LLM\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u7684\u5de5\u4f5c"}}
{"id": "2509.18735", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18735", "abs": "https://arxiv.org/abs/2509.18735", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Muhammad Ali Jamshed", "Dean F. Hougen", "John M. Cioffi"], "title": "6G Twin: Hybrid Gaussian Radio Fields for Channel Estimation and Non-Linear Precoder Design for Radio Access Networks", "comment": "Submitted to IEEE Transactions on Wireless Communications", "summary": "This work introduces 6G Twin, the first end-to-end artificial intelligence\n(AI)-native radio access network (RAN) design that unifies (i) neural Gaussian\nRadio Fields (GRF) for compressed channel state information (CSI) acquisition,\n(ii) continual channel prediction with handover persistence, and (iii) an\nenergy-optimal nonlinear precoder (minPMAC). GRF replaces dense pilots with a\nsparse Gaussian field, cutting pilot overhead by about 100x while delivering\n1.1 ms inference and less than 2 minutes on-site training, thus enabling\nmillisecond-scale closed-loop operation. A replay-driven continual learner\nsustains accuracy under mobility and cell transitions, improving channel\nnormalized mean square error (NMSE) by more than 10 dB over frozen predictors\nand an additional 2-5 dB over uniform replay, thereby stabilizing performance\nacross UMi/UMa handovers. Finally, minPMAC solves a convex, order-free MAC\nprecoder design that recovers the globally optimal order from Broadcast Channel\n(BC) duals and minimizes transmit energy subject to minimum-rate guarantees,\nachieving 4-10 times lower energy (scenario dependent) with monotonically\nincreasing bits per joule as SNR grows. This translates to up to 5 times higher\ndata rate at comparable power or the same rates at substantially lower power.\nTogether, these components form a practical, GPU-ready framework that attains\nreal-time CSI, robust tracking in dynamic networks with efficient handovers,\nand state-of-the-art throughput-energy tradeoffs under 3GPP-style settings.", "AI": {"tldr": "6G Twin\u662f\u9996\u4e2a\u7aef\u5230\u7aefAI\u539f\u751f\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u8bbe\u8ba1\uff0c\u901a\u8fc7\u795e\u7ecf\u9ad8\u65af\u65e0\u7ebf\u7535\u573a\u538b\u7f29CSI\u83b7\u53d6\u3001\u6301\u7eed\u4fe1\u9053\u9884\u6d4b\u548c\u80fd\u91cf\u6700\u4f18\u975e\u7ebf\u6027\u9884\u7f16\u7801\u5668\uff0c\u5b9e\u73b0100\u500d\u5bfc\u9891\u5f00\u9500\u524a\u51cf\u3001\u6beb\u79d2\u7ea7\u95ed\u73af\u64cd\u4f5c\u548c4-10\u500d\u80fd\u91cf\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edfRAN\u7cfb\u7edf\u4e2d\u9ad8\u5bfc\u9891\u5f00\u9500\u3001\u79fb\u52a8\u6027\u7ba1\u7406\u56f0\u96be\u548c\u80fd\u91cf\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684AI\u539f\u751f\u6846\u67b6\u6765\u5b9e\u73b0\u5b9e\u65f6CSI\u83b7\u53d6\u3001\u9c81\u68d2\u8ddf\u8e2a\u548c\u6700\u4f18\u80fd\u91cf\u6548\u7387\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u9ad8\u65af\u65e0\u7ebf\u7535\u573a(GRF)\u538b\u7f29CSI\u83b7\u53d6\uff0c\u6301\u7eed\u5b66\u4e60\u5668\u5904\u7406\u79fb\u52a8\u6027\u548c\u5c0f\u533a\u5207\u6362\uff0c\u4ee5\u53caminPMAC\u975e\u7ebf\u6027\u9884\u7f16\u7801\u5668\u8fdb\u884c\u80fd\u91cf\u6700\u4f18\u9884\u7f16\u7801\u8bbe\u8ba1\u3002", "result": "\u5b9e\u73b0100\u500d\u5bfc\u9891\u5f00\u9500\u524a\u51cf\u30011.1ms\u63a8\u7406\u65f6\u95f4\u3001\u5c0f\u4e8e2\u5206\u949f\u73b0\u573a\u8bad\u7ec3\u300110dB\u4ee5\u4e0aNMSE\u6539\u8fdb\u30014-10\u500d\u80fd\u91cf\u964d\u4f4e\u548c5\u500d\u6570\u636e\u7387\u63d0\u5347\u3002", "conclusion": "6G Twin\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684GPU\u5c31\u7eea\u6846\u67b6\uff0c\u57283GPP\u6807\u51c6\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u5b9e\u65f6CSI\u3001\u52a8\u6001\u7f51\u7edc\u4e2d\u7684\u9c81\u68d2\u8ddf\u8e2a\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u541e\u5410\u91cf-\u80fd\u91cf\u6743\u8861\u3002"}}
{"id": "2509.19136", "categories": ["cs.SE", "cs.AI", "D.2.4; D.2.5; F.3.1"], "pdf": "https://arxiv.org/pdf/2509.19136", "abs": "https://arxiv.org/abs/2509.19136", "authors": ["S\u00e9bastien Salva", "Redha Taguelmimt"], "title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "comment": null, "summary": "The use of natural language (NL) test cases for validating graphical user\ninterface (GUI) applications is emerging as a promising direction to manually\nwritten executable test scripts, which are costly to develop and difficult to\nmaintain. Recent advances in large language models (LLMs) have opened the\npossibility of the direct execution of NL test cases by LLM agents. This paper\ninvestigates this direction, focusing on the impact on NL test case unsoundness\nand on test case execution consistency. NL test cases are inherently unsound,\nas they may yield false failures due to ambiguous instructions or unpredictable\nagent behaviour. Furthermore, repeated executions of the same NL test case may\nlead to inconsistent outcomes, undermining test reliability. To address these\nchallenges, we propose an algorithm for executing NL test cases with guardrail\nmechanisms and specialised agents that dynamically verify the correct execution\nof each test step. We introduce measures to evaluate the capabilities of LLMs\nin test execution and one measure to quantify execution consistency. We propose\na definition of weak unsoundness to characterise contexts in which NL test case\nexecution remains acceptable, with respect to the industrial quality levels Six\nSigma. Our experimental evaluation with eight publicly available LLMs, ranging\nfrom 3B to 70B parameters, demonstrates both the potential and current\nlimitations of current LLM agents for GUI testing. Our experiments show that\nMeta Llama 3.1 70B demonstrates acceptable capabilities in NL test case\nexecution with high execution consistency (above the level 3-sigma). We provide\nprototype tools, test suites, and results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u76f4\u63a5\u6267\u884c\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7684\u53ef\u884c\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u6d4b\u8bd5\u7528\u4f8b\u7684\u4e0d\u5065\u5168\u6027\u548c\u6267\u884c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u9632\u62a4\u673a\u5236\u7684\u7b97\u6cd5\u6765\u63d0\u9ad8GUI\u6d4b\u8bd5\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u624b\u5199\u53ef\u6267\u884c\u6d4b\u8bd5\u811a\u672c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u7ef4\u62a4\uff0c\u800c\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7684\u6267\u884c\u5b58\u5728\u4e0d\u5065\u5168\u6027\u548c\u6267\u884c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u6765\u63d0\u5347GUI\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u9632\u62a4\u673a\u5236\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e13\u95e8\u7684\u4ee3\u7406\u52a8\u6001\u9a8c\u8bc1\u6bcf\u4e2a\u6d4b\u8bd5\u6b65\u9aa4\u7684\u6b63\u786e\u6267\u884c\uff0c\u5e76\u5f15\u5165\u4e86\u8bc4\u4f30LLM\u6d4b\u8bd5\u6267\u884c\u80fd\u529b\u7684\u6307\u6807\u548c\u6267\u884c\u4e00\u81f4\u6027\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cMeta Llama 3.1 70B\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u6267\u884c\u65b9\u9762\u8868\u73b0\u51fa\u53ef\u63a5\u53d7\u7684\u80fd\u529b\uff0c\u6267\u884c\u4e00\u81f4\u6027\u9ad8\u4e8e3-sigma\u6c34\u5e73\u3002", "conclusion": "\u5f53\u524dLLM\u4ee3\u7406\u5728GUI\u6d4b\u8bd5\u4e2d\u5177\u6709\u6f5c\u529b\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u6307\u6807\u4e3a\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7684\u6267\u884c\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u548c\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2509.19027", "categories": ["cs.PF", "cs.AR", "68M20, 60J10", "C.1.1; C.4"], "pdf": "https://arxiv.org/pdf/2509.19027", "abs": "https://arxiv.org/abs/2509.19027", "authors": ["Faruk Alpay", "Hamdi Alakkad"], "title": "Glass-Box Analysis for Computer Systems: Transparency Index, Shapley Attribution, and Markov Models of Branch Prediction", "comment": "20 pages, 2 figures, 3 tables, 1 pseudocode", "summary": "We formalize glass-box analysis for computer systems and introduce three\nprincipled tools. First, the Glass-Box Transparency Index (GTI) quantifies the\nfraction of performance variance explainable by internal features and comes\nequipped with bounds, invariances, cross-validated estimation, and bootstrap\nconfidence intervals. Second, Explainable Throughput Decomposition (ETD) uses\nShapley values to provide an efficiency-preserving attribution of throughput,\ntogether with non-asymptotic Monte Carlo error guarantees and convexity\n(Jensen) gap bounds. Third, we develop an exact Markov analytic framework for\nbranch predictors, including a closed-form misprediction rate for a two-bit\nsaturating counter under a two-state Markov branch process and its i.i.d.\ncorollary. Additionally, we establish an identifiability theorem for recovering\nevent rates from aggregated hardware counters and provide stability bounds\nunder noise.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u73bb\u7483\u76d2\u5206\u6790\u5de5\u5177\uff1aGTI\u91cf\u5316\u6027\u80fd\u65b9\u5dee\u53ef\u89e3\u91ca\u6bd4\u4f8b\uff0cETD\u4f7f\u7528Shapley\u503c\u8fdb\u884c\u541e\u5410\u91cf\u5f52\u56e0\uff0c\u4ee5\u53ca\u5206\u652f\u9884\u6d4b\u5668\u7684\u7cbe\u786e\u9a6c\u5c14\u53ef\u592b\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u8ba1\u7b97\u673a\u7cfb\u7edf\u8fdb\u884c\u900f\u660e\u5316\u5206\u6790\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u91cf\u5316\u5185\u90e8\u7279\u5f81\u5bf9\u6027\u80fd\u5f71\u54cd\u7684\u65b9\u6cd5\u8bba\u548c\u5de5\u5177\u3002", "method": "1) \u5f00\u53d1Glass-Box Transparency Index (GTI)\u91cf\u5316\u6027\u80fd\u65b9\u5dee\u89e3\u91ca\u6bd4\u4f8b\uff1b2) \u4f7f\u7528Shapley\u503c\u7684Explainable Throughput Decomposition (ETD)\u8fdb\u884c\u541e\u5410\u91cf\u5f52\u56e0\uff1b3) \u5efa\u7acb\u5206\u652f\u9884\u6d4b\u5668\u7684\u7cbe\u786e\u9a6c\u5c14\u53ef\u592b\u5206\u6790\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e09\u79cd\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u5206\u6790\u5de5\u5177\uff1aGTI\u5e26\u6709\u8fb9\u754c\u548c\u7f6e\u4fe1\u533a\u95f4\uff0cETD\u63d0\u4f9b\u8bef\u5dee\u4fdd\u8bc1\u548c\u51f8\u6027\u95f4\u9699\u8fb9\u754c\uff0c\u5206\u652f\u9884\u6d4b\u5206\u6790\u6846\u67b6\u5305\u542b\u95ed\u5f0f\u89e3\u548c\u53ef\u8bc6\u522b\u6027\u5b9a\u7406\u3002", "conclusion": "\u8fd9\u4e9b\u5de5\u5177\u4e3a\u8ba1\u7b97\u673a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u73bb\u7483\u76d2\u5206\u6790\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4e25\u8c28\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.18869", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18869", "abs": "https://arxiv.org/abs/2509.18869", "authors": ["Baiqiang Wang", "Dongfang Zhao", "Nathan R Tallent", "Luanzheng Guo"], "title": "On The Reproducibility Limitations of RAG Systems", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is increasingly employed in generative\nAI-driven scientific workflows to integrate rapidly evolving scientific\nknowledge bases, yet its reliability is frequently compromised by\nnon-determinism in their retrieval components. This paper introduces ReproRAG,\na comprehensive benchmarking framework designed to systematically measure and\nquantify the reproducibility of vector-based retrieval systems. ReproRAG\ninvestigates sources of uncertainty across the entire pipeline, including\ndifferent embedding models, precision, retrieval algorithms, hardware\nconfigurations, and distributed execution environments. Utilizing a suite of\nmetrics, such as Exact Match Rate, Jaccard Similarity, and Kendall's Tau, the\nproposed framework effectively characterizes the trade-offs between\nreproducibility and performance. Our large-scale empirical study reveals\ncritical insights; for instance, we observe that different embedding models\nhave remarkable impact on RAG reproducibility. The open-sourced ReproRAG\nframework provides researchers and engineers productive tools to validate\ndeployments, benchmark reproducibility, and make informed design decisions,\nthereby fostering more trustworthy AI for science.", "AI": {"tldr": "ReproRAG\u662f\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u53ef\u91cd\u73b0\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5d4c\u5165\u6a21\u578b\u3001\u7cbe\u5ea6\u3001\u68c0\u7d22\u7b97\u6cd5\u7b49\u591a\u4e2a\u56e0\u7d20\u5bf9RAG\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd", "motivation": "RAG\u5728\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u68c0\u7d22\u7ec4\u4ef6\u7684\u975e\u786e\u5b9a\u6027\u7ecf\u5e38\u5f71\u54cd\u53ef\u9760\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u65b9\u6cd5\u6765\u91cf\u5316\u548c\u6539\u8fdb\u53ef\u91cd\u73b0\u6027", "method": "\u63d0\u51faReproRAG\u6846\u67b6\uff0c\u4f7f\u7528\u7cbe\u786e\u5339\u914d\u7387\u3001Jaccard\u76f8\u4f3c\u5ea6\u3001Kendall's Tau\u7b49\u6307\u6807\uff0c\u5168\u9762\u5206\u6790\u5d4c\u5165\u6a21\u578b\u3001\u7cbe\u5ea6\u3001\u68c0\u7d22\u7b97\u6cd5\u3001\u786c\u4ef6\u914d\u7f6e\u548c\u5206\u5e03\u5f0f\u73af\u5883\u7b49\u56e0\u7d20", "result": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u663e\u793a\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u5bf9RAG\u53ef\u91cd\u73b0\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u6846\u67b6\u6709\u6548\u63ed\u793a\u4e86\u53ef\u91cd\u73b0\u6027\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb", "conclusion": "\u5f00\u6e90\u7684ReproRAG\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u90e8\u7f72\u3001\u57fa\u51c6\u6d4b\u8bd5\u53ef\u91cd\u73b0\u6027\u548c\u505a\u51fa\u660e\u667a\u8bbe\u8ba1\u51b3\u7b56\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u4fe1\u7684\u79d1\u5b66AI"}}
{"id": "2509.19185", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.19185", "abs": "https://arxiv.org/abs/2509.19185", "authors": ["Mohammed Mehedi Hasan", "Hao Li", "Emad Fallahzadeh", "Gopi Krishnan Rajbahadur", "Bram Adams", "Ahmed E. Hassan"], "title": "An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications", "comment": null, "summary": "Foundation model (FM)-based AI agents are rapidly gaining adoption across\ndiverse domains, but their inherent non-determinism and non-reproducibility\npose testing and quality assurance challenges. While recent benchmarks provide\ntask-level evaluations, there is limited understanding of how developers verify\nthe internal correctness of these agents during development.\n  To address this gap, we conduct the first large-scale empirical study of\ntesting practices in the AI agent ecosystem, analyzing 39 open-source agent\nframeworks and 439 agentic applications. We identify ten distinct testing\npatterns and find that novel, agent-specific methods like DeepEval are seldom\nused (around 1%), while traditional patterns like negative and membership\ntesting are widely adapted to manage FM uncertainty. By mapping these patterns\nto canonical architectural components of agent frameworks and agentic\napplications, we uncover a fundamental inversion of testing effort:\ndeterministic components like Resource Artifacts (tools) and Coordination\nArtifacts (workflows) consume over 70% of testing effort, while the FM-based\nPlan Body receives less than 5%. Crucially, this reveals a critical blind spot,\nas the Trigger component (prompts) remains neglected, appearing in around 1% of\nall tests.\n  Our findings offer the first empirical testing baseline in FM-based agent\nframeworks and agentic applications, revealing a rational but incomplete\nadaptation to non-determinism. To address it, framework developers should\nimprove support for novel testing methods, application developers must adopt\nprompt regression testing, and researchers should explore barriers to adoption.\nStrengthening these practices is vital for building more robust and dependable\nAI agents.", "AI": {"tldr": "\u5bf939\u4e2a\u5f00\u6e90AI\u4ee3\u7406\u6846\u67b6\u548c439\u4e2a\u4ee3\u7406\u5e94\u7528\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\uff0c\u5f00\u53d1\u8005\u4e3b\u8981\u4f7f\u7528\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\uff08\u5982\u8d1f\u9762\u6d4b\u8bd5\u548c\u6210\u5458\u6d4b\u8bd5\uff09\u6765\u7ba1\u7406\u57fa\u7840\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u975e\u786e\u5b9a\u6027\u7ec4\u4ef6\u6d88\u8017\u4e86\u8d85\u8fc770%\u7684\u6d4b\u8bd5\u5de5\u4f5c\u91cf\uff0c\u800c\u5173\u952e\u7684\u89e6\u53d1\u7ec4\u4ef6\uff08\u63d0\u793a\u8bcd\uff09\u6d4b\u8bd5\u4ec5\u5360\u7ea61%\uff0c\u5b58\u5728\u4e25\u91cd\u76f2\u533a\u3002", "motivation": "\u57fa\u7840\u6a21\u578bAI\u4ee3\u7406\u7684\u975e\u786e\u5b9a\u6027\u548c\u4e0d\u53ef\u91cd\u73b0\u6027\u7ed9\u6d4b\u8bd5\u548c\u8d28\u91cf\u4fdd\u8bc1\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u7ea7\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5bf9\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5185\u90e8\u6b63\u786e\u6027\u9a8c\u8bc1\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5bf939\u4e2a\u5f00\u6e90\u4ee3\u7406\u6846\u67b6\u548c439\u4e2a\u4ee3\u7406\u5e94\u7528\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u51fa\u5341\u79cd\u4e0d\u540c\u7684\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6a21\u5f0f\u6620\u5c04\u5230\u4ee3\u7406\u6846\u67b6\u548c\u5e94\u7528\u7684\u5178\u578b\u67b6\u6784\u7ec4\u4ef6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f20\u7edf\u6d4b\u8bd5\u6a21\u5f0f\u88ab\u5e7f\u6cdb\u91c7\u7528\uff08\u5982\u8d1f\u9762\u6d4b\u8bd5\u548c\u6210\u5458\u6d4b\u8bd5\uff09\uff0c\u800c\u65b0\u578b\u4ee3\u7406\u7279\u5b9a\u65b9\u6cd5\uff08\u5982DeepEval\uff09\u4f7f\u7528\u7387\u5f88\u4f4e\uff08\u7ea61%\uff09\u3002\u6d4b\u8bd5\u5de5\u4f5c\u91cf\u5b58\u5728\u6839\u672c\u6027\u5012\u7f6e\uff1a\u786e\u5b9a\u6027\u7ec4\u4ef6\u6d88\u801770%\u4ee5\u4e0a\u6d4b\u8bd5\u5de5\u4f5c\u91cf\uff0c\u800c\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u8ba1\u5212\u4e3b\u4f53\u6d4b\u8bd5\u4e0d\u52305%\uff0c\u89e6\u53d1\u7ec4\u4ef6\u6d4b\u8bd5\u4ec5\u53601%\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5728\u975e\u786e\u5b9a\u6027\u9002\u5e94\u65b9\u9762\u7684\u7406\u6027\u4f46\u4e0d\u5b8c\u6574\u7684\u8c03\u6574\uff0c\u5efa\u8bae\u6846\u67b6\u5f00\u53d1\u8005\u6539\u8fdb\u65b0\u578b\u6d4b\u8bd5\u65b9\u6cd5\u7684\u652f\u6301\uff0c\u5e94\u7528\u5f00\u53d1\u8005\u5e94\u91c7\u7528\u63d0\u793a\u56de\u5f52\u6d4b\u8bd5\uff0c\u7814\u7a76\u4eba\u5458\u5e94\u63a2\u7d22\u91c7\u7528\u969c\u788d\uff0c\u4ee5\u6784\u5efa\u66f4\u5065\u58ee\u53ef\u9760\u7684AI\u4ee3\u7406\u3002"}}
{"id": "2509.18957", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.18957", "abs": "https://arxiv.org/abs/2509.18957", "authors": ["Shengye Song", "Minxian Xu", "Kan Hu", "Wenxia Guo", "Kejiang Ye"], "title": "TD3-Sched: Learning to Orchestrate Container-based Cloud-Edge Resources via Distributed Reinforcement Learning", "comment": "14 pages, 5 figures", "summary": "Resource scheduling in cloud-edge systems is challenging as edge nodes run\nlatency-sensitive workloads under tight resource constraints, while existing\ncentralized schedulers can suffer from performance bottlenecks and user\nexperience degradation. To address the issues of distributed decisions in\ncloud-edge environments, we present TD3-Sched, a distributed reinforcement\nlearning (DRL) scheduler based on Twin Delayed Deep Deterministic Policy\nGradient (TD3) for continuous control of CPU and memory allocation, which can\nachieve optimized decisions for resource provisioning under dynamic workloads.\nOn a realistic cloud-edge testbed with SockShop application and Alibaba traces,\nTD3-Sched achieves reductions of 17.9% to 38.6% in latency under same loads\ncompared with other reinforcement-learning and rule-based baselines, and 16% to\n31.6% under high loads. TD3-Sched also shows superior Service Level Objective\n(SLO) compliance with only 0.47% violations. These results indicate faster\nconvergence, lower latency, and more stable performance while preserving\nservice quality in container-based cloud-edge environment compared with the\nbaselines.", "AI": {"tldr": "TD3-Sched\u662f\u57fa\u4e8eTD3\u7b97\u6cd5\u7684\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u8c03\u5ea6\u5668\uff0c\u5728\u4e91\u8fb9\u73af\u5883\u4e2d\u5b9e\u73b0CPU\u548c\u5185\u5b58\u8d44\u6e90\u7684\u8fde\u7eed\u63a7\u5236\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u9ad8SLO\u5408\u89c4\u6027", "motivation": "\u89e3\u51b3\u4e91\u8fb9\u7cfb\u7edf\u4e2d\u8fb9\u7f18\u8282\u70b9\u8fd0\u884c\u5ef6\u8fdf\u654f\u611f\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u7684\u8d44\u6e90\u8c03\u5ea6\u6311\u6218\uff0c\u907f\u514d\u96c6\u4e2d\u5f0f\u8c03\u5ea6\u5668\u7684\u6027\u80fd\u74f6\u9888\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\u95ee\u9898", "method": "\u57fa\u4e8eTwin Delayed Deep Deterministic Policy Gradient (TD3)\u7b97\u6cd5\u7684\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8eCPU\u548c\u5185\u5b58\u5206\u914d\u7684\u8fde\u7eed\u63a7\u5236", "result": "\u5728\u771f\u5b9e\u4e91\u8fb9\u6d4b\u8bd5\u5e73\u53f0\u4e0a\uff0c\u76f8\u6bd4\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u76f8\u540c\u8d1f\u8f7d\u4e0b\u5ef6\u8fdf\u964d\u4f4e17.9%-38.6%\uff0c\u9ad8\u8d1f\u8f7d\u4e0b\u964d\u4f4e16%-31.6%\uff0cSLO\u8fdd\u89c4\u7387\u4ec5\u4e3a0.47%", "conclusion": "TD3-Sched\u5728\u5bb9\u5668\u5316\u4e91\u8fb9\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u670d\u52a1\u8d28\u91cf"}}
{"id": "2509.19086", "categories": ["cs.DC", "D.4.1; C.4; C.1.4; D.1.3"], "pdf": "https://arxiv.org/pdf/2509.19086", "abs": "https://arxiv.org/abs/2509.19086", "authors": ["Michal Konopa", "Jan Fesl", "Ladislav Ber\u00e1nek"], "title": "Scheduler-Driven Job Atomization", "comment": "22 pages", "summary": "Modern GPU clusters, particularly those built on NVIDIA's Multi-Instance GPU\n(MIG) architecture, often suffer from inefficiencies because jobs are treated\nas rigid, indivisible blocks that occupy a fixed slice until completion. The\nreliance on static peak memory estimates exacerbates fragmentation,\nunderutilization, and job rejections. We propose Scheduler-Driven Job\nAtomization (SJA), a new paradigm that establishes a bidirectional interaction\nbetween scheduler and jobs. In SJA, the scheduler advertises available\nexecution gaps, and jobs respond by signaling interest if they can potentially\ngenerate a subjob that fits the offered time-capacity window. The scheduler may\ncollect multiple signals for the same slot and, based on its allocation policy\n(e.g., fairness, efficiency, or SLA priorities), selects which job is granted\nthe slot. Only then does the chosen job materialize a safe, self-contained\nsubjob tailored to that opportunity. Unlike migration or preemption, SJA\nproactively shapes workloads before execution, thereby avoiding costly state\ntransfers and unpredictable interruptions. It aims to increase GPU utilization,\nreduce wait times, and minimize migration overhead by aligning jobs with\nopportunities in real time, ensuring that each admitted subjob is correct by\nconstruction. This paper is presented as a concept paper: it introduces the\nparadigm, defines its building blocks, and outlines future research directions,\nrather than offering a full experimental evaluation.", "AI": {"tldr": "\u63d0\u51faSJA\u8c03\u5ea6\u5668\u9a71\u52a8\u4f5c\u4e1a\u539f\u5b50\u5316\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8c03\u5ea6\u5668\u4e0e\u4f5c\u4e1a\u53cc\u5411\u4ea4\u4e92\uff0c\u5c06\u4f5c\u4e1a\u5206\u89e3\u4e3a\u9002\u5408\u7a7a\u95f2\u65f6\u95f4\u7a97\u53e3\u7684\u5b50\u4f5c\u4e1a\uff0c\u63d0\u9ad8GPU\u96c6\u7fa4\u5229\u7528\u7387", "motivation": "\u73b0\u4ee3GPU\u96c6\u7fa4\uff08\u7279\u522b\u662f\u57fa\u4e8eNVIDIA MIG\u67b6\u6784\uff09\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u4f5c\u4e1a\u88ab\u89c6\u4e3a\u521a\u6027\u4e0d\u53ef\u5206\u5272\u5757\uff0c\u9759\u6001\u5cf0\u503c\u5185\u5b58\u4f30\u8ba1\u5bfc\u81f4\u788e\u7247\u5316\u3001\u5229\u7528\u7387\u4f4e\u548c\u4f5c\u4e1a\u62d2\u7edd", "method": "SJA\u5efa\u7acb\u8c03\u5ea6\u5668\u4e0e\u4f5c\u4e1a\u7684\u53cc\u5411\u4ea4\u4e92\uff1a\u8c03\u5ea6\u5668\u516c\u5e03\u53ef\u7528\u6267\u884c\u95f4\u9699\uff0c\u4f5c\u4e1a\u54cd\u5e94\u8868\u793a\u5174\u8da3\uff0c\u8c03\u5ea6\u5668\u57fa\u4e8e\u5206\u914d\u7b56\u7565\u9009\u62e9\u4f5c\u4e1a\u751f\u6210\u5b9a\u5236\u5b50\u4f5c\u4e1a", "result": "\u8be5\u65b9\u6cd5\u4e3b\u52a8\u5728\u6267\u884c\u524d\u5851\u9020\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u907f\u514d\u6602\u8d35\u7684\u72b6\u6001\u8f6c\u79fb\u548c\u4e0d\u53ef\u9884\u6d4b\u4e2d\u65ad\uff0c\u65e8\u5728\u63d0\u9ad8GPU\u5229\u7528\u7387\u3001\u51cf\u5c11\u7b49\u5f85\u65f6\u95f4\u548c\u6700\u5c0f\u5316\u8fc1\u79fb\u5f00\u9500", "conclusion": "SJA\u662f\u4e00\u79cd\u65b0\u7684\u8c03\u5ea6\u8303\u5f0f\uff0c\u901a\u8fc7\u5b9e\u65f6\u5c06\u4f5c\u4e1a\u4e0e\u673a\u4f1a\u5bf9\u9f50\u6765\u786e\u4fdd\u6bcf\u4e2a\u5b50\u4f5c\u4e1a\u7684\u6b63\u786e\u6027\uff0c\u672c\u6587\u4f5c\u4e3a\u6982\u5ff5\u8bba\u6587\u4ecb\u7ecd\u4e86\u8be5\u8303\u5f0f\u7684\u6784\u5efa\u6a21\u5757\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411"}}
{"id": "2509.19150", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.19150", "abs": "https://arxiv.org/abs/2509.19150", "authors": ["Harikrishna Tummalapalli", "Riccardo Balin", "Christine M. Simpson", "Andrew Park", "Aymen Alsaadi", "Andrew E. Shao", "Wesley Brewer", "Shantenu Jha"], "title": "In-Transit Data Transport Strategies for Coupled AI-Simulation Workflow Patterns", "comment": null, "summary": "Coupled AI-Simulation workflows are becoming the major workloads for HPC\nfacilities, and their increasing complexity necessitates new tools for\nperformance analysis and prototyping of new in-situ workflows. We present\nSimAI-Bench, a tool designed to both prototype and evaluate these coupled\nworkflows. In this paper, we use SimAI-Bench to benchmark the data transport\nperformance of two common patterns on the Aurora supercomputer: a one-to-one\nworkflow with co-located simulation and AI training instances, and a\nmany-to-one workflow where a single AI model is trained from an ensemble of\nsimulations. For the one-to-one pattern, our analysis shows that node-local and\nDragonHPC data staging strategies provide excellent performance compared Redis\nand Lustre file system. For the many-to-one pattern, we find that data\ntransport becomes a dominant bottleneck as the ensemble size grows. Our\nevaluation reveals that file system is the optimal solution among the tested\nstrategies for the many-to-one pattern.", "AI": {"tldr": "SimAI-Bench\u5de5\u5177\u7528\u4e8e\u8bc4\u4f30AI-\u6a21\u62df\u8026\u5408\u5de5\u4f5c\u6d41\u7684\u6570\u636e\u4f20\u8f93\u6027\u80fd\uff0c\u5728Aurora\u8d85\u7b97\u4e0a\u6d4b\u8bd5\u4e86\u4e24\u79cd\u5e38\u89c1\u6a21\u5f0f\uff1a\u4e00\u5bf9\u4e00\u548c\u4e00\u5bf9\u591a\u5de5\u4f5c\u6d41\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u5f0f\u4e0b\u6700\u4f18\u7684\u6570\u636e\u4f20\u8f93\u7b56\u7565\u4e0d\u540c", "motivation": "\u968f\u7740AI-\u6a21\u62df\u8026\u5408\u5de5\u4f5c\u6d41\u6210\u4e3aHPC\u4e3b\u8981\u8d1f\u8f7d\u4e14\u590d\u6742\u5ea6\u4e0d\u65ad\u589e\u52a0\uff0c\u9700\u8981\u65b0\u5de5\u5177\u6765\u8fdb\u884c\u6027\u80fd\u5206\u6790\u548c\u539f\u578b\u5f00\u53d1", "method": "\u4f7f\u7528SimAI-Bench\u5de5\u5177\u5728Aurora\u8d85\u7b97\u4e0a\u5bf9\u4e24\u79cd\u5e38\u89c1\u8026\u5408\u6a21\u5f0f\uff08\u4e00\u5bf9\u4e00\u548c\u4e00\u5bf9\u591a\uff09\u8fdb\u884c\u6570\u636e\u4f20\u8f93\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u6570\u636e\u4f20\u8f93\u7b56\u7565", "result": "\u4e00\u5bf9\u4e00\u6a21\u5f0f\u4e0b\uff0c\u8282\u70b9\u672c\u5730\u548cDragonHPC\u6570\u636e\u6682\u5b58\u7b56\u7565\u6027\u80fd\u4f18\u4e8eRedis\u548cLustre\u6587\u4ef6\u7cfb\u7edf\uff1b\u4e00\u5bf9\u591a\u6a21\u5f0f\u4e0b\uff0c\u6587\u4ef6\u7cfb\u7edf\u662f\u6d4b\u8bd5\u7b56\u7565\u4e2d\u7684\u6700\u4f18\u89e3\uff0c\u4f46\u6570\u636e\u4f20\u8f93\u968f\u96c6\u6210\u89c4\u6a21\u589e\u957f\u6210\u4e3a\u4e3b\u8981\u74f6\u9888", "conclusion": "\u4e0d\u540c\u8026\u5408\u5de5\u4f5c\u6d41\u6a21\u5f0f\u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u4f20\u8f93\u7b56\u7565\u4f18\u5316\uff0cSimAI-Bench\u662f\u8bc4\u4f30\u548c\u539f\u578b\u5f00\u53d1\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u7684\u6709\u7528\u5de5\u5177"}}
{"id": "2509.19187", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.19187", "abs": "https://arxiv.org/abs/2509.19187", "authors": ["J\u00e9r\u00e9mie Chalopin", "Yi-Jun Chang", "Lyuting Chen", "Giuseppe A. Di Luna", "Haoran Zhou"], "title": "Non-Uniform Content-Oblivious Leader Election on Oriented Asynchronous Rings", "comment": null, "summary": "We study the leader election problem in oriented ring networks under\ncontent-oblivious asynchronous message-passing systems, where an adversary may\narbitrarily corrupt message contents.\n  Frei et al. (DISC 2024) presented a uniform terminating leader election\nalgorithm for oriented rings in this setting, with message complexity $O(n\n\\cdot \\mathsf{ID}_{\\max})$ on a ring of size $n$, where $\\mathsf{ID}_{\\max}$ is\nthe largest identifier in the system, this result has been recently extended by\nChalopin et al. (DISC 2025) to unoriented rings.\n  In this paper, we investigate the message complexity of leader election on\nring networks in the content-oblivious model, showing that no uniform algorithm\ncan solve the problem if each process is limited to sending a constant number\nof messages in one direction.\n  Interestingly, this limitation hinges on the uniformity assumption. In the\nnon-uniform setting, where processes know an upper bound $U \\geq n$ on the ring\nsize, we present an algorithm with message complexity $O(n \\cdot U \\cdot\n\\mathsf{ID}_{\\min})$, in which each process sends $O(U \\cdot\n\\mathsf{ID}_{\\min})$ messages clockwise and only three messages\ncounter-clockwise. Here, $\\mathsf{ID}_{\\min}$ is the smallest identifier in the\nsystem. This dependence on the identifiers compares favorably with the\ndependence on $\\mathsf{ID}_{\\max}$ of Frei et al.\n  We also show a non-uniform algorithm where each process sends $O(U \\cdot\n\\log\\mathsf{ID}_{\\min})$ messages in one direction and\n$O(\\log\\mathsf{ID}_{\\min})$ in the other. The factor $\\log \\mathsf{ID}_{\\min}$\nis optimal, matching the lower bound of Frei et al.\n  Finally, in the anonymous setting, where processes do not have identifiers,\nwe propose a randomized algorithm where each process sends only $O(\\log^2 U)$\nmessages, with a success probability of $1 - U^{-c}$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9762\u5411\u73af\u7f51\u7edc\u4e2d\u5728\u5185\u5bb9\u4e0d\u53ef\u77e5\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u7cfb\u7edf\u4e0b\u7684\u9886\u5bfc\u8005\u9009\u4e3e\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u5747\u5300\u7b97\u6cd5\u4e2d\u5982\u679c\u6bcf\u4e2a\u8fdb\u7a0b\u53ea\u80fd\u53d1\u9001\u5e38\u6570\u6570\u91cf\u7684\u6d88\u606f\u5219\u65e0\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u4e2a\u975e\u5747\u5300\u7b97\u6cd5\u548c\u968f\u673a\u7b97\u6cd5\u6765\u4f18\u5316\u6d88\u606f\u590d\u6742\u5ea6\u3002", "motivation": "\u7814\u7a76\u5728\u6d88\u606f\u5185\u5bb9\u53ef\u80fd\u88ab\u6076\u610f\u7be1\u6539\u7684\u5185\u5bb9\u4e0d\u53ef\u77e5\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u7cfb\u7edf\u4e2d\uff0c\u9762\u5411\u73af\u7f51\u7edc\u7684\u9886\u5bfc\u8005\u9009\u4e3e\u95ee\u9898\u7684\u6d88\u606f\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u63a2\u7d22\u5728\u8fdb\u7a0b\u53d1\u9001\u6d88\u606f\u6570\u91cf\u53d7\u9650\u60c5\u51b5\u4e0b\u7684\u53ef\u884c\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u7b97\u6cd5\u8bbe\u8ba1\uff1a1) \u8bc1\u660e\u5747\u5300\u7b97\u6cd5\u5728\u5e38\u6570\u6d88\u606f\u9650\u5236\u4e0b\u7684\u4e0d\u53ef\u80fd\u6027\uff1b2) \u8bbe\u8ba1\u975e\u5747\u5300\u7b97\u6cd5\u5229\u7528\u73af\u5927\u5c0f\u4e0a\u754cU\u548c\u6700\u5c0f\u6807\u8bc6\u7b26ID_min\uff1b3) \u5f00\u53d1\u968f\u673a\u7b97\u6cd5\u7528\u4e8e\u533f\u540d\u8bbe\u7f6e\u3002", "result": "1) \u8bc1\u660e\u4e86\u5747\u5300\u7b97\u6cd5\u5728\u5e38\u6570\u6d88\u606f\u9650\u5236\u4e0b\u65e0\u6cd5\u89e3\u51b3\u9886\u5bfc\u8005\u9009\u4e3e\u95ee\u9898\uff1b2) \u63d0\u51fa\u4e86\u6d88\u606f\u590d\u6742\u5ea6\u4e3aO(n\u00b7U\u00b7ID_min)\u7684\u975e\u5747\u5300\u7b97\u6cd5\uff1b3) \u8bbe\u8ba1\u4e86\u6d88\u606f\u590d\u6742\u5ea6\u4e3aO(U\u00b7logID_min)\u7684\u4f18\u5316\u7b97\u6cd5\uff1b4) \u63d0\u51fa\u4e86\u533f\u540d\u8bbe\u7f6e\u4e0b\u7684\u968f\u673a\u7b97\u6cd5\uff0c\u6d88\u606f\u590d\u6742\u5ea6\u4e3aO(log\u00b2U)\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5747\u5300\u6027\u5047\u8bbe\u5bf9\u9886\u5bfc\u8005\u9009\u4e3e\u6d88\u606f\u590d\u6742\u5ea6\u7684\u91cd\u8981\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u591a\u4e2a\u9ad8\u6548\u7684\u975e\u5747\u5300\u548c\u968f\u673a\u7b97\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u73b0\u6709\u7ed3\u679c\u7684\u6d88\u606f\u590d\u6742\u5ea6\u4f9d\u8d56\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u6807\u8bc6\u7b26\u8f83\u5c0f\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2509.19294", "categories": ["cs.DC", "astro-ph.IM", "D.1.3; J.2"], "pdf": "https://arxiv.org/pdf/2509.19294", "abs": "https://arxiv.org/abs/2509.19294", "authors": ["Jenny Lynn Almerol", "Elisabetta Boella", "Mario Spera", "Daniele Gregori"], "title": "Accelerating Gravitational $N$-Body Simulations Using the RISC-V-Based Tenstorrent Wormhole", "comment": null, "summary": "Although originally developed primarily for artificial intelligence\nworkloads, RISC-V-based accelerators are also emerging as attractive platforms\nfor high-performance scientific computing. In this work, we present our\napproach to accelerating an astrophysical $N$-body code on the RISC-V-based\nWormhole n300 card developed by Tenstorrent. Our results show that this\nplatform can be highly competitive for astrophysical simulations employing this\nclass of algorithms, delivering more than a $2 \\times$ speedup and\napproximately $2 \\times$ energy savings compared to a highly optimized CPU\nimplementation of the same code.", "AI": {"tldr": "RISC-V\u52a0\u901f\u5668\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5929\u4f53\u7269\u7406N\u4f53\u4ee3\u7801\u5728Wormhole n300\u5361\u4e0a\u5b9e\u73b02\u500d\u901f\u5ea6\u63d0\u5347\u548c2\u500d\u8282\u80fd", "motivation": "\u867d\u7136RISC-V\u6700\u521d\u4e3aAI\u5de5\u4f5c\u8d1f\u8f7d\u8bbe\u8ba1\uff0c\u4f46\u5176\u5728\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u4e5f\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u5728\u5929\u4f53\u7269\u7406\u6a21\u62df\u4e2d\u7684\u6027\u80fd\u8868\u73b0", "method": "\u5c06\u5929\u4f53\u7269\u7406N\u4f53\u4ee3\u7801\u79fb\u690d\u5230Tenstorrent\u5f00\u53d1\u7684RISC-V\u67b6\u6784Wormhole n300\u52a0\u901f\u5361\u4e0a\uff0c\u5e76\u4e0e\u9ad8\u5ea6\u4f18\u5316\u7684CPU\u5b9e\u73b0\u8fdb\u884c\u5bf9\u6bd4", "result": "\u76f8\u6bd4\u4f18\u5316\u7684CPU\u5b9e\u73b0\uff0cRISC-V\u5e73\u53f0\u63d0\u4f9b\u8d85\u8fc72\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c\u7ea62\u500d\u7684\u80fd\u6e90\u8282\u7701", "conclusion": "RISC-V\u52a0\u901f\u5668\u5e73\u53f0\u5728\u5929\u4f53\u7269\u7406\u6a21\u62df\u7b97\u6cd5\u4e2d\u5177\u6709\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u662f\u9ad8\u6027\u80fd\u79d1\u5b66\u8ba1\u7b97\u7684\u6709\u529b\u9009\u62e9"}}
