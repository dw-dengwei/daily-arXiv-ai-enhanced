<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [PCCL: Photonic circuit-switched collective communication for distributed ML](https://arxiv.org/abs/2509.15450)
*Abhishek Vijaya Kumar,Arjun Devraj,Rachee Singh*

Main category: cs.DC

TL;DR: PCCL是一个光子集体通信库，通过动态重构网络拓扑来匹配集体通信算法的通信模式，消除拥塞和延迟，在128个GPU上实现3倍加速和1.3倍的端到端训练吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现代分布式机器学习存在理论性能与实际性能之间的差距，主要由于GPU集群中的拥塞和跳数引起的延迟问题。

Method: PCCL采用硬件无关的优化框架，智能决定何时重新配置网络，在网络重构延迟与拥塞/延迟成本之间进行权衡，为任何集体原语和拓扑创建直接、无争用的电路。

Result: 在128个GPU上的评估显示，PCCL在各种工作负载、缓冲区大小和拓扑上相比最先进算法实现了高达3倍的加速，端到端训练吞吐量提升1.3倍。

Conclusion: PCCL通过动态网络重构有效解决了分布式ML中的通信瓶颈问题，为不同光学硬件提供了实用的解决方案，显著提升了集体通信性能。

Abstract: Modern distributed ML suffers from a fundamental gap between the theoretical
and realized performance of collective communication algorithms due to
congestion and hop-count induced dilation in practical GPU clusters. We present
PCCL, a Photonic Collective Communication Library that reconfigures the network
topology to match the communication patterns of collective algorithms, thereby
eliminating congestion and dilation by creating direct, contention-free
circuits between communicating GPUs. Unlike prior approaches that synthesize
algorithms for specific network topologies and collectives, PCCL generalizes to
any collective primitive and any topology by adapting the network to match each
algorithm's communication pattern. PCCL's key innovation lies in its
hardware-agnostic optimization framework that intelligently decides when to
reconfigure based on the trade-off between network reconfiguration delay and
congestion/dilation costs, making it practical across different optical
hardware with varying switching speeds. Our evaluation demonstrates that PCCL
achieves up to 3X speedup over state-of-the-art algorithms on 128 GPUs across
various workloads, buffer sizes, and topologies, translating to a 1.3X speedup
in end-to-end training throughput.

</details>


### [2] [Angelfish: Consensus with Optimal Throughput and Latency Across the Leader-DAG Spectrum](https://arxiv.org/abs/2509.15847)
*Qianyu Yu,Giuliano Losa,Nibesh Shrestha,Xuechao Wang*

Main category: cs.DC

TL;DR: Angelfish是一种混合共识协议，结合了领导者驱动和DAG驱动两种方法的优势，在保持高吞吐量的同时实现了低延迟


<details>
  <summary>Details</summary>
Motivation: 现有区块链共识协议在延迟和吞吐量之间存在权衡：领导者驱动协议延迟低但吞吐量有限，DAG驱动协议吞吐量高但延迟较差。需要一种能同时兼顾两者的解决方案

Method: 使用动态调整的节点子集进行轻量级投票，替代昂贵的DAG顶点广播。结合最佳努力广播和可靠广播，让落后节点快速追赶

Result: Angelfish达到了最先进的峰值吞吐量，同时在中等负载下匹配了领导者驱动协议的延迟性能

Conclusion: 该协议成功实现了领导者驱动和DAG驱动协议的优势结合，为区块链共识提供了延迟和吞吐量俱佳的解决方案

Abstract: To maximize performance, many modern blockchain systems rely on
eventually-synchronous, Byzantine fault-tolerant (BFT) consensus protocols. Two
protocol designs have emerged in this space: protocols that minimize latency
using a leader that drives both data dissemination and consensus, and protocols
that maximize throughput using a separate, asynchronous data dissemination
layer. Recent protocols such as Partially-Synchronous Bullshark and Sailfish
combine elements of both approaches by using a DAG to enable parallel data
dissemination and a leader that paces DAG formation. This improves latency
while achieving state-of-the-art throughput. Yet the latency of leader-based
protocols is still better under moderate loads.
  We present Angelfish, a hybrid protocol that adapts smoothly across this
design space, from leader-based to Sailfish-like DAG-based consensus. Angelfish
lets a dynamically-adjusted subset of parties use best-effort broadcast to
issue lightweight votes instead of reliably broadcasting costlier DAG vertices.
This reduces communication, helps lagging nodes catch up, and lowers latency in
practice compared to prior DAG-based protocols. Our empirical evaluation shows
that Angelfish attains state-of-the-art peak throughput while matching the
latency of leader-based protocols under moderate throughput, delivering the
best of both worlds.

</details>


### [3] [Efficient Pre-Training of LLMs via Topology-Aware Communication Alignment on More Than 9600 GPUs](https://arxiv.org/abs/2509.15940)
*Guoliang He,Youhe Jiang,Wencong Xiao,Kaihua Jiang,Shuguang Wang,Jun Wang,Zixian Du,Zhuo Jiang,Xinlei Zhang,Binhang Yuan,Eiko Yoneki*

Main category: cs.DC

TL;DR: Arnold调度系统通过将LLM预训练作业的通信模式与数据中心网络拓扑对齐，显著提升了大规模GPU集群的训练性能


<details>
  <summary>Details</summary>
Motivation: LLM预训练在大规模GPU集群上存在复杂的通信模式，稀疏但高容量的突发数据传输导致带宽竞争，传统资源调度效率低下

Method: 进行深入的特性研究分析物理网络拓扑对LLM预训练作业的影响，开发调度算法使通信模式与现代数据中心物理网络拓扑有效对齐

Result: 仿真实验显示通信组最大传播范围减少1.67倍，生产环境中9600+GPU训练端到端性能提升10.6%

Conclusion: Arnold调度系统通过拓扑感知的调度策略有效解决了大规模LLM训练中的通信瓶颈问题

Abstract: The scaling law for large language models (LLMs) depicts that the path
towards machine intelligence necessitates training at large scale. Thus,
companies continuously build large-scale GPU clusters, and launch training jobs
that span over thousands of computing nodes. However, LLM pre-training presents
unique challenges due to its complex communication patterns, where GPUs
exchange data in sparse yet high-volume bursts within specific groups.
Inefficient resource scheduling exacerbates bandwidth contention, leading to
suboptimal training performance. This paper presents Arnold, a scheduling
system summarizing our experience to effectively align LLM communication
patterns with data center topology at scale. An in-depth characteristic study
is performed to identify the impact of physical network topology to LLM
pre-training jobs. Based on the insights, we develop a scheduling algorithm to
effectively align communication patterns with the physical network topology in
modern data centers. Through simulation experiments, we show the effectiveness
of our algorithm in reducing the maximum spread of communication groups by up
to $1.67$x. In production training, our scheduling system improves the
end-to-end performance by $10.6\%$ when training with more than $9600$ GPUs, a
significant improvement for our training pipeline.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [4] [Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)](https://arxiv.org/abs/2509.15238)
*Dylan Léveillé*

Main category: cs.MA

TL;DR: 开发了一个基于交替时序逻辑(ATL)的工具，自动生成BDI智能体的协作计划，支持多智能体系统中的竞争与合作。


<details>
  <summary>Details</summary>
Motivation: 现有BDI计划生成方法需要大量人工工作且主要针对单智能体系统，无法有效处理多智能体间的协作与竞争关系。

Method: 使用交替时序逻辑(ATL)来自动生成BDI计划，该方法能够考虑系统中智能体之间可能的竞争或合作关系。

Result: 通过一个需要智能体协作的游戏案例验证了工具的有效性，生成的计划使智能体能够成功实现共享目标。

Conclusion: 提出的ATL-based工具能够自动生成支持多智能体协作的BDI计划，解决了现有方法在多智能体场景下的局限性。

Abstract: Belief-Desire-Intention (BDI) is a framework for modelling agents based on
their beliefs, desires, and intentions. Plans are a central component of BDI
agents, and define sequences of actions that an agent must undertake to achieve
a certain goal. Existing approaches to plan generation often require
significant manual effort, and are mainly focused on single-agent systems. As a
result, in this work, we have developed a tool that automatically generates BDI
plans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans
generated accommodate for possible competition or cooperation between the
agents in the system. We demonstrate the effectiveness of the tool by
generating plans for an illustrative game that requires agent collaboration to
achieve a shared goal. We show that the generated plans allow the agents to
successfully attain this goal.

</details>


### [5] [Dynamic Agent Grouping ECBS: Scaling Windowed Multi-Agent Path Finding with Completeness Guarantees](https://arxiv.org/abs/2509.15381)
*Tiannan Zhang,Rishi Veerapaneni,Shao-Hung Chan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.MA

TL;DR: 本文扩展了WinC-MAPF框架，提出了DAG-ECBS方法，使用有界次优求解器在规划部分路径时保持完整性保证，提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的WinC-MAPF框架需要最优MAPF求解器，限制了其应用范围。本文旨在扩展该框架，使其能够使用有界次优求解器同时保持完整性。

Method: 设计了动态代理分组ECBS（DAG-ECBS）方法，动态创建和规划代理组，确保每个代理组解决方案都是有界次优的。

Result: DAG-ECBS在WinC-MAPF框架中保持了完整性，相比SS-CBS具有更好的可扩展性，并且优于没有完整性保证的窗口化ECBS。

Conclusion: 本文为设计更多能够使用WinC-MAPF框架的MAPF方法提供了蓝图，扩展了该框架的应用范围。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths for a team of agents. Although several MAPF methods which
solve full-horizon MAPF have completeness guarantees, very few MAPF methods
that plan partial paths have completeness guarantees. Recent work introduced
the Windowed Complete MAPF (WinC-MAPF) framework, which shows how windowed
optimal MAPF solvers (e.g., SS-CBS) can use heuristic updates and disjoint
agent groups to maintain completeness even when planning partial paths
(Veerapaneni et al. 2024). A core limitation of WinC-MAPF is that they required
optimal MAPF solvers. Our main contribution is to extend WinC-MAPF by showing
how we can use a bounded suboptimal solver while maintaining completeness. In
particular, we design Dynamic Agent Grouping ECBS (DAG-ECBS) which dynamically
creates and plans agent groups while maintaining that each agent group solution
is bounded suboptimal. We prove how DAG-ECBS can maintain completeness in the
WinC-MAPF framework. DAG-ECBS shows improved scalability compared to SS-CBS and
can outperform windowed ECBS without completeness guarantees. More broadly, our
work serves as a blueprint for designing more MAPF methods that can use the
WinC-MAPF framework.

</details>
