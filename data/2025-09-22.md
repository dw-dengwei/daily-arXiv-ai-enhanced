<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 3]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [PCCL: Photonic circuit-switched collective communication for distributed ML](https://arxiv.org/abs/2509.15450)
*Abhishek Vijaya Kumar,Arjun Devraj,Rachee Singh*

Main category: cs.DC

TL;DR: PCCL是一个光子集体通信库，通过重新配置网络拓扑以匹配分布式ML中的集体算法通信模式，消除拥塞和膨胀，实现GPU间直接无争用电路。


<details>
  <summary>Details</summary>
Motivation: 现代分布式ML在实际GPU集群中存在理论与实现性能差距，主要由于拥塞和跳数引起的膨胀。

Method: PCCL针对任何集体原语和拓扑通用，通过硬件无关优化框架智能决定何时重配置网络，权衡重配置延迟与拥塞/膨胀成本。

Result: 在128个GPU上，PCCL在各种工作负载、缓冲区大小和拓扑下，实现高达3倍加速，端到端训练吞吐量提升1.3倍。

Conclusion: PCCL通过将网络适应算法通信模式，提供显著性能提升，适用于不同光学硬件。

Abstract: Modern distributed ML suffers from a fundamental gap between the theoretical
and realized performance of collective communication algorithms due to
congestion and hop-count induced dilation in practical GPU clusters. We present
PCCL, a Photonic Collective Communication Library that reconfigures the network
topology to match the communication patterns of collective algorithms, thereby
eliminating congestion and dilation by creating direct, contention-free
circuits between communicating GPUs. Unlike prior approaches that synthesize
algorithms for specific network topologies and collectives, PCCL generalizes to
any collective primitive and any topology by adapting the network to match each
algorithm's communication pattern. PCCL's key innovation lies in its
hardware-agnostic optimization framework that intelligently decides when to
reconfigure based on the trade-off between network reconfiguration delay and
congestion/dilation costs, making it practical across different optical
hardware with varying switching speeds. Our evaluation demonstrates that PCCL
achieves up to 3X speedup over state-of-the-art algorithms on 128 GPUs across
various workloads, buffer sizes, and topologies, translating to a 1.3X speedup
in end-to-end training throughput.

</details>


### [2] [Angelfish: Consensus with Optimal Throughput and Latency Across the Leader-DAG Spectrum](https://arxiv.org/abs/2509.15847)
*Qianyu Yu,Giuliano Losa,Nibesh Shrestha,Xuechao Wang*

Main category: cs.DC

TL;DR: Angelfish is a hybrid BFT consensus protocol that dynamically adapts between leader-based and DAG-based designs to balance latency and throughput in blockchain systems.


<details>
  <summary>Details</summary>
Motivation: Modern BFT protocols face trade-offs: leader-based for low latency but lower throughput, DAG-based for high throughput but higher latency. Recent hybrids like Bullshark and Sailfish improve but leader-based still better for moderate loads.

Method: Angelfish uses a leader to pace consensus, but allows a dynamic subset of parties to send lightweight votes via best-effort broadcast instead of full DAG vertices, reducing communication and aiding catch-up.

Result: Empirical evaluation shows state-of-the-art peak throughput matching Sailfish, while achieving leader-based latency under moderate loads.

Conclusion: Angelfish provides the best of both worlds, optimizing performance across varying loads.

Abstract: To maximize performance, many modern blockchain systems rely on
eventually-synchronous, Byzantine fault-tolerant (BFT) consensus protocols. Two
protocol designs have emerged in this space: protocols that minimize latency
using a leader that drives both data dissemination and consensus, and protocols
that maximize throughput using a separate, asynchronous data dissemination
layer. Recent protocols such as Partially-Synchronous Bullshark and Sailfish
combine elements of both approaches by using a DAG to enable parallel data
dissemination and a leader that paces DAG formation. This improves latency
while achieving state-of-the-art throughput. Yet the latency of leader-based
protocols is still better under moderate loads.
  We present Angelfish, a hybrid protocol that adapts smoothly across this
design space, from leader-based to Sailfish-like DAG-based consensus. Angelfish
lets a dynamically-adjusted subset of parties use best-effort broadcast to
issue lightweight votes instead of reliably broadcasting costlier DAG vertices.
This reduces communication, helps lagging nodes catch up, and lowers latency in
practice compared to prior DAG-based protocols. Our empirical evaluation shows
that Angelfish attains state-of-the-art peak throughput while matching the
latency of leader-based protocols under moderate throughput, delivering the
best of both worlds.

</details>


### [3] [Efficient Pre-Training of LLMs via Topology-Aware Communication Alignment on More Than 9600 GPUs](https://arxiv.org/abs/2509.15940)
*Guoliang He,Youhe Jiang,Wencong Xiao,Kaihua Jiang,Shuguang Wang,Jun Wang,Zixian Du,Zhuo Jiang,Xinlei Zhang,Binhang Yuan,Eiko Yoneki*

Main category: cs.DC

TL;DR: 大规模语言模型(LLM)预训练面临复杂的通信模式挑战，Arnold调度系统通过对齐通信模式与数据中心拓扑来优化性能。


<details>
  <summary>Details</summary>
Motivation: LLM预训练需要大规模GPU集群，但通信模式稀疏且高体积，导致带宽争用和低效调度，影响训练性能。

Method: 进行网络拓扑对LLM预训练影响的深入研究，开发调度算法以对齐通信组与物理网络拓扑。

Result: 模拟实验中，算法将通信组最大扩展减少1.67倍；在生产环境中，使用超过9600个GPU时，端到端性能提升10.6%。

Conclusion: Arnold系统显著改善了大规模LLM训练管道的性能。

Abstract: The scaling law for large language models (LLMs) depicts that the path
towards machine intelligence necessitates training at large scale. Thus,
companies continuously build large-scale GPU clusters, and launch training jobs
that span over thousands of computing nodes. However, LLM pre-training presents
unique challenges due to its complex communication patterns, where GPUs
exchange data in sparse yet high-volume bursts within specific groups.
Inefficient resource scheduling exacerbates bandwidth contention, leading to
suboptimal training performance. This paper presents Arnold, a scheduling
system summarizing our experience to effectively align LLM communication
patterns with data center topology at scale. An in-depth characteristic study
is performed to identify the impact of physical network topology to LLM
pre-training jobs. Based on the insights, we develop a scheduling algorithm to
effectively align communication patterns with the physical network topology in
modern data centers. Through simulation experiments, we show the effectiveness
of our algorithm in reducing the maximum spread of communication groups by up
to $1.67$x. In production training, our scheduling system improves the
end-to-end performance by $10.6\%$ when training with more than $9600$ GPUs, a
significant improvement for our training pipeline.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [4] [Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)](https://arxiv.org/abs/2509.15238)
*Dylan Léveillé*

Main category: cs.MA

TL;DR: A tool automatically generates BDI agent plans using ATL to support multi-agent cooperation and competition.


<details>
  <summary>Details</summary>
Motivation: Existing BDI plan generation methods require significant manual effort and focus mainly on single-agent systems, lacking support for multi-agent interactions like competition or cooperation.

Method: Develop a tool that uses Alternating-Time Temporal Logic (ATL) to automatically generate BDI plans, accommodating possible competition or cooperation between agents.

Result: The tool generates effective plans, demonstrated in an illustrative game requiring agent collaboration, allowing agents to achieve the shared goal.

Conclusion: The ATL-based tool successfully enables BDI agents to attain goals in multi-agent scenarios through automatically generated plans.

Abstract: Belief-Desire-Intention (BDI) is a framework for modelling agents based on
their beliefs, desires, and intentions. Plans are a central component of BDI
agents, and define sequences of actions that an agent must undertake to achieve
a certain goal. Existing approaches to plan generation often require
significant manual effort, and are mainly focused on single-agent systems. As a
result, in this work, we have developed a tool that automatically generates BDI
plans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans
generated accommodate for possible competition or cooperation between the
agents in the system. We demonstrate the effectiveness of the tool by
generating plans for an illustrative game that requires agent collaboration to
achieve a shared goal. We show that the generated plans allow the agents to
successfully attain this goal.

</details>


### [5] [Dynamic Agent Grouping ECBS: Scaling Windowed Multi-Agent Path Finding with Completeness Guarantees](https://arxiv.org/abs/2509.15381)
*Tiannan Zhang,Rishi Veerapaneni,Shao-Hung Chan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.MA

TL;DR: 扩展WinC-MAPF框架，支持有界次优求解器同时保持完全性，提出DAG-ECBS方法，提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有WinC-MAPF依赖最优求解器，限制了效率；旨在使用有界次优求解器提升可扩展性，同时维持完全性。

Method: 设计DAG-ECBS，通过动态创建代理组并使用有界次优ECBS规划路径，证明在WinC-MAPF框架下保持完全性。

Result: DAG-ECBS比SS-CBS更具可扩展性，优于无完全性保证的窗口ECBS。

Conclusion: 为设计更多利用WinC-MAPF框架的MAPF方法提供蓝图。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths for a team of agents. Although several MAPF methods which
solve full-horizon MAPF have completeness guarantees, very few MAPF methods
that plan partial paths have completeness guarantees. Recent work introduced
the Windowed Complete MAPF (WinC-MAPF) framework, which shows how windowed
optimal MAPF solvers (e.g., SS-CBS) can use heuristic updates and disjoint
agent groups to maintain completeness even when planning partial paths
(Veerapaneni et al. 2024). A core limitation of WinC-MAPF is that they required
optimal MAPF solvers. Our main contribution is to extend WinC-MAPF by showing
how we can use a bounded suboptimal solver while maintaining completeness. In
particular, we design Dynamic Agent Grouping ECBS (DAG-ECBS) which dynamically
creates and plans agent groups while maintaining that each agent group solution
is bounded suboptimal. We prove how DAG-ECBS can maintain completeness in the
WinC-MAPF framework. DAG-ECBS shows improved scalability compared to SS-CBS and
can outperform windowed ECBS without completeness guarantees. More broadly, our
work serves as a blueprint for designing more MAPF methods that can use the
WinC-MAPF framework.

</details>
