# AI-Enhanced arXiv Daily 2025-06-10

<a id='toc'></a>
## 今日总计: 3 篇论文
### 目录
- [cs.LG](#cslg) (1 篇)
- [nlin.CG](#nlincg) (1 篇)
- [cs.CL](#cscl) (1 篇)

---
<a id='cslg'></a>
## cs.LG  [⬆️ 返回目录](#toc)

### [1] [Extending AALpy with Passive Learning: A Generalized State-Merging Approach](https://arxiv.org/abs/2506.06333)
> *将 AALpy 扩展到被动学习：一种广义的状态合并方法*

*Benjamin von Berg, Bernhard K. Aichernig* | **Main category: cs.LG**

**Keywords:** 自动机学习, 被动学习, 状态合并, AALpy, 红蓝框架

**Comment:** Accepted for publication at CAV 2025, the 37th International
  Conference on Computer Aided Verification

> **TL;DR:** AALpy 库现在增加了被动学习的状态合并功能，通过广义的红蓝框架实现，大大简化了状态合并算法的开发。

**AI_Comments:** {ai_comment}

<details>
  <summary>Details</summary>

**Motivation:** AALpy 主要专注于主动学习，但缺少被动学习中的重要方法。引入被动学习中的状态合并方法可以扩展其功能，并简化相关算法的实现。

**Method:** 作者在 AALpy 中引入了基于红蓝框架的广义状态合并实现。通过使用通用的内部表示，使得该框架具有高度可配置性。该方法将状态合并算法的实现工作量主要简化为兼容性标准和评分的定义。

**Result:** {results}

**Conclusion:** 在 AALpy 中引入广义状态合并功能，极大地增强了其在被动学习领域的能力，并简化了相关算法的开发和实现。

> **ai_Abstract:** {ai_Abstract}

> **摘要翻译:** {abstract_translation}

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='nlincg'></a>
## nlin.CG  [⬆️ 返回目录](#toc)

### [2] [Elementary Cellular Automata as Non-Cryptographic Hash Functions](https://arxiv.org/abs/2506.06551)
> *基本元胞自动机作为非加密哈希函数*

*Daniel McKinley* | **Main category: nlin.CG**

**Keywords:** 基本元胞自动机, 哈希函数, 误差最小化, 有损压缩, 边缘检测

**Comment:** None

> **TL;DR:** 10种基本元胞自动机被实现为一种使用误差最小化有损压缩算法的哈希函数，并具有独特属性，可应用于边缘检测。

**AI_Comments:** {ai_comment}

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 将256个基本元胞自动机（ECA）中的10个子集实现为哈希函数。使用误差最小化有损压缩算法，作用于环绕的4x4邻域单元。该算法与快速傅里叶变换和快速沃尔什-哈达马变换的嵌套二的幂结构并行。用Java实现，旨在对任何2字节RGB代码位图进行哈希处理。

**Result:** {results}

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** {ai_Abstract}

> **摘要翻译:** {abstract_translation}

</details>

[⬆️ 返回分类顶部](#nlincg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL  [⬆️ 返回目录](#toc)

### [3] [Language Models over Canonical Byte-Pair Encodings](https://arxiv.org/abs/2506.07956)
> *规范字节对编码上的语言模型*

*Tim Vieira, Tianyu Liu, Clemente Pasti, Yahya Emara, Brian DuSell, Benjamin LeBrun, Mario Giulianelli, Juan Luis Gastaldi, Timothy J. O'Donnell, Ryan Cotterell* | **Main category: cs.CL**

**Keywords:** 语言模型, 字节对编码, 非规范性, token化, 概率分配

**Comment:** ICML 2025

> **TL;DR:** 现代语言模型中的字节对编码存在非规范性问题，本文提出两种方法解决此问题，提高模型性能。

**AI_Comments:** {ai_comment}

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型在字节对编码中会将非规范的token编码分配非零概率，这既是错误的（因为非规范字符串从不出现在训练数据中），也是浪费的（它将概率质量从合理的输出中转移开）。

**Method:** 提出了两种强制规范性的方法：1) 通过条件作用实现规范性（利用测试时推理策略，无需额外训练）；2) 通过构造实现规范性（一种模型参数化，保证规范输出，但需要训练）。

**Result:** {results}

**Conclusion:** 解决语言模型中非规范性token编码问题是可行的，并且能够提升模型性能。

> **ai_Abstract:** {ai_Abstract}

> **摘要翻译:** {abstract_translation}

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

