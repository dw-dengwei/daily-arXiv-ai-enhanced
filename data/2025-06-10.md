# AI-Enhanced arXiv Daily 2025-06-10

<a id='toc'></a>
## 今日总计: 3 篇论文
### 目录
- [cs.LG](#cslg) (1 篇)
- [nlin.CG](#nlincg) (1 篇)
- [cs.CL](#cscl) (1 篇)

---
<a id='cslg'></a>
## cs.LG  <small>[⬆️ 返回目录](#toc)</small>

### [1] [Extending AALpy with Passive Learning: A Generalized State-Merging Approach](https://arxiv.org/abs/2506.06333)
> *AALpy的被动学习扩展：一种广义的状态合并方法*

*Benjamin von Berg, Bernhard K. Aichernig* | **Main category: cs.LG**

**Keywords:** AALpy, 被动学习, 状态合并, 自动机学习, 红蓝框架

**Comment:** Accepted for publication at CAV 2025, the 37th International
  Conference on Computer Aided Verification

> **TL;DR:** 本文介绍了AALpy库中新增的广义状态合并实现，该实现基于红蓝框架，旨在简化被动自动机学习中状态合并算法的定义和执行，显著减少了实现工作量。

**AI_Comments:** 这项工作通过将广义状态合并方法集成到成熟的AALpy库中，显著提升了其在被动自动机学习领域的能力。其创新之处在于提供了一个高度通用和可配置的框架，极大地简化了新旧状态合并算法的实现复杂性，从而加速了该领域的研究和开发。这对于自动机学习社区来说是一个重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有AALpy库主要专注于主动学习，为了扩展其功能并简化被动自动机学习中状态合并算法的实现，本文引入了广义状态合并方法。

**Method:** 通过在AALpy中引入基于红蓝框架的广义状态合并实现，利用不同自动机类型的通用内部表示，实现了高度可配置的状态合并算法。这主要通过定义兼容性标准和评分来减少实现工作量。

**Result:** 新的实现大大简化了状态合并算法的定义和执行，将实现工作量主要限制在兼容性标准和评分的定义上。例如，文献中一些现有算法只需几行代码即可在AALpy中实现。

**Conclusion:** 通过在AALpy中集成广义状态合并功能，该工作显著降低了开发和实现被动自动机学习算法的难度，为研究人员和开发者提供了更高效的工具。

> **ai_Abstract:** 本文介绍了对AALpy（一个专注于IO行为系统主动学习的开源自动机学习库）的最新扩展。该扩展引入了被动自动机学习领域中一种重要方法——红蓝框架下的广义状态合并实现。通过利用不同自动机类型的通用内部表示，该实现具有高度通用性和可配置性。文章描述了如何使用AALpy定义和执行状态合并算法，从而将实现工作量主要减少到兼容性标准和评分的定义，极大地简化了现有和新型算法的实现，例如，文献中的一些算法只需少量代码即可实现。

> **摘要翻译:** AALpy是一个成熟的开源自动机学习库，用Python编写，专注于具有IO行为的系统的主动学习。它提供了从完全确定性到概率自动机的各种最先进的算法。在这项工作中，我们介绍了最近新增的一种广义实现，它是被动自动机学习领域中一种重要方法：红蓝框架中的状态合并。使用不同自动机类型的通用内部表示，可以实现红蓝框架的通用且高度可配置的实现。我们描述了如何使用AALpy定义和执行状态合并算法，这主要将状态合并算法的实现工作量减少到兼容性标准和评分的定义。这有助于现有和新型算法的实现。特别是，使用AALpy定义文献中一些现有状态合并算法只需几行代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='nlincg'></a>
## nlin.CG  <small>[⬆️ 返回目录](#toc)</small>

### [2] [Elementary Cellular Automata as Non-Cryptographic Hash Functions](https://arxiv.org/abs/2506.06551)
> *初等元胞自动机作为非加密哈希函数*

*Daniel McKinley* | **Main category: nlin.CG**

**Keywords:** 初等元胞自动机, 非加密哈希函数, 误差最小化, 边缘检测, 有损压缩

**Comment:** 

> **TL;DR:** 本文研究了10个初等元胞自动机（ECA）作为非加密哈希函数，发现它们具有误差最小化/最大化、唯一解、有损逆、高效追溯哈希及边缘检测等特性。

**AI_Comments:** 这项研究通过将初等元胞自动机应用于非加密哈希函数领域，展现了其在数据处理和图像分析中的潜力。特别是发现ECA规则具有误差最小化/最大化、有损逆和高效追溯哈希等特性，为未来在特定应用场景（如边缘检测）中利用ECA提供了新的思路。其算法结构与FFT/FWHT的并行性也暗示了潜在的计算效率。

<details>
  <summary>Details</summary>

**Motivation:** 探索初等元胞自动机（ECA）作为非加密哈希函数的潜力及其相关特性。

**Method:** 实现了256个初等元胞自动机（ECA）中的10个子集作为哈希函数，采用误差最小化有损压缩算法处理环绕的4x4邻域单元。处理了所有256条规则，算法结构类似于快速傅里叶变换和快速沃尔什-哈达玛变换，并使用Java实现，旨在哈希任何2字节RGB位图。

**Result:** 在处理所有256条规则后，发现10条规则（分为两个8条规则的子集）具有误差最小化和最大化、唯一解、有损逆、高效追溯哈希等特性，并可应用于边缘检测。

**Conclusion:** 初等元胞自动机在作为非加密哈希函数方面表现出多种有趣且有用的特性，包括误差处理、逆操作能力以及在图像处理（如边缘检测）中的潜在应用。

> **ai_Abstract:** 本文探索了将部分初等元胞自动机（ECA）用作非加密哈希函数。研究人员实现了256个ECA中的10个子集，并采用了一种基于误差最小化有损压缩的算法。通过处理所有256条规则，他们发现10条规则展现出误差最小化/最大化、唯一解、有损逆、高效追溯哈希等特性，并可应用于边缘检测。该算法在结构上类似于快速傅里叶变换和快速沃尔什-哈达玛变换，并以Java实现，用于处理2字节RGB位图。

> **摘要翻译:** 256个初等元胞自动机（ECA）中的10个子集被实现为哈希函数，采用一种在环绕的4x4邻域单元上运行的误差最小化有损压缩算法。处理了所有256条规则，发现其中10条规则（分为两个8条规则的子集）具有包括误差最小化和最大化、唯一解、有损逆、高效追溯哈希等特性，并可应用于边缘检测。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套2次幂结构并行，使用Java实现，并旨在哈希任何2字节RGB代码位图。

</details>

[⬆️ 返回分类顶部](#nlincg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL  <small>[⬆️ 返回目录](#toc)</small>

### [3] [Language Models over Canonical Byte-Pair Encodings](https://arxiv.org/abs/2506.07956)
> *基于规范字节对编码的语言模型*

*Tim Vieira, Tianyu Liu, Clemente Pasti, Yahya Emara, Brian DuSell, Benjamin LeBrun, Mario Giulianelli, Juan Luis Gastaldi, Timothy J. O'Donnell, Ryan Cotterell* | **Main category: cs.CL**

**Keywords:** 语言模型, 字节对编码, 规范性, token化, 概率分配

**Comment:** ICML 2025

> **TL;DR:** 现代语言模型在处理字节对编码时，会错误地为非规范的token编码分配概率，这既是错误的也造成了浪费。本文提出了两种方法（条件化和构建）来强制执行规范性，从而提高了模型在未见数据上的似然性。

**AI_Comments:** 这项工作识别并解决了现代语言模型在处理字节对编码时一个关键但常被忽视的问题：非规范token编码的概率分配。通过提出两种不同的解决方案（无需训练的测试时策略和需要训练的模型重参数化），该研究不仅提供了实用的改进方法，而且深入探讨了语言模型内部表示的规范性问题，对于提高模型效率和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型使用确定性分词器（如字节对编码）将字符字符串表示为token字符串的概率分布。然而，这些模型会为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量，这些编码虽然可以解码为有效字符字符串，但不可能通过确定性分词器生成，因此永远不会出现在训练数据中。这种错误分配既是错误的（因为非规范字符串从未出现在训练数据中），也是浪费的（将概率质量从合理输出中转移）。

**Method:** 本文提出了两种强制执行token级别语言模型规范性的方法，以确保只有规范的token字符串被赋予正概率：1. 通过条件化实现规范性：利用测试时推理策略，无需额外训练。2. 通过构建实现规范性：一种模型参数化方法，保证规范输出但需要训练。

**Result:** 实验证明，纠正规范性错误可以提高多个模型和语料库在未见数据上的似然性。

**Conclusion:** 通过强制语言模型仅为规范的token编码分配概率，可以纠正现有模型中的错误和浪费，从而提高模型的性能和效率。

> **ai_Abstract:** 现代语言模型在处理字符字符串时，通过确定性分词器（如字节对编码）将其转换为token字符串。然而，现有方法存在一个问题：模型会为大量不可能通过分词器生成的“非规范”token编码分配非零概率，这既是错误的，也造成了概率质量的浪费。为了解决这个问题，本文提出了两种方法来强制语言模型只为规范的token字符串分配正概率：一种是通过测试时的推理策略（无需额外训练）实现的“条件化”，另一种是通过模型参数化（需要训练）实现的“构建”。实验结果表明，纠正这些规范性错误能够提高模型在未见数据上的似然性。

> **摘要翻译:** 现代语言模型将字符字符串的概率分布表示为通过确定性分词器（如字节对编码）派生出的（更短的）token字符串的分布。尽管这种方法在将语言模型扩展到大型语料库方面非常有效，但其目前的实现方式存在一个令人担忧的特性：模型为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量——这些token字符串可以解码为有效的字符字符串，但根据确定性分词器是不可能的（即，无论语料库多大，它们都不会出现在任何训练语料库中）。这种错误分配既是错误的，因为非规范字符串从未出现在训练数据中，也是浪费的，因为它将概率质量从合理输出中转移。这些都是可避免的错误！在这项工作中，我们提出了在token级别语言模型中强制执行规范性的方法，确保只有规范的token字符串被赋予正概率。我们提出了两种方法：（1）通过条件化实现规范性，利用测试时推理策略而无需额外训练，以及（2）通过构建实现规范性，这是一种保证规范输出但需要训练的模型参数化。我们证明，纠正规范性错误可以提高多个模型和语料库在未见数据上的似然性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

