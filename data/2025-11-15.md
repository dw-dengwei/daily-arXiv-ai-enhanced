<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Querying Labeled Time Series Data with Scenario Programs](https://arxiv.org/abs/2511.10627)
*Edward Kim,Devan Shanker,Varun Bharadwaj,Hongbeen Park,Jinkyu Kim,Hazem Torfah,Daniel J Fremont,Sanjit A Seshia*

Main category: cs.AI

TL;DR: 提出了一个用于验证模拟中发现的自动驾驶故障场景是否在真实世界中可重现的查询算法，通过将抽象场景表示为Scenic程序并在真实数据集中匹配来缩小sim-to-real差距。


<details>
  <summary>Details</summary>
Motivation: 解决仿真测试中发现的故障场景是否能在真实世界中重现的问题，避免因模拟传感器数据差异导致的虚假故障场景。

Method: 引入形式化定义来描述标记时间序列传感器数据如何匹配抽象场景，使用Scenic概率编程语言表示场景程序，并开发查询算法在真实数据集中识别匹配场景的数据子集。

Result: 实验显示该算法比最先进的商业视觉大语言模型更准确，查询速度快几个数量级，且能随着查询时间序列数据时长而扩展。

Conclusion: 该方法能有效验证模拟故障场景在真实世界中的可重现性，为自动驾驶系统安全测试提供了可靠的验证手段。

Abstract: Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failure scenarios identified in simulation might either be artifacts of synthetic sensor data or actual issues that also occur with real sensor data. To address this, an effective approach to validating simulated failure scenarios is to locate occurrences of these scenarios within real-world datasets and verify whether the failure persists on the datasets. To this end, we introduce a formal definition of how labeled time series sensor data can match an abstract scenario, represented as a scenario program using the Scenic probabilistic programming language. We present a querying algorithm that, given a scenario program and a labeled dataset, identifies the subset of data that matches the specified scenario. Our experiment shows that our algorithm is more accurate and orders of magnitude faster in querying scenarios than the state-of-the-art commercial vision large language models, and can scale with the duration of queried time series data.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [2] [Verification of Sequential Convex Programming for Parametric Non-convex Optimization](https://arxiv.org/abs/2511.10622)
*Rajiv Sambharya,Nikolai Matni,George Pappas*

Main category: math.OC

TL;DR: 提出了一个验证框架来精确验证顺序凸规划(SCP)算法在参数化非凸优化中的最坏情况性能，该框架提供全局最坏情况保证。


<details>
  <summary>Details</summary>
Motivation: 现有的SCP算法分析通常只能在有限条件下提供局部保证，缺乏对算法在所有问题实例上性能的全局最坏情况量化。

Method: 将验证问题构建为优化问题，在参数集上最大化性能指标，同时确保迭代序列符合SCP更新规则。框架涵盖传统SCP变体和结合凸子问题与舍入步骤的算法。

Result: 在控制、信号处理和运筹学等应用中，该框架首次为参数化设置中的SCP算法提供了全局最坏情况保证。

Conclusion: 该验证框架能够为SCP算法提供精确的全局最坏情况性能保证，填补了现有分析方法的空白。

Abstract: We introduce a verification framework to exactly verify the worst-case performance of sequential convex programming (SCP) algorithms for parametric non-convex optimization. The verification problem is formulated as an optimization problem that maximizes a performance metric (e.g., the suboptimality after a given number of iterations) over parameters constrained to be in a parameter set and iterate sequences consistent with the SCP update rules. Our framework is general, extending the notion of SCP to include both conventional variants such as trust-region, convex-concave, and prox-linear methods, and algorithms that combine convex subproblems with rounding steps, as in relaxing and rounding schemes. Unlike existing analyses that may only provide local guarantees under limited conditions, our framework delivers global worst-case guarantees--quantifying how well an SCP algorithm performs across all problem instances in the specified family. Applications in control, signal processing, and operations research demonstrate that our framework provides, for the first time, global worst-case guarantees for SCP algorithms in the parametric setting.

</details>


### [3] [Global Solutions to Non-Convex Functional Constrained Problems with Hidden Convexity](https://arxiv.org/abs/2511.10626)
*Ilyas Fatkhullin,Niao He,Guanghui Lan,Florian Wolf*

Main category: math.OC

TL;DR: 本文提出了首个能证明解决具有隐藏凸性的非凸优化问题到全局最小值的算法，包括非光滑情况下的近端点方法和光滑情况下的束水平方法，无需约束条件且复杂度与无约束隐藏凸优化匹配。


<details>
  <summary>Details</summary>
Motivation: 许多应用中的约束非凸优化问题实际上具有隐藏凸性，可以通过非线性可逆变换转化为凸规划问题，但通常这种变换是隐式或未知的，而原始变量的(次)梯度却容易获取，这促使了直接在原始非凸空间中使用标准(次)梯度oracle的算法开发。

Method: 1. 非光滑情况：使用改进的不精确近端点方法；2. 光滑情况：提出基于线性约束二次子问题的束水平类型方法。

Result: 非光滑情况下达到$\widetilde{\mathcal{O}}(\varepsilon^{-3})$的oracle复杂度，光滑情况下改进到$\widetilde{\mathcal{O}}(\varepsilon^{-1})$的oracle复杂度，且无需任何约束条件就能处理隐藏凸等式约束。

Conclusion: 尽管问题是非凸的，但所提出的方法不需要任何约束条件，能够处理隐藏凸等式约束，并且达到了与解决无约束隐藏凸优化相匹配的复杂度，为具有隐藏凸性的非凸优化问题提供了首个可证明收敛到全局最小值的算法。

Abstract: Constrained non-convex optimization is fundamentally challenging, as global solutions are generally intractable and constraint qualifications may not hold. However, in many applications, including safe policy optimization in control and reinforcement learning, such problems possess hidden convexity, meaning they can be reformulated as convex programs via a nonlinear invertible transformation. Typically such transformations are implicit or unknown, making the direct link with the convex program impossible. On the other hand, (sub-)gradients with respect to the original variables are often accessible or can be easily estimated, which motivates algorithms that operate directly in the original (non-convex) problem space using standard (sub-)gradient oracles. In this work, we develop the first algorithms to provably solve such non-convex problems to global minima. First, using a modified inexact proximal point method, we establish global last-iterate convergence guarantees with $\widetilde{\mathcal{O}}(\varepsilon^{-3})$ oracle complexity in non-smooth setting. For smooth problems, we propose a new bundle-level type method based on linearly constrained quadratic subproblems, improving the oracle complexity to $\widetilde{\mathcal{O}}(\varepsilon^{-1})$. Surprisingly, despite non-convexity, our methodology does not require any constraint qualifications, can handle hidden convex equality constraints, and achieves complexities matching those for solving unconstrained hidden convex optimization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2511.10619)
*Avrim Blum,Marten Garicano,Kavya Ravichandran,Dravyansh Sharma*

Main category: cs.LG

TL;DR: 本文提出了两个新的参数化多臂老虎机算法家族，通过离线数据学习近最优算法，在奖励曲线满足特定凹性条件时获得更强的性能保证，同时保证在良好实例上的最优臂识别和在恶劣实例上的最坏情况保障。


<details>
  <summary>Details</summary>
Motivation: 改进型多臂老虎机问题用于在不确定性下分配努力，但现有算法的最坏情况保证较为悲观。本文旨在通过参数化算法家族和数据驱动方法，在满足额外凹性条件时获得更强的性能保证，同时保持最坏情况下的鲁棒性。

Method: 提出了两个参数化算法家族：第一个包含先前工作中的最优随机算法，在奖励曲线满足额外凹性条件时可获得更强的性能保证；第二个家族包含既能保证在良好实例上识别最优臂，又能在恶劣实例上保持最坏情况保障的算法。

Result: 通过离线数据学习近最优算法，在奖励曲线满足凹性条件时实现了比现有算法更强的性能保证，且无需验证假设是否满足。

Conclusion: 采用统计学习视角，通过参数化算法家族和数据驱动方法，在改进型多臂老虎机问题中实现了更强的数据依赖保证，同时保持了最坏情况下的鲁棒性。

Abstract: The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bounds of $Ω(k)$ and $Ω(\sqrt{k})$ multiplicative approximation factors are known for both deterministic and randomized algorithms (respectively) relative to the optimal arm, where $k$ is the number of bandit arms. In this work, we propose two new parameterized families of bandit algorithms and bound the sample complexity of learning the near-optimal algorithm from each family using offline data. The first family we define includes the optimal randomized algorithm from prior work. We show that an appropriately chosen algorithm from this family can achieve stronger guarantees, with optimal dependence on $k$, when the arm reward curves satisfy additional properties related to the strength of concavity. Our second family contains algorithms that both guarantee best-arm identification on well-behaved instances and revert to worst case guarantees on poorly-behaved instances. Taking a statistical learning perspective on the bandit rewards optimization problem, we achieve stronger data-dependent guarantees without the need for actually verifying whether the assumptions are satisfied.

</details>
