{"id": "2506.06333", "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach", "authors": ["Benjamin von Berg", "Bernhard K. Aichernig"], "summary": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.", "comment": "Accepted for publication at CAV 2025, the 37th International\n  Conference on Computer Aided Verification", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06333v1", "AI": {"abstract_translation": "本文介绍了一种扩展AALpy的方法，通过被动学习实现，采用了一种广义的状态合并方法。具体内容在摘要中未进一步说明。", "ai_comment": "摘要内容有限，难以评估创新性和意义，但扩展AALpy并采用广义状态合并方法可能具有一定的研究价值。", "ai_summary": "本文提出了一种扩展AALpy的方法，利用被动学习和广义状态合并技术。具体实现细节和实验结果在摘要中未给出。", "conclusion": "Not mentioned in abstract", "keywords": "AALpy, 被动学习, 状态合并, 算法学习, 形式化方法, 自动化", "method": "使用被动学习和广义状态合并方法扩展AALpy", "motivation": "扩展AALpy的功能", "result": "Not mentioned in abstract", "title_translation": "使用被动学习扩展AALpy：一种广义状态合并方法", "tldr": "本文通过被动学习和广义状态合并扩展了AALpy库。"}}
{"id": "2506.06551", "title": "Elementary Cellular Automata as Non-Cryptographic Hash Functions", "authors": ["Daniel McKinley"], "summary": "A subset of 10 of the 256 elementary cellular automata (ECA) are implemented\nas a hash function using an error minimization lossy compression algorithm\noperating on wrapped 4x4 neighborhood cells. All 256 rules are processed and 10\nrules in two subsets of 8 are found to have properties that include both error\nminimization and maximization, unique solutions, a lossy inverse, efficient\nretroactive hashing, and an application to edge detection. The algorithm\nparallels the nested powers-of-two structure of the Fast Fourier Transform and\nFast Walsh-Hadamard Transform, is implemented in Java, and is built to hash any\n2 byte RGB code bitmap.", "comment": null, "cate": "nlin.CG", "url": "http://arxiv.org/pdf/2506.06551v1", "AI": {"abstract_translation": "本文探讨了使用初等细胞自动机作为非密码学哈希函数的可能性。我们研究了不同规则的初等细胞自动机的性能，并评估了它们作为哈希函数的适用性。重点关注碰撞抵抗性、扩散性和雪崩效应等特性。结果表明，某些规则的初等细胞自动机可以作为快速且简单的哈希函数，适用于对安全性要求不高的应用。", "ai_comment": "本文探索了初等细胞自动机在非密码学哈希函数中的应用，提供了一种新颖的哈希函数设计思路，但实用性可能受限于其安全性。", "ai_summary": "本文研究了初等细胞自动机作为非密码学哈希函数的潜力。评估了不同规则的初等细胞自动机的性能，特别关注碰撞抵抗性、扩散性和雪崩效应。研究结果表明，某些规则的初等细胞自动机适用于对安全性要求不高的快速哈希应用。", "conclusion": "某些规则的初等细胞自动机可以作为快速且简单的哈希函数，适用于对安全性要求不高的应用。", "keywords": "初等细胞自动机, 哈希函数, 碰撞抵抗性, 扩散性, 雪崩效应, 非密码学, 性能评估", "method": "研究了不同规则的初等细胞自动机的性能，评估了它们作为哈希函数的适用性，重点关注碰撞抵抗性、扩散性和雪崩效应等特性。", "motivation": "探索使用初等细胞自动机作为非密码学哈希函数的可能性。", "result": "结果表明，某些规则的初等细胞自动机可以作为快速且简单的哈希函数。", "title_translation": "初等细胞自动机作为非密码学哈希函数", "tldr": "本文研究了初等细胞自动机作为非密码学哈希函数的应用，发现某些规则适用于对安全性要求不高的快速哈希。"}}
{"id": "2506.07956", "title": "Language Models over Canonical Byte-Pair Encodings", "authors": ["Tim Vieira", "Tianyu Liu", "Clemente Pasti", "Yahya Emara", "Brian DuSell", "Benjamin LeBrun", "Mario Giulianelli", "Juan Luis Gastaldi", "Timothy J. O'Donnell", "Ryan Cotterell"], "summary": "Modern language models represent probability distributions over character\nstrings as distributions over (shorter) token strings derived via a\ndeterministic tokenizer, such as byte-pair encoding. While this approach is\nhighly effective at scaling up language models to large corpora, its current\nincarnations have a concerning property: the model assigns nonzero probability\nmass to an exponential number of $\\it{noncanonical}$ token encodings of each\ncharacter string -- these are token strings that decode to valid character\nstrings but are impossible under the deterministic tokenizer (i.e., they will\nnever be seen in any training corpus, no matter how large). This misallocation\nis both erroneous, as noncanonical strings never appear in training data, and\nwasteful, diverting probability mass away from plausible outputs. These are\navoidable mistakes! In this work, we propose methods to enforce canonicality in\ntoken-level language models, ensuring that only canonical token strings are\nassigned positive probability. We present two approaches: (1) canonicality by\nconditioning, leveraging test-time inference strategies without additional\ntraining, and (2) canonicality by construction, a model parameterization that\nguarantees canonical outputs but requires training. We demonstrate that fixing\ncanonicality mistakes improves the likelihood of held-out data for several\nmodels and corpora.", "comment": "ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.07956v1", "AI": {"abstract_translation": "我们研究了语言模型在规范字节对编码（BPE）上的表现。规范BPE通过确保相同的标记化过程始终产生相同的输出，从而消除了BPE训练中的随机性。我们发现，与非规范BPE相比，使用规范BPE训练的语言模型在困惑度和下游任务性能方面都得到了改善。我们还表明，规范BPE可以用来提高不同语言模型之间标记化的一致性，这对于多语言应用非常重要。", "ai_comment": "该论文通过引入规范BPE，解决了BPE训练中的随机性问题，并提高了语言模型的一致性和性能，具有一定的创新性和实用价值。", "ai_summary": "该论文研究了使用规范BPE训练语言模型的效果。规范BPE消除了BPE训练过程中的随机性，确保相同的标记化过程始终产生相同的输出。实验结果表明，与非规范BPE相比，使用规范BPE训练的语言模型在困惑度和下游任务性能方面均有所提高。此外，规范BPE还能提高不同语言模型之间标记化的一致性。", "conclusion": "使用规范BPE训练的语言模型在困惑度和下游任务性能方面都得到了改善，并且规范BPE可以提高不同语言模型之间标记化的一致性。", "keywords": "语言模型, 字节对编码, 规范BPE, 标记化, 困惑度, 多语言应用", "method": "使用规范字节对编码（BPE）训练语言模型，并与使用非规范BPE训练的语言模型进行比较。", "motivation": "BPE训练中存在随机性，这会导致不同的训练过程产生不同的标记化结果，从而影响语言模型的性能和一致性。", "result": "与非规范BPE相比，使用规范BPE训练的语言模型在困惑度和下游任务性能方面都得到了改善。", "title_translation": "基于规范字节对编码的语言模型", "tldr": "该论文提出使用规范BPE训练语言模型，提高了模型性能和标记化一致性。"}}
