{"id": "2506.06333", "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach", "authors": ["Benjamin von Berg", "Bernhard K. Aichernig"], "summary": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.", "comment": "Accepted for publication at CAV 2025, the 37th International\n  Conference on Computer Aided Verification", "cate": "cs.LG", "url": "http://arxiv.org/pdf/2506.06333v1", "AI": {"title_translation": "使用被动学习扩展AALpy：一种广义状态合并方法", "tldr": "AALpy通过广义状态合并方法扩展了被动学习功能，简化了状态合并算法的实现。", "motivation": "AALpy是一个专注于具有IO行为的系统主动学习的开源自动机学习库。本文旨在通过添加被动自动机学习领域中的重要方法（红蓝框架中的状态合并）的广义实现来扩展AALpy。", "method": "在AALpy中，使用通用的内部表示来实现不同自动机类型的红蓝框架中的状态合并算法。算法的实现主要集中在兼容性标准和评分的定义上。", "result": "展示了如何使用AALpy定义和执行状态合并算法，并通过少量代码即可实现现有文献中的一些状态合并算法。", "conclusion": "通过在AALpy中实现广义状态合并方法，可以有效降低状态合并算法的实现工作量，并促进现有和新型算法的实现。", "translation": "AALpy 是一个完善的开源自动机学习库，用 Python 编写，专注于具有 IO 行为的系统的主动学习。它为不同的自动机类型提供了广泛的最新算法，范围从完全确定性自动机到概率自动机。在这项工作中，我们介绍了最近添加的被动自动机学习领域中一种重要方法的广义实现：红蓝框架中的状态合并。使用不同自动机类型的通用内部表示允许红蓝框架的通用和高度可配置的实现。我们描述了如何使用 AALpy 定义和执行状态合并算法，这减少了状态合并算法的实现工作量，主要减少到兼容性标准和评分的定义。这有助于实现现有算法和新算法。特别是，使用 AALpy 定义文献中的一些现有状态合并算法只需几行代码。", "summary": "本文介绍了AALpy通过实现红蓝框架中的广义状态合并方法来扩展其被动学习功能。该方法利用通用内部表示，简化了状态合并算法的定义和执行，并通过少量代码即可实现现有算法。", "keywords": "AALpy, 自动机学习, 状态合并, 被动学习, 红蓝框架", "comments": "该论文通过在AALpy中引入通用的状态合并框架，降低了被动学习算法的实现难度，具有一定的实用价值。然而，摘要中未提及该方法在性能或适用性上的具体优势或局限性。"}}
{"id": "2506.06551", "title": "Elementary Cellular Automata as Non-Cryptographic Hash Functions", "authors": ["Daniel McKinley"], "summary": "A subset of 10 of the 256 elementary cellular automata (ECA) are implemented\nas a hash function using an error minimization lossy compression algorithm\noperating on wrapped 4x4 neighborhood cells. All 256 rules are processed and 10\nrules in two subsets of 8 are found to have properties that include both error\nminimization and maximization, unique solutions, a lossy inverse, efficient\nretroactive hashing, and an application to edge detection. The algorithm\nparallels the nested powers-of-two structure of the Fast Fourier Transform and\nFast Walsh-Hadamard Transform, is implemented in Java, and is built to hash any\n2 byte RGB code bitmap.", "comment": null, "cate": "nlin.CG", "url": "http://arxiv.org/pdf/2506.06551v1", "AI": {"title_translation": "初级细胞自动机作为非密码散列函数", "tldr": "使用初级细胞自动机（ECA）作为散列函数，通过误差最小化有损压缩算法处理4x4邻域单元，发现10个规则具有适用于边缘检测的特性。", "motivation": "探索初级细胞自动机（ECA）作为散列函数的潜力。", "method": "使用误差最小化有损压缩算法在包裹的4x4邻域单元上实现10个初级细胞自动机（ECA）作为散列函数。该算法类似于快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套二次幂结构，用Java实现，旨在散列任何2字节RGB代码位图。", "result": "发现256个规则中的10个规则在8个规则的两个子集中具有误差最小化和最大化、唯一解、有损逆、高效追溯散列以及边缘检测应用等特性。", "conclusion": "已实现的算法可以有效地用作散列函数，并且可以应用于边缘检测。", "translation": "实现了256个基本细胞自动机（ECA）中的一个子集（10个），作为散列函数，使用在包裹的4x4邻域单元上运行的误差最小化有损压缩算法。处理了所有256个规则，发现8个规则的两个子集中的10个规则具有包括误差最小化和最大化、唯一解、有损逆、高效追溯散列以及边缘检测应用等特性。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套二次幂结构相似，用Java实现，旨在散列任何2字节RGB代码位图。", "summary": "本研究实现了256个基本细胞自动机中的一个子集，共10个，作为散列函数，采用误差最小化有损压缩算法处理4x4邻域单元。研究发现，其中10个规则具有误差最小化、最大化、唯一解、有损逆等特性，并可应用于边缘检测。该算法用Java实现，适用于散列2字节RGB代码位图。", "keywords": "细胞自动机, 散列函数, 误差最小化", "comments": "该论文提出了一种新颖的散列函数实现方法，将细胞自动机与误差最小化算法相结合，具有一定的创新性。然而，其实际的密码学安全性需要进一步评估。"}}
{"id": "2506.07956", "title": "Language Models over Canonical Byte-Pair Encodings", "authors": ["Tim Vieira", "Tianyu Liu", "Clemente Pasti", "Yahya Emara", "Brian DuSell", "Benjamin LeBrun", "Mario Giulianelli", "Juan Luis Gastaldi", "Timothy J. O'Donnell", "Ryan Cotterell"], "summary": "Modern language models represent probability distributions over character\nstrings as distributions over (shorter) token strings derived via a\ndeterministic tokenizer, such as byte-pair encoding. While this approach is\nhighly effective at scaling up language models to large corpora, its current\nincarnations have a concerning property: the model assigns nonzero probability\nmass to an exponential number of $\\it{noncanonical}$ token encodings of each\ncharacter string -- these are token strings that decode to valid character\nstrings but are impossible under the deterministic tokenizer (i.e., they will\nnever be seen in any training corpus, no matter how large). This misallocation\nis both erroneous, as noncanonical strings never appear in training data, and\nwasteful, diverting probability mass away from plausible outputs. These are\navoidable mistakes! In this work, we propose methods to enforce canonicality in\ntoken-level language models, ensuring that only canonical token strings are\nassigned positive probability. We present two approaches: (1) canonicality by\nconditioning, leveraging test-time inference strategies without additional\ntraining, and (2) canonicality by construction, a model parameterization that\nguarantees canonical outputs but requires training. We demonstrate that fixing\ncanonicality mistakes improves the likelihood of held-out data for several\nmodels and corpora.", "comment": "ICML 2025", "cate": "cs.CL", "url": "http://arxiv.org/pdf/2506.07956v1", "AI": {"title_translation": "基于规范字节对编码的语言模型", "tldr": "语言模型会给不可能出现的token序列赋予非零概率，这很浪费。本文提出了两种方法来解决这个问题，并通过实验验证了其有效性。", "motivation": "当前语言模型会给每个字符序列的非规范token编码赋予非零概率，这导致概率分配错误和浪费。", "method": "提出了两种强制规范性的方法：(1) 通过条件反射实现规范性，利用测试时推理策略，无需额外训练；(2) 通过构建实现规范性，这是一种保证规范输出的模型参数化方法，但需要训练。", "result": "实验表明，修正规范性错误可以提高几个模型和语料库的held-out数据的可能性。", "conclusion": "本文提出的方法可以有效解决语言模型中非规范token编码的问题，提高模型的性能。", "translation": "现代语言模型将字符字符串上的概率分布表示为通过确定性分词器（如字节对编码）导出的（较短）token字符串上的分布。虽然这种方法在将语言模型扩展到大型语料库方面非常有效，但其目前的化身有一个令人担忧的属性：该模型为每个字符字符串的指数数量的非规范token编码分配非零概率质量——这些token字符串解码为有效的字符字符串，但在确定性分词器下是不可能的（即，无论训练语料库有多大，它们都不会出现在任何训练语料库中）。这种错误分配既是错误的，因为非规范字符串永远不会出现在训练数据中，也是浪费的，将概率质量从合理的输出中转移出去。这些都是可以避免的错误！在这项工作中，我们提出了在token级别语言模型中强制规范性的方法，确保只有规范token字符串被分配正概率。我们提出了两种方法：（1）通过条件反射实现规范性，利用测试时推理策略，无需额外训练；（2）通过构建实现规范性，这是一种保证规范输出的模型参数化方法，但需要训练。我们证明了修正规范性错误可以提高几个模型和语料库的held-out数据的可能性。", "summary": "本文提出了一种解决语言模型中非规范token编码问题的方法。该方法通过条件反射或构建的方式强制规范性，确保只有规范的token字符串被分配正概率。实验结果表明，该方法可以提高模型的性能。", "keywords": "语言模型, 字节对编码, 规范性", "comments": "该论文提出了一个有趣的问题，并提供了两种解决方案。通过条件反射实现规范性不需要额外的训练，更易于应用。通过构建实现规范性可以保证规范输出，但需要训练。未来的研究可以比较这两种方法的优劣，并探索其他强制规范性的方法。"}}
