## Total Papers Today: 4
**Report Date:** 2025-06-09

<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation](https://arxiv.org/abs/2506.05566)
> *ScaleRTL：通过推理数据和测试时计算扩展大型语言模型以实现精确的RTL代码生成*

*Chenhui Deng, Yun-Da Tsai, Guan-Ting Liu, Zhongzhi Yu, Haoxing Ren* | **Main category: cs.AR**

**Keywords:** RTL代码生成, 大型语言模型, 推理数据, 测试时计算, VerilogEval

> **TL;DR:** ScaleRTL是一个结合了高质量推理数据和测试时计算的推理型大型语言模型，显著提高了RTL代码生成的准确性，并在VerilogEval和RTLLM上达到了最先进的性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在软件编码方面表现出色，但由于高质量训练数据稀缺以及缺乏测试时扩展支持（非推理特性），它们在RTL代码生成方面的效果有限。先前的努力未能从根本上解决数据瓶颈。

**Method:** 本文引入了ScaleRTL，第一个用于RTL编码的推理型大型语言模型。它通过以下方式实现：1. 策划了一个包含平均56K token的长链式思维推理轨迹的多样化数据集，总计3.5B token，捕获了丰富的RTL知识。2. 在此语料库上对通用推理模型进行微调。3. 通过一种新颖的测试时扩展策略进一步增强性能，该策略通过迭代反思和自我纠正先前的推理步骤来扩展推理过程。

**Result:** ScaleRTL在VerilogEval和RTLLM上实现了最先进的性能，在VerilogEval上比18个有竞争力的基线高出18.4%，在RTLLM上高出12.7%。

**Conclusion:** ScaleRTL通过结合高质量的推理数据和创新的测试时计算策略，成功解决了RTL代码生成中数据稀缺和推理能力不足的问题，显著提升了大型语言模型在该领域的性能。

> **ai_Abstract:** 本研究提出了ScaleRTL，一个专为RTL代码生成设计的推理型大型语言模型，旨在克服现有模型因高质量训练数据稀缺和缺乏测试时扩展能力而导致的局限性。ScaleRTL通过构建一个包含大量链式思维推理轨迹的高质量数据集，并在此基础上微调通用推理模型来实现深度RTL推理。此外，它采用了一种新颖的测试时扩展策略，通过迭代反思和自我纠正来提升性能。实验结果表明，ScaleRTL在VerilogEval和RTLLM基准测试中均取得了最先进的性能，显著超越了现有基线。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展使得它们在软件编码基准上达到了接近人类的性能，但由于高质量训练数据的稀缺，它们在RTL代码生成方面的有效性仍然有限。尽管先前的努力已经针对RTL任务对LLMs进行了微调，但它们并未从根本上克服数据瓶颈，并且由于其非推理性质而缺乏对测试时扩展的支持。在这项工作中，我们引入了ScaleRTL，这是第一个用于RTL编码的推理型LLM，它同时扩展了高质量推理数据和测试时计算。具体来说，我们策划了一组多样化的长链式思维推理轨迹，平均每个56K token，从而形成了一个包含3.5B token的数据集，捕获了丰富的RTL知识。在此语料库上对通用推理模型进行微调，产生了能够进行深度RTL推理的ScaleRTL。随后，我们通过一种新颖的测试时扩展策略进一步增强了ScaleRTL的性能，该策略通过迭代反思和自我纠正先前的推理步骤来扩展推理过程。实验结果表明，ScaleRTL在VerilogEval和RTLLM上实现了最先进的性能，在VerilogEval上比18个有竞争力的基线高出18.4%，在RTLLM上高出12.7%。

</details>


### [2] [Lumina: Real-Time Mobile Neural Rendering by Exploiting Computational Redundancy](https://arxiv.org/abs/2506.05682)
> *Lumina: 利用计算冗余实现实时移动神经渲染*

*Yu Feng, Weikai Lin, Yuge Cheng, Zihan Liu, Jingwen Leng, Minyi Guo, Chen Chen, Shixuan Sun, Yuhao Zhu* | **Main category: cs.AR**

**Keywords:** 神经渲染, 3D 高斯泼溅, 移动计算, 软硬件协同设计, 计算冗余

> **TL;DR:** Lumina 是一种软硬件协同设计的系统，通过 S^2 算法和辐射缓存机制，显著提高了移动设备上 3D 高斯泼溅神经渲染的效率和能效。

<details>
  <summary>Details</summary>

**Motivation:** 3D 高斯泼溅 (3DGS) 虽然极大地推动了神经渲染的进步，但在当前的移动 SoC 上仍然计算量巨大，难以实现实时性能。

**Method:** 本文提出了 Lumina，一个软硬件协同设计的系统。它集成了两个主要优化：一种新颖的 S^2 算法和一种辐射缓存 (RC) 机制。S^2 算法利用渲染中的时间相干性来减少计算开销，而 RC 则利用 3DGS 的颜色积分过程来降低密集光栅化计算的频率。此外，还提出了一种加速器架构 LuminCore，以进一步加速缓存查找并解决光栅化中的基本低效率问题。

**Result:** Lumina 在合成和真实世界数据集上，与移动 Volta GPU 相比，实现了 4.5 倍的加速和 5.3 倍的能耗降低，且质量损失极小（峰值信噪比降低 < 0.2 dB）。

**Conclusion:** Lumina 通过软硬件协同设计，成功解决了移动设备上 3D 高斯泼溅神经渲染的计算挑战，显著提升了实时性能和能效，同时保持了高质量渲染。

> **ai_Abstract:** Lumina 是一种针对移动设备实时神经渲染的软硬件协同设计系统，旨在解决 3D 高斯泼溅在移动 SoC 上计算量大的问题。它引入了 S^2 算法来利用时间相干性减少计算，以及辐射缓存机制来降低光栅化频率。结合专门的 LuminCore 加速器架构，Lumina 在性能和能效方面均取得了显著提升，且对渲染质量影响甚微。

> **摘要翻译:** 3D 高斯泼溅（3DGS）极大地推动了神经渲染的进展，但其在当今的移动 SoC 上仍然计算量巨大。为了解决这一挑战，我们提出了 Lumina，一个软硬件协同设计的系统，它集成了两项主要优化：一种新颖的 S^2 算法和一种辐射缓存（RC）机制，以提高神经渲染的效率。S^2 算法利用渲染中的时间相干性来减少计算开销，而 RC 则利用 3DGS 的颜色积分过程来降低密集光栅化计算的频率。结合这些技术，我们提出了一种加速器架构 LuminCore，以进一步加速缓存查找并解决光栅化中的基本低效率问题。我们展示了 Lumina 在合成和真实世界数据集上，与移动 Volta GPU 相比，实现了 4.5 倍的加速和 5.3 倍的能耗降低，且质量损失极小（峰值信噪比降低 < 0.2 dB）。

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [3] [Preprocessing Methods for Memristive Reservoir Computing for Image Recognition](https://arxiv.org/abs/2506.05588)
> *用于图像识别的忆阻器储层计算预处理方法*

*Rishona Daniels, Duna Wattad, Ronny Ronen, David Saad, Shahar Kvatinsky* | **Main category: cs.NE**

**Keywords:** 忆阻器储层计算, 预处理方法, 图像识别, 准确性, 能耗

> **TL;DR:** 本研究系统比较了忆阻器储层计算的各种预处理方法，并提出了一种基于奇偶校验的预处理方法，该方法在图像识别中可提高准确性并优化能耗。

<details>
  <summary>Details</summary>

**Motivation:** 忆阻器储层计算（RC）在实现高性能方面面临挑战，其性能关键取决于输入预处理方法和储层大小。目前缺乏对这些因素影响的全面评估。

**Method:** 本研究系统比较了用于忆阻器储层计算系统的各种预处理方法，评估了它们对准确性和能耗的影响。此外，还提出了一种基于奇偶校验的预处理方法。

**Result:** 提出的基于奇偶校验的预处理方法可将准确性提高2-6%，同时与现有方法相比，仅需适度增加设备数量。研究结果强调了知情预处理策略对于提高忆阻器储层计算系统效率和可扩展性的重要性。

**Conclusion:** 知情预处理策略对于提高忆阻器储层计算系统的效率和可扩展性至关重要。

> **ai_Abstract:** 本论文系统地比较了用于忆阻器储层计算（RC）的各种预处理方法，旨在解决其在图像识别中实现高性能的挑战。研究评估了不同预处理方法对准确性和能耗的影响，并提出了一种新的基于奇偶校验的预处理方法，该方法在仅适度增加设备数量的情况下，将准确性提高了2-6%。研究结果强调了选择合适的预处理策略对于提升忆阻器RC系统效率和可扩展性的重要性。

> **摘要翻译:** 储层计算（RC）作为一种高效的循环神经网络架构，因其简化的训练（仅需训练其最后一个感知器读出层）而备受关注。当使用忆阻器实现时，RC系统受益于其动态特性，这使得它们成为储层构建的理想选择。然而，在基于忆阻器的RC中实现高性能仍然具有挑战性，因为它关键取决于输入预处理方法和储层大小。尽管兴趣日益增长，但仍缺乏量化这些因素影响的全面评估。本文系统地比较了忆阻器RC系统的各种预处理方法，评估了它们对准确性和能耗的影响。我们还提出了一种基于奇偶校验的预处理方法，该方法在仅需适度增加设备数量的情况下，将准确性提高了2-6%。我们的研究结果强调了知情预处理策略对于提高忆阻器RC系统效率和可扩展性的重要性。

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory](https://arxiv.org/abs/2506.05994)
> *RETENTION: 基于内容可寻址存储器的资源高效树集成模型加速*

*Yi-Chun Liao, Chieh-Lin Tsai, Yuan-Hao Chang, Camélia Slimani, Jalil Boukhobza, Tei-Wei Kuo* | **Main category: cs.LG**

**Keywords:** 树集成模型加速, 内容可寻址存储器, 资源高效, 迭代剪枝, 树映射

> **TL;DR:** RETENTION框架通过迭代剪枝和树映射方案，显著降低内容可寻址存储器（CAM）对树集成模型加速的容量需求，同时保持高精度。

<details>
  <summary>Details</summary>

**Motivation:** 现代树集成模型在结构化数据学习上优于深度学习，但其固有特性对传统加速器构成挑战。利用内容可寻址存储器（CAM）加速树模型虽有前景，但现有设计存在内存消耗过大和利用率低的问题。

**Method:** 本文提出了RETENTION端到端框架，旨在显著降低树模型推理对CAM容量的需求。该框架包含：1) 针对基于bagging的模型（如随机森林）的迭代剪枝算法，其具有新颖的剪枝标准，旨在最小化模型复杂性并确保可控的精度下降。2) 树映射方案，该方案结合了两种创新的数据放置策略，以缓解CAM中广泛使用的“don't care”状态导致的内存冗余。

**Result:** 实验结果表明，仅实施树映射方案即可实现1.46倍至21.30倍的空间效率提升。完整的RETENTION框架可带来4.35倍至207.12倍的改进，且精度损失低于3%。

**Conclusion:** RETENTION框架在降低内容可寻址存储器（CAM）容量需求方面非常有效，为树集成模型的加速提供了一个资源高效的方向。

> **ai_Abstract:** 本文提出了RETENTION框架，旨在解决基于内容可寻址存储器（CAM）加速树集成模型时存在的内存消耗过大和利用率低的问题。该框架通过一个迭代剪枝算法和创新的树映射方案，显著降低了CAM的容量需求。实验证明，RETENTION在大幅提高空间效率的同时，将精度损失控制在3%以内，为树集成模型的资源高效加速提供了有效途径。

> **摘要翻译:** 尽管深度学习在从非结构化数据中学习方面展示了卓越的能力，但现代树集成模型在提取相关信息和从结构化数据集中学习方面仍然更胜一筹。虽然已经为加速树模型做出了多项努力，但模型的固有特性对传统加速器构成了重大挑战。最近利用内容可寻址存储器（CAM）的研究为加速树模型提供了一个有前景的解决方案，然而现有设计存在内存消耗过大和利用率低的问题。这项工作通过引入RETENTION来应对这些挑战，RETENTION是一个端到端框架，显著降低了树模型推理对CAM容量的需求。我们提出了一种迭代剪枝算法，该算法具有为基于bagging的模型（例如随机森林）量身定制的新颖剪枝标准，可在确保可控精度下降的同时最小化模型复杂性。此外，我们提出了一种树映射方案，该方案结合了两种创新的数据放置策略，以缓解CAM中广泛使用的“don't care”状态导致的内存冗余。实验结果表明，仅实施树映射方案即可实现1.46倍至21.30倍的空间效率提升，而完整的RETENTION框架则带来了4.35倍至207.12倍的改进，且精度损失低于3%。这些结果表明，RETENTION在降低CAM容量需求方面非常有效，为树集成模型加速提供了资源高效的方向。

</details>
