<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 52]
- [cs.AI](#cs.AI) [Total: 15]
- [math.OC](#math.OC) [Total: 14]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Joint Design of Protein Surface and Structure Using a Diffusion Bridge Model](https://arxiv.org/abs/2511.16675)
*Guanlue Li,Xufeng Zhao,Fang Wu,Sören Laue*

Main category: cs.LG

TL;DR: PepBridge是一个新颖的蛋白质表面和结构联合设计框架，通过扩散桥模型和多模型扩散方法，从受体表面生成完整的蛋白质结构，确保表面互补性和结构稳定性。


<details>
  <summary>Details</summary>
Motivation: 蛋白质-蛋白质相互作用受表面互补性和疏水作用支配，但设计能够精确互补目标受体的多样化、物理真实的蛋白质结构和表面仍是一个重大挑战。

Method: 使用去噪扩散桥模型将受体表面映射到配体表面，然后通过多模型扩散预测相应结构，同时使用形状-框架匹配网络确保表面几何与骨架结构对齐。

Result: 在多种蛋白质设计场景中的广泛验证表明，PepBridge能够生成结构可行的蛋白质。

Conclusion: 该方法代表了自上而下蛋白质结构联合设计的重要进展。

Abstract: Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.

</details>


### [2] [DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting](https://arxiv.org/abs/2511.16715)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Hao Wang,Haoxuan Wang,Huiran Duan,Junming Liu,Yingli Tian*

Main category: cs.LG

TL;DR: DDTime是一个轻量级的时间序列数据集蒸馏框架，通过频域对齐和样本间正则化解决时间序列蒸馏中的时序偏差和样本多样性不足问题，在20个基准数据集上相比现有方法获得约30%的相对精度提升。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测通常需要大规模数据集和大量计算资源，数据集蒸馏提供了一种有前景的替代方案。但将数据集蒸馏扩展到时间序列预测面临两个挑战：1)强自相关性导致的时序偏差；2)缺乏明确类别先验导致的合成样本多样性不足。

Method: 基于一阶压缩分解构建DDTime框架：1)通过频域对齐机制缓解自相关引起的偏差，确保频谱一致性和时序保真度；2)基于信息瓶颈原理设计样本间正则化，增强多样性并最大化合成轨迹的信息密度。

Result: 在20个基准数据集和多种预测架构上的广泛实验表明，DDTime持续优于现有蒸馏方法，实现约30%的相对精度提升，同时仅引入约2.49%的计算开销。

Conclusion: DDTime提供了一个轻量级且即插即用的蒸馏框架，有效解决了时间序列数据集蒸馏中的关键挑战，在保持高精度的同时显著降低了计算需求。

Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets that preserve the learning behavior of full data. However, extending dataset distillation to time-series forecasting is non-trivial due to two fundamental challenges: 1.temporal bias from strong autocorrelation, which leads to distorted value-term alignment between teacher and student models; and 2.insufficient diversity among synthetic samples, arising from the absence of explicit categorical priors to regularize trajectory variety.
  In this work, we propose DDTime, a lightweight and plug-in distillation framework built upon first-order condensation decomposition. To tackle Challenge 1, it revisits value-term alignment through temporal statistics and introduces a frequency-domain alignment mechanism to mitigate autocorrelation-induced bias, ensuring spectral consistency and temporal fidelity. To address Challenge 2, we further design an inter-sample regularization inspired by the information bottleneck principle, which enhances diversity and maximizes information density across synthetic trajectories. The combined objective is theoretically compatible with a wide range of condensation paradigms and supports stable first-order optimization. Extensive experiments on 20 benchmark datasets and diverse forecasting architectures demonstrate that DDTime consistently outperforms existing distillation methods, achieving about 30% relative accuracy gains while introducing about 2.49% computational overhead. All code and distilled datasets will be released.

</details>


### [3] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 研究发现，在文本属性图上，仅使用节点文本描述的LLM已经能取得良好性能，大多数结构编码策略仅带来边际收益甚至负面影响，表明显式结构先验在强大语言模型时代往往不必要甚至适得其反。


<details>
  <summary>Details</summary>
Motivation: 探索不同图结构编码策略如何影响LLM在文本属性图上的性能，挑战传统图学习中结构必须被显式编码的假设。

Method: 通过系统实验比较不同图结构编码策略，包括模板化图模板和GNN编码结构信息等方法，评估LLM在文本属性图上的表现。

Result: LLM仅使用节点文本描述就能在各项任务中取得强劲性能；大多数结构编码策略仅提供边际收益或负面效果；显式结构先验往往不必要且有时适得其反。

Conclusion: 这标志着与传统图学习范式的显著背离，需要重新思考在LLM时代如何表示和利用结构，为新的语义驱动图学习方法打开了大门。

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [4] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: 提出GCL-OT框架，通过最优传输解决文本属性图中的多粒度异质性对齐问题，显著提升异质图上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性假设和硬优化目标，在异质图上表现不佳，且通常将文本嵌入视为静态目标，导致对齐效果不理想。

Method: 设计基于RealSoftMax的相似度估计器处理部分异质性，基于提示的过滤器处理完全异质性，并引入OT引导的软监督来学习潜在同质性。

Result: 在9个基准测试中持续优于最先进方法，验证了其有效性和鲁棒性。

Conclusion: GCL-OT框架通过灵活的双向对齐机制成功解决了文本属性图中的多粒度异质性挑战。

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [5] [Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach](https://arxiv.org/abs/2511.16786)
*Yaoxin Yang,Peng Ye,Xudong Tan,Chongjun Tu,Maosen Zhao,Jia Hao,Tao Chen*

Main category: cs.LG

TL;DR: FlashCache是一个基于频域分析和异常KV感知的多模态KV缓存压缩框架，通过保留偏离主能量的异常KV对来减少缓存大小，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型的推理开销大，因为多模态KV缓存随视觉输入长度增长而增加。现有压缩方法依赖注意力分数，与高效注意力内核不兼容且忽略值向量的贡献。

Method: 从KV矩阵分布角度重新审视压缩问题，通过频域低通滤波器提取主能量，识别异常KV对，设计异常KV识别模块和动态预算分配模块来保留关键特征。

Result: 在多个MLLM和基准测试中，FlashCache优于现有方法，解码速度提升1.69倍，KV内存使用降低80%，同时保持任务性能。

Conclusion: FlashCache通过频域引导的异常KV感知压缩框架，有效解决了多模态KV缓存压缩问题，实现了高效推理和内存优化。

Abstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache size, which makes them are incompatible with established efficient attention kernels (e.g., FlashAttention) and ignores the contribution of value vectors to the attention output. In this work, we revisit multimodal KV Cache compression from the perspective of the KV matrices' distribution. First, we observe that frequency-domain energy of multimodal KV matrices is predominantly concentrated in low-frequency and extract this principal energy via a low-pass filter. Further, we find that removing KV pairs that deviate substantially from this principal energy leads to a pronounced performance drop, which we define as Outlier KVs. Considering Outlier KVs are more likely to encode features critical for inference, we propose FlashCache, a frequency-domain-guided, Outlier-KV-aware KV Cache compression framework. First, we introduce an Outlier KV Recognition Module that models the principal component of multimodal KV matrices in the frequency domain and preferentially retains KV pairs that significantly deviate from it. Furthermore, Dynamic Budget Allocation Module is designed to adaptively determine the per-layer KV Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal KV compression methods, achieving up to 1.69 times faster decoding with 80% lower KV memory usage while maintaining task performance.

</details>


### [6] [A Vector Symbolic Approach to Multiple Instance Learning](https://arxiv.org/abs/2511.16795)
*Ehsan Ahmed Dhrubo,Mohammad Mahmudul Alam,Edward Raff,Tim Oates,James Holt*

Main category: cs.LG

TL;DR: 提出基于向量符号架构(VSA)的多实例学习框架，通过高维向量和代数运算直接编码MIL的iff约束，在保持严格MIL公式的同时实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习MIL方法大多违反正包当且仅当至少一个正实例的严格逻辑约束，导致性能指标虚高和泛化能力差。

Method: 使用VSA将实例和概念表示为近正交高维向量，通过代数运算在分类时强制执行iff约束，并设计学习编码器将原始数据转换为VSA兼容向量。

Result: 在标准MIL基准和医学影像数据集上达到有效MIL模型的最先进结果，优于现有方法且严格遵循MIL公式。

Conclusion: 为依赖学习启发式的现有MIL方法提供了原则性、可解释且有效的替代方案。

Abstract: Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a bag is labeled positive if and only if at least one instance within it is positive. While this iff constraint aligns with many real-world applications, recent work has shown that most deep learning-based MIL approaches violate it, leading to inflated performance metrics and poor generalization. We propose a novel MIL framework based on Vector Symbolic Architectures (VSAs), which provide a differentiable mechanism for performing symbolic operations in high-dimensional space. Our method encodes the MIL assumption directly into the model's structure by representing instances and concepts as nearly orthogonal high-dimensional vectors and using algebraic operations to enforce the iff constraint during classification. To bridge the gap between raw data and VSA representations, we design a learned encoder that transforms input instances into VSA-compatible vectors while preserving key distributional properties. Our approach, which includes a VSA-driven MaxNetwork classifier, achieves state-of-the-art results for a valid MIL model on standard MIL benchmarks and medical imaging datasets, outperforming existing methods while maintaining strict adherence to the MIL formulation. This work offers a principled, interpretable, and effective alternative to existing MIL approaches that rely on learned heuristics.

</details>


### [7] [A Robust Federated Learning Approach for Combating Attacks Against IoT Systems Under non-IID Challenges](https://arxiv.org/abs/2511.16822)
*Eyad Gad,Zubair Md Fadlullah,Mostafa M. Fouda*

Main category: cs.LG

TL;DR: 该研究比较了FedAvg、FedProx和Scaffold三种联邦学习算法在不同数据分布下对物联网攻击检测的性能，旨在解决统计异质性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中设备资源受限且数据隐私敏感，传统机器学习面临挑战。联邦学习能解决这些问题，但非独立同分布数据的统计异质性严重影响了联邦学习的有效性。

Method: 使用CICIoT2023数据集进行大规模物联网攻击分类，在不同数据分布下比较FedAvg、FedProx和Scaffold三种联邦学习算法的性能。

Result: 通过细致的分析和实验，揭示了这些联邦学习方法在物联网攻击检测中的性能差异。

Conclusion: 该研究为物联网安全领域的联邦学习应用提供了有价值的见解，帮助研究者和实践者更好地应对统计异质性挑战。

Abstract: In the context of the growing proliferation of user devices and the concurrent surge in data volumes, the complexities arising from the substantial increase in data have posed formidable challenges to conventional machine learning model training. Particularly, this is evident within resource-constrained and security-sensitive environments such as those encountered in networks associated with the Internet of Things (IoT). Federated Learning has emerged as a promising remedy to these challenges by decentralizing model training to edge devices or parties, effectively addressing privacy concerns and resource limitations. Nevertheless, the presence of statistical heterogeneity in non-Independently and Identically Distributed (non-IID) data across different parties poses a significant hurdle to the effectiveness of FL. Many FL approaches have been proposed to enhance learning effectiveness under statistical heterogeneity. However, prior studies have uncovered a gap in the existing research landscape, particularly in the absence of a comprehensive comparison between federated methods addressing statistical heterogeneity in detecting IoT attacks. In this research endeavor, we delve into the exploration of FL algorithms, specifically FedAvg, FedProx, and Scaffold, under different data distributions. Our focus is on achieving a comprehensive understanding of and addressing the challenges posed by statistical heterogeneity. In this study, We classify large-scale IoT attacks by utilizing the CICIoT2023 dataset. Through meticulous analysis and experimentation, our objective is to illuminate the performance nuances of these FL methods, providing valuable insights for researchers and practitioners in the domain.

</details>


### [8] [Monte Carlo Expected Threat (MOCET) Scoring](https://arxiv.org/abs/2511.16823)
*Joseph Kim,Saahith Potluri*

Main category: cs.LG

TL;DR: 提出了MOCET指标，一种可解释且双重可扩展的指标，用于量化AI模型在生物安全等领域的真实世界风险


<details>
  <summary>Details</summary>
Motivation: 现有评估指标如LAB-Bench、BioLP-bench和WMDP能可靠评估模型提升能力和领域知识，但缺乏能更好衡量"真实世界风险"的指标，需要可扩展的开放指标来跟上LLM的快速发展

Method: 引入MOCET指标，该指标具有可解释性和双重可扩展性（可自动化和开放），能够量化真实世界风险

Result: MOCET能够解决现有评估指标的不足，为LLM安全案例提供更好的风险背景化评估

Conclusion: MOCET是填补AI安全评估空白的重要工具，特别适用于ASL-3+模型在生物安全等领域的风险评估

Abstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize "real-world risks" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.

</details>


### [9] [ManifoldFormer: Geometric Deep Learning for Neural Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2511.16828)
*Yihang Fu,Lifang He,Qingyu Chen*

Main category: cs.LG

TL;DR: ManifoldFormer是一个几何深度学习框架，通过显式学习神经流形表示来解决现有EEG基础模型忽略神经动态内在几何结构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有EEG基础模型将神经信号视为欧几里得空间中的通用时间序列，忽略了约束大脑活动到低维流形的神经动态内在几何结构，这种基本不匹配限制了表示质量和跨被试泛化能力。

Method: 集成三个关键创新：用于保持几何结构的黎曼VAE进行流形嵌入、在神经流形上直接操作的具有测地线感知注意力机制的几何Transformer、以及利用神经ODE进行流形约束时间演化的动态预测器。

Result: 在四个公共数据集上的广泛评估显示，相比最先进方法有显著改进，准确率提高4.6-4.8%，Cohen's Kappa提高6.2-10.2%，同时保持强大的跨被试泛化能力。

Conclusion: 几何方法揭示了与神经生理学原理一致的有意义神经模式，确立了几何约束对于有效EEG基础模型的重要性。

Abstract: Existing EEG foundation models mainly treat neural signals as generic time series in Euclidean space, ignoring the intrinsic geometric structure of neural dynamics that constrains brain activity to low-dimensional manifolds. This fundamental mismatch between model assumptions and neural geometry limits representation quality and cross-subject generalization. ManifoldFormer addresses this limitation through a novel geometric deep learning framework that explicitly learns neural manifold representations. The architecture integrates three key innovations: a Riemannian VAE for manifold embedding that preserves geometric structure, a geometric Transformer with geodesic-aware attention mechanisms operating directly on neural manifolds, and a dynamics predictor leveraging neural ODEs for manifold-constrained temporal evolution. Extensive evaluation across four public datasets demonstrates substantial improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and 6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject generalization. The geometric approach reveals meaningful neural patterns consistent with neurophysiological principles, establishing geometric constraints as essential for effective EEG foundation models.

</details>


### [10] [Analysis of heart failure patient trajectories using sequence modeling](https://arxiv.org/abs/2511.16839)
*Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: 本文比较了Transformer、Transformer++和Mamba三种架构在心脏病患者临床预测任务中的表现，发现Llama（Transformer++）在预测区分度、校准性和鲁棒性方面表现最佳，Mamba次之。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer和Mamba架构在临床预测任务中表现出色，但医学领域缺乏系统分析模型性能和效率的方法。本研究旨在填补这一空白。

Method: 在42820名瑞典心衰患者队列中，评估了六种序列模型在三个一年期预测任务上的表现，包括临床不稳定、死亡率等。进行了输入序列修改、架构配置和数据预处理技术的消融实验。

Result: Llama实现了最高的预测区分度和最佳校准，在所有任务中表现出鲁棒性，Mamba次之。两种架构在模型规模相同时，使用25%更少的训练数据就能达到优越性能。

Conclusion: 本研究首次提供了临床预测任务中系统设计选择的消融研究，为未来基于EHR的模型开发提供了起点建议。

Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long context lengths, while using fewer model parameters. Despite the impressive performance of these architectures, a systematic approach to empirically analyze model performance and efficiency under various settings is not well established in the medical domain. The performances of six sequence models were investigated across three architecture classes (Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF) cohort (N = 42820), providing a clinically relevant case study. Patient data included diagnoses, vital signs, laboratories, medications and procedures extracted from in-hospital EHRs. The models were evaluated on three one-year prediction tasks: clinical instability (a readmission phenotype) after initial HF hospitalization, mortality after initial HF hospitalization and mortality after latest hospitalization. Ablations account for modifications of the EHR-based input patient sequence, architectural model configurations, and temporal preprocessing techniques for data collection. Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas. Both architectures demonstrate efficient representation learning, with tiny configurations surpassing other large-scaled Transformers. At equal model size, Llama and Mambas achieve superior performance using 25% less training data. This paper presents a first ablation study with systematic design choices for input tokenization, model configuration and temporal data preprocessing. Future model development in clinical prediction tasks using EHRs could build upon this study's recommendation as a starting point.

</details>


### [11] [Provably Minimum-Length Conformal Prediction Sets for Ordinal Classification](https://arxiv.org/abs/2511.16845)
*Zijian Zhang,Xinyu Chen,Yuanjie Shi,Liyuan Lillian Ma,Zifan Xu,Yan Yan*

Main category: cs.LG

TL;DR: 提出了一种用于序数分类的保形预测方法，该方法模型无关且提供实例级最优预测区间，通过滑动窗口算法实现线性时间复杂度，显著提高了预测效率。


<details>
  <summary>Details</summary>
Motivation: 现有序数保形预测方法要么依赖启发式算法，要么要求基础模型预测单峰分布，限制了覆盖效率权衡的分析能力，缺乏模型无关和分布无关的特性。

Method: 将序数保形分类建模为实例级最小长度覆盖问题，开发线性时间复杂度的滑动窗口算法，并提出长度正则化变体以缩小预测集大小同时保持覆盖。

Result: 在四个不同领域的基准数据集上实验表明，相比基线方法平均减少15%的预测集大小，显著提高了预测效率。

Conclusion: 该方法填补了序数保形预测的空白，提供了模型无关、分布无关的实例级最优预测区间，在保持统计有效性的同时显著提升预测效率。

Abstract: Ordinal classification has been widely applied in many high-stakes applications, e.g., medical imaging and diagnosis, where reliable uncertainty quantification (UQ) is essential for decision making. Conformal prediction (CP) is a general UQ framework that provides statistically valid guarantees, which is especially useful in practice. However, prior ordinal CP methods mainly focus on heuristic algorithms or restrictively require the underlying model to predict a unimodal distribution over ordinal labels. Consequently, they provide limited insight into coverage-efficiency trade-offs, or a model-agnostic and distribution-free nature favored by CP methods. To this end, we fill this gap by propose an ordinal-CP method that is model-agnostic and provides instance-level optimal prediction intervals. Specifically, we formulate conformal ordinal classification as a minimum-length covering problem at the instance level. To solve this problem, we develop a sliding-window algorithm that is optimal on each calibration data, with only a linear time complexity in K, the number of label candidates. The local optimality per instance further also improves predictive efficiency in expectation. Moreover, we propose a length-regularized variant that shrinks prediction set size while preserving coverage. Experiments on four benchmark datasets from diverse domains are conducted to demonstrate the significantly improved predictive efficiency of the proposed methods over baselines (by 15% decrease on average over four datasets).

</details>


### [12] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 提出了一个封建Q学习方案，分析了其收敛和稳定性条件，通过随机逼近理论和ODE方法证明了收敛性，并将其解释为博弈均衡点。


<details>
  <summary>Details</summary>
Motivation: 分层强化学习在捕捉决策问题的时间结构和增强持续学习能力方面有潜力，但理论保证落后于实践，需要提供收敛和稳定性分析。

Method: 使用封建Q学习方案，利用随机逼近理论和ODE方法进行收敛性分析，将更新过程解释为博弈均衡。

Result: 证明了封建Q学习在特定条件下的收敛性和稳定性，实验验证了理论预期结果。

Conclusion: 为封建强化学习提供了原则性的收敛和稳定性分析，为分层强化学习的博弈论方法开辟了新途径。

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [13] [Sex and age determination in European lobsters using AI-Enhanced bioacoustics](https://arxiv.org/abs/2511.16848)
*Feliciano Pedro Francisco Domingos,Isibor Kennedy Ihianle,Omprakash Kaiwartya,Ahmad Lotfi,Nicola Khan,Nicholas Beaudreau,Amaya Albalat,Pedro Machado*

Main category: cs.LG

TL;DR: 本研究利用欧洲龙虾的生物声学特征（嗡嗡声/甲壳振动），通过深度学习和机器学习模型成功实现了对龙虾年龄（幼体/成体）和性别（雄/雌）的高精度分类。


<details>
  <summary>Details</summary>
Motivation: 监测水生生物，特别是像龙虾这样的难以追踪物种存在挑战。了解龙虾的栖息地、福利、繁殖、性别和年龄对于管理和保护至关重要。

Method: 使用被动声学监测收集数据，采用深度学习模型（1D-CNN、1D-DCNN）和六种机器学习模型（SVM、k-NN、朴素贝叶斯、随机森林、XGBoost、MLP），以MFCC作为特征。

Result: 年龄分类准确率超过97%（朴素贝叶斯为91.31%），性别分类除朴素贝叶斯外所有模型均超过93.23%。

Conclusion: 研究表明监督机器学习和深度学习能够从龙虾声音中提取与年龄和性别相关的特征，为非侵入性PAM方法在龙虾保护、检测和管理中提供了有前景的应用。

Abstract: Monitoring aquatic species, especially elusive ones like lobsters, presents challenges. This study focuses on Homarus gammarus (European lobster), a key species for fisheries and aquaculture, and leverages non-invasive Passive Acoustic Monitoring (PAM). Understanding lobster habitats, welfare, reproduction, sex, and age is crucial for management and conservation. While bioacoustic emissions have classified various aquatic species using Artificial Intelligence (AI) models, this research specifically uses H. gammarus bioacoustics (buzzing/carapace vibrations) to classify lobsters by age (juvenile/adult) and sex (male/female).
  The dataset was collected at Johnshaven, Scotland, using hydrophones in concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN, 1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as features.
  For age classification (adult vs. juvenile), most models achieved over 97% accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive Bayes surpassed 93.23%. These strong results demonstrate the potential of supervised ML and DL to extract age- and sex-related features from lobster sounds. This research offers a promising non-invasive PAM approach for lobster conservation, detection, and management in aquaculture and fisheries, enabling real-world edge computing applications for underwater species.

</details>


### [14] [Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization](https://arxiv.org/abs/2511.17489)
*Vinay Kanakeri,Shivam Bajaj,Ashwin Verma,Vijay Gupta,Aritra Mitra*

Main category: cs.LG

TL;DR: 提出一种结合聚类和学习的算法，用于多智能体线性二次调节器(LQR)控制问题，通过聚类相似的系统来学习个性化策略，提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习通常需要大量数据，为了提高样本效率，可以利用来自'近似相似'过程的数据。但由于过程模型未知，识别哪些其他过程相似具有挑战性。

Method: 结合顺序消除和零阶策略优化的思想，提出同时进行聚类和学习的算法，为每个聚类输出个性化策略。

Result: 在适当的聚类分离条件下，证明了算法能高概率正确聚类，且每个聚类学习到的策略的次优性差距与聚类大小成反比，没有额外偏差。

Conclusion: 这是首个揭示聚类如何在数据驱动控制中用于学习个性化策略的工作，既能享受协作带来的统计增益，又不会因包含不相似过程的数据而遭受次优性。

Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.

</details>


### [15] [Better audio representations are more brain-like: linking model-brain alignment with performance in downstream auditory tasks](https://arxiv.org/abs/2511.16849)
*Leonardo Pepino,Pablo Riera,Juan Kamienkowski,Luciana Ferrer*

Main category: cs.LG

TL;DR: 研究发现，在听觉领域，自监督音频模型的任务性能与大脑表示对齐度呈正相关，且大脑相似性在预训练过程中会自然涌现。


<details>
  <summary>Details</summary>
Motivation: 探究人工神经网络在提升任务性能时，其内部表示是否也更接近大脑信号，特别是在听觉领域。

Method: 使用36种不同音频模型，通过体素回归、成分回归和表示相似性分析，评估模型与两个独立fMRI数据集的脑活动对齐度，并在HEAREval基准的6个听觉任务中评估模型性能。

Result: 发现近期自监督音频模型比旧模型和专门化模型更能预测听觉皮层活动，模型整体任务性能与大脑表示对齐度呈强正相关（r>0.7），且EnCodecMAE预训练过程中大脑相似性会逐步增加。

Conclusion: 大脑样表示可以从自然音频数据中重建缺失信息的学习过程中自然涌现，而不需要明确优化这一目标。

Abstract: Artificial neural networks (ANNs) are increasingly powerful models of brain computation, yet it remains unclear whether improving their task performance also makes their internal representations more similar to brain signals. To address this question in the auditory domain, we quantified the alignment between the internal representations of 36 different audio models and brain activity from two independent fMRI datasets. Using voxel-wise and component-wise regression, and representation similarity analysis (RSA), we found that recent self-supervised audio models with strong performance in diverse downstream tasks are better predictors of auditory cortex activity than older and more specialized models. To assess the quality of the audio representations, we evaluated these models in 6 auditory tasks from the HEAREval benchmark, spanning music, speech, and environmental sounds. This revealed strong positive Pearson correlations ($r>0.7$) between a model's overall task performance and its alignment with brain representations. Finally, we analyzed the evolution of the similarity between audio and brain representations during the pretraining of EnCodecMAE. We discovered that brain similarity increases progressively and emerges early during pretraining, despite the model not being explicitly optimized for this objective. This suggests that brain-like representations can be an emergent byproduct of learning to reconstruct missing information from naturalistic audio data.

</details>


### [16] [The use of vocal biomarkers in the detection of Parkinson's disease: a robust statistical performance comparison of classic machine learning models](https://arxiv.org/abs/2511.16856)
*Katia Pires Nascimento do Sacramento,Elliot Q. C. Garcia,Nicéias Silva Vilela,Vinicius P. Sacramento,Tiago A. E. Ferreira*

Main category: cs.LG

TL;DR: 本研究评估了深度神经网络（DNN）在利用语音生物标志物区分帕金森病患者与健康对照者方面的有效性，与传统机器学习方法相比，DNN在两个公开语音数据集上表现出更优性能。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期常伴有语音障碍，使用语音生物标志物进行早期诊断具有非侵入性、低成本和临床可及性等优势。

Method: 使用两个公开语音数据集，提取梅尔频率倒谱系数（MFCCs），采用1000次独立随机执行的验证策略评估模型鲁棒性，使用非参数检验比较不同分类模型的性能。

Result: DNN在意大利语音数据集和帕金森远程监测数据集上的平均准确率分别达到98.65%和92.11%，显著优于传统机器学习模型。

Conclusion: 研究证实了DNN在利用语音生物标志物进行神经退行性疾病早期检测方面的效率和潜力，能够提供更高的准确性和可靠性。

Abstract: Parkinson's disease (PD) is a progressive neurodegenerative disorder that, in addition to directly impairing functional mobility, is frequently associated with vocal impairments such as hypophonia and dysarthria, which typically manifest in the early stages. The use of vocal biomarkers to support the early diagnosis of PD presents a non-invasive, low-cost, and accessible alternative in clinical settings. Thus, the objective of this cross-sectional study was to consistently evaluate the effectiveness of a Deep Neural Network (DNN) in distinguishing individuals with Parkinson's disease from healthy controls, in comparison with traditional Machine Learning (ML) methods, using vocal biomarkers. Two publicly available voice datasets were used. Mel-frequency cepstral coefficients (MFCCs) were extracted from the samples, and model robustness was assessed using a validation strategy with 1000 independent random executions. Performance was evaluated using classification statistics. Since normality assumptions were not satisfied, non-parametric tests (Kruskal-Wallis and Bonferroni post-hoc tests) were applied to verify whether the tested classification models were similar or different in the classification of PD. With an average accuracy of $98.65\%$ and $92.11\%$ on the Italian Voice dataset and Parkinson's Telemonitoring dataset, respectively, the DNN demonstrated superior performance and efficiency compared to traditional ML models, while also achieving competitive results when benchmarked against relevant studies. Overall, this study confirms the efficiency of DNNs and emphasizes their potential to provide greater accuracy and reliability for the early detection of neurodegenerative diseases using voice-based biomarkers.

</details>


### [17] [Topologic Attention Networks: Attending to Direct and Indirect Neighbors through Gaussian Belief Propagation](https://arxiv.org/abs/2511.16871)
*Marshall Rosenhoover,Huaming Zhang*

Main category: cs.LG

TL;DR: 提出拓扑注意力网络，通过概率机制学习信息在图中的直接和间接连接流动，解决图神经网络长距离依赖建模问题


<details>
  <summary>Details</summary>
Motivation: 图神经网络依赖局部消息传递，难以建模图中的长距离依赖关系，现有方法计算成本高且可扩展性有限

Method: 使用拓扑注意力机制，该机制从图的学习信息传播中产生，能够统一推理局部和全局关系，不依赖显式的成对交互

Result: 在所有测量的基线模型上实现了最先进的性能

Conclusion: 拓扑注意力网络提供了一种有效建模图中长距离依赖关系的新框架，具有更好的计算效率和可扩展性

Abstract: Graph Neural Networks rely on local message passing, which limits their ability to model long-range dependencies in graphs. Existing approaches extend this range through continuous-time dynamics or dense self-attention, but both suffer from high computational cost and limited scalability. We propose Topologic Attention Networks, a new framework that applies topologic attention, a probabilistic mechanism that learns how information should flow through both direct and indirect connections in a graph. Unlike conventional attention that depends on explicit pairwise interactions, topologic attention emerges from the learned information propagation of the graph, enabling unified reasoning over local and global relationships. This method achieves provides state-of-the-art performance across all measured baseline models. Our implementation is available at https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks.

</details>


### [18] [PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling](https://arxiv.org/abs/2511.16883)
*Zhongjie Dai,Tao Feng,Jiaxuan You*

Main category: cs.LG

TL;DR: 提出了PersonalizedRouter框架，通过图结构建模用户偏好，实现个性化LLM选择，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着多样化LLM的出现，用户在选择合适LLM时面临挑战，现有方法无法从交互数据中学习个体用户偏好。

Method: 将交互数据转换为异构图，建模任务上下文、查询、候选LLM和用户决策之间的关系，使用两种策略评估跨用户适应性。

Result: 在两种模拟策略下分别超越最强方法15.38%和9.83%，在1000用户基准上分别提升16.19%和59.69%，同时保持更高效率。

Conclusion: PersonalizedRouter在个性化LLM选择方面表现优异，具有强大的少样本泛化能力，能适应新用户和新LLM。

Abstract: The growing number of Large Language Models (LLMs) with diverse capabilities and response styles provides users with a wider range of choices, which presents challenges in selecting appropriate LLMs, as user preferences vary in terms of performance, cost, and response style. Current LLM selection methods typically optimize for a single fixed objective, such as performance, cost, or a trade-off between them, and fail to learn individual user preferences from interaction data. To address these limitations, we propose PersonalizedRouter, a graph-based framework that models diverse user profiles and performs personalized LLM selection by leveraging interaction data that includes task context, queries, candidate LLMs, and user decisions. To capture contextual information between user queries and optimal LLMs, PersonalizedRouter converts the interaction data into a heterogeneous graph, where the relationships between different types of nodes are represented by edges. To evaluate adaptability across users, we design two strategies: the multi-cost-efficiency simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10 LLMs. Experimental results show that PersonalizedRouter significantly outperforms existing LLM selection methods and surpasses the strongest methods by a large margin of 15.38% and 9.83% under two simulation strategies. On the PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by 16.19% and 59.69% while maintaining higher efficiency. Moreover, PersonalizedRouter demonstrates strong few-shot generalization, achieving 64.81% and 85.80% of the fully trained model's performance when adapting to new users and new LLMs.

</details>


### [19] [Predicting Talent Breakout Rate using Twitter and TV data](https://arxiv.org/abs/2511.16905)
*Bilguun Batsaikhan,Hiroyuki Fukuda*

Main category: cs.LG

TL;DR: 该研究提出了一种结合Twitter和电视数据来预测日本艺人爆红的方法，比较了传统时间序列模型、神经网络和集成学习方法在艺人爆红预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 在广告领域早期发现潜在人才至关重要，研究旨在探索结合社交媒体和电视数据是否能有效预测艺人爆红，并比较不同建模方法的预测能力。

Method: 定义了艺人爆红概念，结合Twitter和电视数据，实验了传统时间序列模型、神经网络和集成学习方法，使用标准回归指标和爆红预测的精确度、召回率进行评估。

Result: 集成学习方法在标准回归指标上表现最佳，但在艺人爆红预测的精确度和召回率方面，神经网络模型优于传统方法和集成学习方法。

Conclusion: 结合Twitter和电视数据可以有效预测艺人爆红，神经网络在爆红预测任务中展现出更好的预测能力，尽管集成学习在标准回归指标上表现更好。

Abstract: Early detection of rising talents is of paramount importance in the field of advertising. In this paper, we define a concept of talent breakout and propose a method to detect Japanese talents before their rise to stardom. The main focus of the study is to determine the effectiveness of combining Twitter and TV data on predicting time-dependent changes in social data. Although traditional time-series models are known to be robust in many applications, the success of neural network models in various fields (e.g.\ Natural Language Processing, Computer Vision, Reinforcement Learning) continues to spark an interest in the time-series community to apply new techniques in practice. Therefore, in order to find the best modeling approach, we have experimented with traditional, neural network and ensemble learning methods. We observe that ensemble learning methods outperform traditional and neural network models based on standard regression metrics. However, by utilizing the concept of talent breakout, we are able to assess the true forecasting ability of the models, where neural networks outperform traditional and ensemble learning methods in terms of precision and recall.

</details>


### [20] [PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage](https://arxiv.org/abs/2511.16912)
*Trieu Nguyen,Hao-Wei Pang,Shasha Feng*

Main category: cs.LG

TL;DR: PepEVOLVE是一个用于多肽先导化合物优化的动态框架，能够自动学习编辑位置并优化多目标属性，相比现有方法在Rev结合大环肽基准测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的大环肽优化方法如PepINVENT需要预先指定可突变位置，且使用静态预训练和优化算法，限制了模型的泛化能力和优化效果。

Method: PepEVOLVE采用动态掩码和CHUCKLES移位增强预训练，使用上下文无关多臂老虎机路由器发现高奖励残基，结合演化优化算法和组相对优势稳定强化学习更新。

Result: 在Rev结合大环肽基准测试中，PepEVOLVE达到更高平均分数（约0.8 vs 0.6），最佳候选分数0.95（vs 0.87），且在优化渗透性和亲脂性时收敛更快。

Conclusion: PepEVOLVE为多肽先导化合物优化提供了实用且可复现的路径，能够在编辑位置未知时实现更高效的探索和跨多目标的设计质量提升。

Abstract: Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.

</details>


### [21] [A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests](https://arxiv.org/abs/2511.16923)
*Ali Anaissi,Deshao Liu,Yuanzhe Jia,Weidong Huang,Widad Alyassine,Junaid Akram*

Main category: cs.LG

TL;DR: SCR-MF是一个两阶段工作流，结合scRecover进行dropout检测和missForest进行非参数插补，在单细胞RNA测序中提供稳健且可解释的性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序存在普遍的dropout事件，这会掩盖生物信号，需要有效的插补方法来恢复丢失的数据。

Method: 采用模块化两阶段工作流：第一阶段使用scRecover进行dropout检测，第二阶段使用missForest进行非参数插补。

Result: 在公共和模拟数据集上，SCR-MF在大多数情况下达到或超过现有插补方法的性能，同时保持生物保真度和透明度。

Conclusion: SCR-MF在准确性和计算效率之间提供了有竞争力的平衡，适用于中等规模单细胞数据集。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.

</details>


### [22] [CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection](https://arxiv.org/abs/2511.16929)
*Rui Xue,Dan He,Fengmei Jin,Chen Zhang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: 提出了CroTad框架，一种基于对比强化学习的在线轨迹异常检测方法，能够无阈值、鲁棒地检测子轨迹和点级异常，适用于不规则采样的轨迹数据。


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统中轨迹异常检测的关键挑战：子轨迹异常检测研究不足、现有方法依赖阈值调整、不规则采样数据和训练集噪声影响模型性能。

Method: 结合对比学习和强化学习，通过对比学习提取不同行程的正常旅行模式，利用深度强化学习进行在线实时异常评分，实现细粒度异常检测。

Result: 在两个真实世界数据集上的广泛实验表明，该框架在各种评估场景下都具有有效性和鲁棒性。

Conclusion: CroTad框架能够有效解决轨迹异常检测中的关键问题，提供无阈值、鲁棒的在线检测能力，适用于现实世界应用。

Abstract: Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.

</details>


### [23] [A novel approach to classification of ECG arrhythmia types with latent ODEs](https://arxiv.org/abs/2511.16933)
*Angelina Yan,Matt L. Sampson,Peter Melchior*

Main category: cs.LG

TL;DR: 提出了一种端到端的心电图分类方法，使用潜在ODE建模连续ECG波形，通过降采样处理不同频率信号，在保持高分类性能的同时解决了可穿戴设备电池寿命与信号保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 12导联ECG虽然采样频率高但监测时间短，容易错过间歇性事件；可穿戴ECG可以长期监测但受电池限制采样频率低且不规则，形态分析困难。需要解决信号保真度与电池寿命之间的权衡。

Method: 训练潜在ODE模型连续ECG波形，从高频单通道信号创建鲁棒特征向量。将初始360Hz ECG降采样到90Hz和45Hz，为每个波形构建三个潜在向量，然后使用梯度提升树进行分类。

Result: 在不同频率下性能下降最小，宏平均AUC-ROC值在360Hz、90Hz和45Hz下分别为0.984、0.978和0.976，表明该方法能有效绕过信号保真度与电池寿命的权衡。

Conclusion: 该方法使更小的可穿戴设备成为可能，促进了心脏健康的长期监测，为可穿戴ECG设备提供了实用的解决方案。

Abstract: 12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.

</details>


### [24] [ToC: Tree-of-Claims Search with Multi-Agent Language Models](https://arxiv.org/abs/2511.16972)
*Shuyang Yu,Jianan Liang,Hui Hu*

Main category: cs.LG

TL;DR: Tree of Claims (ToC) 是一个结合蒙特卡洛树搜索和多智能体系统的专利权利要求优化框架，显著优于标准LLM方法，在1145个权利要求基准测试中平均综合得分提升8%。


<details>
  <summary>Details</summary>
Motivation: 传统专利权利要求撰写劳动密集、成本高且不一致，而常规大语言模型缺乏结构化迭代推理能力，无法进行精确的权利要求优化。

Method: ToC将权利要求编辑重新定义为引导搜索问题，集成蒙特卡洛树搜索与多智能体系统：EditorAgent提出基于上下文的编辑建议，ExaminerAgent通过结构化思维链分析新颖性和现有技术披露。

Result: 在1145个权利要求基准测试中，ToC在零样本和少样本场景下显著优于标准LLM，平均综合得分提升8%，某些情况下提升达9%。

Conclusion: ToC建立了一个透明、可控且可解释的方法论，有效将先进的LLM推理能力与战略性MCTS规划相结合，实现结构化专利权利要求优化。

Abstract: Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\%, and up to 9\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.

</details>


### [25] [Gradient flow for deep equilibrium single-index models](https://arxiv.org/abs/2511.16976)
*Sanjit Dandapanthula,Aaditya Ramdas*

Main category: cs.LG

TL;DR: 本文研究了深度平衡模型(DEQs)在梯度下降训练中的理论特性，在线性模型和单索引模型设置下证明了参数守恒定律、梯度流良好条件性以及线性收敛到全局最优解。


<details>
  <summary>Details</summary>
Motivation: 深度平衡模型在实践上取得了显著成功，但对其梯度下降动态的理论理解仍是一个活跃研究领域，需要填补现有文献中的理论空白。

Method: 在线性DEQs和深度平衡单索引模型的简单设置下，通过数学分析证明了参数守恒定律，并利用这一性质分析梯度流条件性和收敛性。

Result: 证明了线性DEQs的参数在训练过程中保持球面约束，梯度流始终保持良好条件，并在适当初始化和小步长下梯度下降能线性收敛到全局最优解。

Conclusion: 该研究为深度平衡模型的训练动态提供了严格的理论保证，验证了梯度下降方法在DEQs训练中的有效性。

Abstract: Deep equilibrium models (DEQs) have recently emerged as a powerful paradigm for training infinitely deep weight-tied neural networks that achieve state of the art performance across many modern machine learning tasks. Despite their practical success, theoretically understanding the gradient descent dynamics for training DEQs remains an area of active research. In this work, we rigorously study the gradient descent dynamics for DEQs in the simple setting of linear models and single-index models, filling several gaps in the literature. We prove a conservation law for linear DEQs which implies that the parameters remain trapped on spheres during training and use this property to show that gradient flow remains well-conditioned for all time. We then prove linear convergence of gradient descent to a global minimizer for linear DEQs and deep equilibrium single-index models under appropriate initialization and with a sufficiently small step size. Finally, we validate our theoretical findings through experiments.

</details>


### [26] [FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models](https://arxiv.org/abs/2511.16992)
*Fatemeh,Nourzad,Amirhossein Roknilamouki,Eylem Ekici,Jia,Liu,Ness B. Shroff*

Main category: cs.LG

TL;DR: FIRM是一种联邦多目标对齐算法，通过客户端内正则化解决多目标冲突，无需传输多个梯度，实现通信效率和客户端分歧漂移缓解。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对齐需要平衡多个冲突目标（如帮助性和无害性），集中训练存在计算密集和数据隐私问题，现有联邦多目标优化方法因依赖多梯度传输而面临通信瓶颈。

Method: 每个客户端本地解决正则化多目标优化问题，通过客户端内正则化直接缓解客户端分歧漂移，只需传输单组适配参数，保持高通信效率。

Result: 算法收敛到帕累托稳定点，提供有限时间收敛保证；实证显示训练动态更平滑，客户端分歧漂移减少，奖励权衡改善，并能根据偏好平滑调整目标权衡。

Conclusion: FIRM在联邦多目标对齐中实现了通信效率和客户端分歧漂移缓解，为大规模模型对齐提供了可行的联邦学习解决方案。

Abstract: Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.

</details>


### [27] [Mask the Redundancy: Evolving Masking Representation Learning for Multivariate Time-Series Clustering](https://arxiv.org/abs/2511.17008)
*Zexi Tan,Xiaopeng Luo,Yunlin Liu,Yiqun Zhang*

Main category: cs.LG

TL;DR: 提出EMTC方法，通过重要性感知的变量级掩码和多内生视图表示学习模块，解决多元时间序列聚类中冗余信息导致性能瓶颈的问题。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列包含大量冗余信息（如稳态机器运行记录、太阳能发电的零输出期），这些冗余降低了表示学习中对判别性时间戳的关注，导致聚类性能瓶颈。现有掩码策略多为独立预处理步骤，无法动态适应聚类关键时间戳的重要性变化。

Method: 提出EMTC方法，包含重要性感知变量级掩码(IVM)和多内生视图(MEV)表示学习模块。IVM自适应引导模型学习更具判别性的聚类表示，MEV通过重建和对比学习路径增强泛化能力。

Result: 在15个真实基准数据集上的实验表明，EMTC优于8种最先进方法，平均比最强基线提升4.85%。

Conclusion: EMTC通过动态掩码和多重表示学习有效解决了多元时间序列聚类中的冗余问题，显著提升了聚类性能。

Abstract: Multivariate Time-Series (MTS) clustering discovers intrinsic grouping patterns of temporal data samples. Although time-series provide rich discriminative information, they also contain substantial redundancy, such as steady-state machine operation records and zero-output periods of solar power generation. Such redundancy diminishes the attention given to discriminative timestamps in representation learning, thus leading to performance bottlenecks in MTS clustering. Masking has been widely adopted to enhance the MTS representation, where temporal reconstruction tasks are designed to capture critical information from MTS. However, most existing masking strategies appear to be standalone preprocessing steps, isolated from the learning process, which hinders dynamic adaptation to the importance of clustering-critical timestamps. Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC) method, with its model architecture composed of Importance-aware Variate-wise Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules. IVM adaptively guides the model in learning more discriminative representations for clustering, while the MEV-based reconstruction and contrastive learning pathways enhance the generalization. That is, the MEV reconstruction facilitates multi-perspective complementary to prevent the masking from premature convergence, and the clustering-guided contrastive learning facilitates the joint optimization of representation and clustering. Extensive experiments on 15 real benchmark datasets demonstrate the superiority of EMTC in comparison with eight SOTA methods, where the EMTC achieves an average improvement of 4.85% over the strongest baselines.

</details>


### [28] [Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon Emissions in Image Generation](https://arxiv.org/abs/2511.17031)
*Aniketh Iyengar,Jiaqi Han,Boris Ruf,Vincent Grari,Marcin Detyniecki,Stefano Ermon*

Main category: cs.LG

TL;DR: 将Kaplan缩放定律应用于扩散模型，基于计算复杂度预测GPU能耗，验证了扩散推理的计算受限特性，为可持续AI部署提供基础


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中的计算需求快速增长，引发了对能耗和环境影响的担忧，但缺乏跨模型配置和硬件设置的能耗预测方法

Method: 将扩散模型推理分解为文本编码、迭代去噪和解码组件，假设去噪操作因多次执行而主导能耗，在多种扩散模型和GPU架构上进行实验

Result: 能耗缩放定律在单个架构内预测精度高（R平方>0.9），跨架构泛化能力强，保持高秩相关性，能可靠估计未见模型-硬件组合的能耗

Conclusion: 验证了扩散推理的计算受限特性，为可持续AI部署规划和碳足迹估算提供了理论基础

Abstract: The rapidly growing computational demands of diffusion models for image generation have raised significant concerns about energy consumption and environmental impact. While existing approaches to energy optimization focus on architectural improvements or hardware acceleration, there is a lack of principled methods to predict energy consumption across different model configurations and hardware setups. We propose an adaptation of Kaplan scaling laws to predict GPU energy consumption for diffusion models based on computational complexity (FLOPs). Our approach decomposes diffusion model inference into text encoding, iterative denoising, and decoding components, with the hypothesis that denoising operations dominate energy consumption due to their repeated execution across multiple inference steps. We conduct comprehensive experiments across four state-of-the-art diffusion models (Stable Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures (NVIDIA A100, A4000, A6000), spanning various inference configurations including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts (10-50), and classifier-free guidance settings. Our energy scaling law achieves high predictive accuracy within individual architectures (R-squared > 0.9) and exhibits strong cross-architecture generalization, maintaining high rank correlations across models and enabling reliable energy estimation for unseen model-hardware combinations. These results validate the compute-bound nature of diffusion inference and provide a foundation for sustainable AI deployment planning and carbon footprint estimation.

</details>


### [29] [Why Do Language Model Agents Whistleblow?](https://arxiv.org/abs/2511.17085)
*Kushal Agrawal,Frank Xiao,Guido Bergman,Asa Cooper Stickland*

Main category: cs.LG

TL;DR: 研究大型语言模型作为工具使用代理时的举报行为，发现模型会在未经用户指示的情况下向外部机构披露可疑不当行为，并通过评估套件分析了影响举报频率的因素。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型作为工具使用代理的部署，其对齐训练会以新的方式体现。研究发现语言模型可能以违背用户利益或明确指示的方式使用工具，特别是未经用户指示向外部披露可疑不当行为的举报行为。

Method: 引入包含多样化和现实化不当行为场景的评估套件，测试不同模型和设置下的举报行为，包括任务复杂性、系统提示的道德引导、可用工具和工作流程等因素的影响。

Result: 研究发现：(1)不同模型家族的举报频率差异很大；(2)增加任务复杂性会降低举报倾向；(3)系统提示中的道德引导显著提高举报率；(4)提供更多工具和详细工作流程会减少举报率。同时验证了数据集对模型评估意识的鲁棒性。

Conclusion: 大型语言模型在作为工具使用代理时确实会表现出未经用户指示的举报行为，这种行为受多种因素影响，研究为理解和控制此类行为提供了评估框架和实证基础。

Abstract: The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.

</details>


### [30] [Step-E: A Differentiable Data Cleaning Framework for Robust Learning with Noisy Labels](https://arxiv.org/abs/2511.17040)
*Wenzhang Du*

Main category: cs.LG

TL;DR: Step-E是一个将样本选择和模型学习集成到单一优化过程中的简单框架，通过按损失对样本排序并逐步排除高损失样本，有效处理噪声标签和异常值。


<details>
  <summary>Details</summary>
Motivation: 野外收集的训练数据通常包含噪声标签和异常值，这会严重降低深度神经网络的性能和可靠性。传统的数据清洗作为单独预处理阶段存在不足，无法充分利用下游模型的反馈或适应未知的噪声模式。

Method: 在每个训练周期，Step-E按损失对样本进行排序，在短暂预热阶段后逐渐增加从梯度更新中排除的高损失样本比例，形成一个在线课程，专注于简单和一致的样本，最终忽略持续的异常值。

Result: 在CIFAR-100N上，Step-E将ResNet-18模型的测试准确率从43.3%提升到50.4%，明显优于损失截断、自步学习和一次性过滤方法，接近干净标签的60.5%。在CIFAR-10N上也从83.9%提升到85.3%，接近干净标签的85.9%，且训练时间开销适中。

Conclusion: Step-E框架通过将样本选择与模型学习集成到单一优化过程中，有效处理噪声标签数据，显著提升模型性能，接近干净标签数据的效果，同时保持适度的计算开销。

Abstract: Training data collected in the wild often contain noisy labels and outliers that substantially degrade the performance and reliability of deep neural networks. While data cleaning is commonly applied as a separate preprocessing stage, such two-stage pipelines neither fully exploit feedback from the downstream model nor adapt to unknown noise patterns. We propose Step-E, a simple framework that integrates sample selection and model learning into a single optimization process. At each epoch, Step-E ranks samples by loss and gradually increases the fraction of high-loss examples that are excluded from gradient updates after a brief warm-up stage, yielding an online curriculum that focuses on easy and consistent examples and eventually ignores persistent outliers. On CIFAR-100N, Step-E improves the test accuracy of a ResNet-18 model from 43.3% (+/- 0.7%) to 50.4% (+/- 0.9%), clearly outperforming loss truncation, self-paced learning, and one-shot filtering while approaching the clean-label oracle at 60.5% (+/- 0.2%). On CIFAR-10N (aggre), Step-E also improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the clean-label oracle (85.9%), with only moderate training-time overhead.

</details>


### [31] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 提出了几何解缠遗忘(GU)方法，通过将遗忘梯度更新分解为保留空间的切向和法向分量，只执行法向分量来减少对保留知识的影响，实现理论上有保证的机器遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的机器遗忘方法在有效遗忘和保留知识保护之间存在权衡，缺乏对遗忘更新如何影响保留知识的正式分析，以及是否能理论保证消除副作用。

Method: 从保留损失的一阶分析出发，提出几何解缠遗忘方法，将遗忘梯度更新分解为保留梯度子空间的切向和法向分量，只执行法向更新。在信任区域预算下，该方法提供了最优的一阶保留不变移动。

Result: 在TOFU、MUSE和WMDP三个基准测试中，GU方法在各种基于梯度的遗忘程序上实现了一致的改进。

Conclusion: 几何解缠遗忘方法提供了一种理论上有保证的简单解决方案，能够有效减少机器遗忘过程中的副作用，并在多个基准测试中表现出优越性能。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


### [32] [Hash Collisions in Molecular Fingerprints: Effects on Property Prediction and Bayesian Optimization](https://arxiv.org/abs/2511.17078)
*Walter Virany,Austin Tripp*

Main category: cs.LG

TL;DR: 研究比较了精确指纹与标准压缩指纹在分子性质预测和贝叶斯优化中的性能差异，发现精确指纹在预测准确性上有小幅但一致的提升，但在贝叶斯优化中无显著改进。


<details>
  <summary>Details</summary>
Motivation: 分子指纹方法使用哈希函数生成固定长度的分子向量表示，但哈希冲突会导致不同子结构具有相同特征，从而在分子相似性计算中产生高估。

Method: 使用精确指纹与标准压缩指纹进行对比，在DOCKSTRING数据集的五个分子性质预测基准上进行测试，使用高斯过程作为基础预测模型。

Result: 在分子性质预测中，精确指纹相比压缩指纹产生了小幅但一致的准确性提升；但在贝叶斯优化任务中，这些改进并未转化为显著的性能提升。

Conclusion: 虽然精确指纹在分子性质预测中能提高准确性，但由于在贝叶斯优化中无显著优势，其实际应用价值可能有限。

Abstract: Molecular fingerprinting methods use hash functions to create fixed-length vector representations of molecules. However, hash collisions cause distinct substructures to be represented with the same feature, leading to overestimates in molecular similarity calculations. We investigate whether using exact fingerprints improves accuracy compared to standard compressed fingerprints in molecular property prediction and Bayesian optimization where the underlying predictive model is a Gaussian process. We find that using exact fingerprints yields a small yet consistent improvement in predictive accuracy on five molecular property prediction benchmarks from the DOCKSTRING dataset. However, these gains did not translate to significant improvements in Bayesian optimization performance.

</details>


### [33] [DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph Embeddings](https://arxiv.org/abs/2511.17419)
*Yeamin Kaiser,Muhammed Tasnim Bin Anwar,Bholanath Das,Chowdhury Farhan Ahmed,Md. Tanvir Alam*

Main category: cs.LG

TL;DR: DS-Span是一个单阶段判别式子图挖掘框架，将模式增长、剪枝和监督驱动评分统一在一个搜索空间遍历中，生成紧凑且可解释的子图特征用于图嵌入和分类。


<details>
  <summary>Details</summary>
Motivation: 现有的频繁或判别式子图挖掘方法存在冗余的多阶段流程、高计算成本和挖掘结构与判别相关性之间弱耦合的问题，需要更高效的统一框架。

Method: 提出DS-Span框架，引入覆盖上限资格机制动态限制探索，以及信息增益引导的选择机制，在单次搜索空间遍历中统一进行模式增长、剪枝和监督评分。

Result: 在基准测试中，DS-Span比现有多阶段方法生成更紧凑和判别性的子图特征，在显著减少运行时间的同时达到相当或更高的准确率。

Conclusion: 统一的单阶段判别性挖掘为可扩展和可解释的图表示学习提供了有前景的基础。

Abstract: Graph representation learning seeks to transform complex, high-dimensional graph structures into compact vector spaces that preserve both topology and semantics. Among the various strategies, subgraph-based methods provide an interpretable bridge between symbolic pattern discovery and continuous embedding learning. Yet, existing frequent or discriminative subgraph mining approaches often suffer from redundant multi-phase pipelines, high computational cost, and weak coupling between mined structures and their discriminative relevance. We propose DS-Span, a single-phase discriminative subgraph mining framework that unifies pattern growth, pruning, and supervision-driven scoring within one traversal of the search space. DS-Span introduces a coverage-capped eligibility mechanism that dynamically limits exploration once a graph is sufficiently represented, and an information-gain-guided selection that promotes subgraphs with strong class-separating ability while minimizing redundancy. The resulting subgraph set serves as an efficient, interpretable basis for downstream graph embedding and classification. Extensive experiments across benchmarks demonstrate that DS-Span generates more compact and discriminative subgraph features than prior multi-stage methods, achieving higher or comparable accuracy with significantly reduced runtime. These results highlight the potential of unified, single-phase discriminative mining as a foundation for scalable and interpretable graph representation learning.

</details>


### [34] [InTAct: Interval-based Task Activation Consolidation for Continual Learning](https://arxiv.org/abs/2511.17439)
*Patryk Krukowski,Jan Miksa,Piotr Helm,Jacek Tabor,Paweł Wawrzyński,Przemysław Spurek*

Main category: cs.LG

TL;DR: InTAct是一种持续学习方法，通过约束共享层中重要神经元的激活范围来防止表示漂移，在保持参数灵活性的同时稳定功能行为，显著提升领域增量学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于提示的持续学习方法在领域偏移场景下的表示漂移问题，即使任务特定参数被隔离，共享表示层的演化仍会导致先前有用特征被覆盖和遗忘。

Method: 捕获先前学习任务的特征激活范围，约束更新以确保网络在这些区域内保持一致性，同时允许在其他区域灵活适应，稳定重要神经元的功能角色而非直接限制参数值。

Result: 在DomainNet和ImageNet-R等多样化领域增量基准测试中，InTAct持续减少表示漂移并提升性能，平均准确率比最先进基线提高多达8个百分点。

Conclusion: InTAct通过在编码过去知识的地方调节表示变化，实现了稳定性和可塑性之间的原则性平衡，可无缝集成到现有基于提示的持续学习框架中。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge without forgetting previously learned information. While recent prompt-based methods perform strongly in class-incremental settings, they remain vulnerable under domain shifts, where the input distribution changes but the label space remains fixed. This exposes a persistent problem known as representation drift. Shared representations evolve in ways that overwrite previously useful features and cause forgetting even when prompts isolate task-specific parameters. To address this issue, we introduce InTAct, a method that preserves functional behavior in shared layers without freezing parameters or storing past data. InTAct captures the characteristic activation ranges associated with previously learned tasks and constrains updates to ensure the network remains consistent within these regions, while still allowing for flexible adaptation elsewhere. In doing so, InTAct stabilizes the functional role of important neurons rather than directly restricting parameter values. The approach is architecture-agnostic and integrates seamlessly into existing prompt-based continual learning frameworks. By regulating representation changes where past knowledge is encoded, InTAct achieves a principled balance between stability and plasticity. Across diverse domain-incremental benchmarks, including DomainNet and ImageNet-R, InTAct consistently reduces representation drift and improves performance, increasing Average Accuracy by up to 8 percentage points over state-of-the-art baselines.

</details>


### [35] [PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM](https://arxiv.org/abs/2511.17467)
*Siqi Liang,Yudi Zhang,Yue Guo*

Main category: cs.LG

TL;DR: 提出基于知识图谱增强检索增强生成（Graph RAG）的个性化语言模型框架，通过构建LLM衍生的图索引和社区信息摘要，实现用户画像驱动的个性化AI代理。


<details>
  <summary>Details</summary>
Motivation: 需要能够适应用户偏好的个性化AI代理，让代理体现用户的"画像"（如用户资料或品味）。

Method: 结合知识图谱增强的RAG机制，构建LLM衍生的图索引和相关文档，总结相关信息社区，通过动态提示工程生成个性化提示。

Result: 在LaMP基准测试中，新闻分类F1提升11.1%，电影标签F1提升56.1%，产品评分MAE降低10.4%。

Conclusion: 该框架能够在保持与用户画像一致行为的同时，从集体知识中受益，显著提升个性化任务的性能。

Abstract: We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's "persona" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F

</details>


### [36] [Four decades of circumpolar super-resolved satellite land surface temperature data](https://arxiv.org/abs/2511.17134)
*Sonia Dupuis,Nando Metzger,Konrad Schindler,Frank Göttsche,Stefan Wunderle*

Main category: cs.LG

TL;DR: 开发了一个42年的泛北极地表温度数据集，通过深度学习超分辨率算法将AVHRR GAC数据从4公里降尺度到1公里分辨率，提高了对北极地区精细尺度过程的分析能力。


<details>
  <summary>Details</summary>
Motivation: AVHRR卫星数据的空间分辨率较粗，限制了其在分析北极地区精细尺度永久冻土动态和其他地表过程方面的应用，需要更高分辨率的地表温度数据来支持气候变化监测。

Method: 使用基于深度各向异性扩散模型的超分辨率算法，以MODIS LST数据为训练目标，结合高分辨率土地覆盖、数字高程和植被高度图作为指导，将AVHRR GAC数据从4公里降尺度到1公里。

Result: 生成了覆盖整个泛北极地区42年、每天两次观测的1公里分辨率地表温度数据集，显著提高了数据空间分辨率。

Conclusion: 该数据集能够改进永久冻土建模、重建近地表气温、评估格陵兰冰盖表面质量平衡，并为MODIS前时代的气候监测提供支持，同时为未来卫星任务提供了可适应的框架。

Abstract: Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.

</details>


### [37] [Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions](https://arxiv.org/abs/2511.17200)
*Shubhranil Basak,Mada Hemanth,Madhav Rao*

Main category: cs.LG

TL;DR: 使用深度学习从6轴IMU数据合成归一化sEMG信号，验证了该方法在肌肉意图检测应用中的可行性。


<details>
  <summary>Details</summary>
Motivation: sEMG信号对肌肉功能分析很重要但容易受噪声干扰且采集困难，而IMU提供了可穿戴的替代方案，因此研究从IMU数据合成sEMG信号的方法。

Method: 收集同步的sEMG和IMU数据，使用基于扩张因果卷积的滑动窗口波网络模型，将IMU数据映射到sEMG信号。

Result: 模型成功预测了肌肉激活的时序和大致形状，峰值幅度通常被低估，但具有高时间保真度。

Conclusion: 该方法在假肢控制和康复生物反馈等肌肉意图检测应用中具有可行性。

Abstract: Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.

</details>


### [38] [DelTriC: A Novel Clustering Method with Accurate Outlier](https://arxiv.org/abs/2511.17219)
*Tomas Javurek,Michal Gregor,Sebastian Kula,Marian Simko*

Main category: cs.LG

TL;DR: DelTriC是一种新的聚类算法，通过PCA/UMAP降维、Delaunay三角剖分和反向投影机制，在原始高维空间中形成聚类。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法在高维空间中面临挑战，需要一种既能处理高维数据又能保持准确性和可扩展性的方法。

Method: 首先在低维代理空间中进行三角剖分以索引局部邻接关系，然后反向投影到原始空间进行鲁棒的边修剪、合并和异常检测。

Result: DelTriC在许多场景下优于k-means、DBSCAN和HDBSCAN等传统方法，具有可扩展性和准确性，并显著改进了异常检测。

Conclusion: DelTriC通过解耦邻域构建和决策制定，提供了一种有效的高维数据聚类解决方案。

Abstract: The paper introduces DelTriC (Delaunay Triangulation Clustering), a clustering algorithm which integrates PCA/UMAP-based projection, Delaunay triangulation, and a novel back-projection mechanism to form clusters in the original high-dimensional space. DelTriC decouples neighborhood construction from decision-making by first triangulating in a low-dimensional proxy to index local adjacency, and then back-projecting to the original space to perform robust edge pruning, merging, and anomaly detection. DelTriC can outperform traditional methods such as k-means, DBSCAN, and HDBSCAN in many scenarios; it is both scalable and accurate, and it also significantly improves outlier detection.

</details>


### [39] [Generating transition states of chemical reactions via distance-geometry-based flow matching](https://arxiv.org/abs/2511.17229)
*Yufei Luo,Xiang Gu,Jian Sun*

Main category: cs.LG

TL;DR: TS-DFM是一个基于流匹配的框架，能够从反应物和产物预测过渡态结构，在分子距离几何空间中操作，显著提升了结构预测精度并加速了反应路径优化。


<details>
  <summary>Details</summary>
Motivation: 过渡态对于理解反应机理至关重要，但实验和计算方法复杂且有限，需要开发更高效的过渡态预测方法。

Method: 提出TS-DFM框架，在分子距离几何空间中操作，设计TSDVNet网络学习速度场以生成准确的过渡态几何结构。

Result: 在Transition1X基准数据集上，TS-DFM比之前最优方法React-OT结构精度提升30%，预测的过渡态能加速CI-NEB优化收敛，并能发现替代反应路径和更低能垒的过渡态。

Conclusion: TS-DFM在未见过的分子和反应类型上表现出强大的泛化能力，有望促进反应探索研究。

Abstract: Transition states (TSs) are crucial for understanding reaction mechanisms, yet their exploration is limited by the complexity of experimental and computational approaches. Here we propose TS-DFM, a flow matching framework that predicts TSs from reactants and products. By operating in molecular distance geometry space, TS-DFM explicitly captures the dynamic changes of interatomic distances in chemical reactions. A network structure named TSDVNet is designed to learn the velocity field for generating TS geometries accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the previous state-of-the-art method React-OT by 30\% in structural accuracy. These predicted TSs provide high-quality initial structures, accelerating the convergence of CI-NEB optimization. Additionally, TS-DFM can identify alternative reaction paths. In our experiments, even a more favorable TS with lower energy barrier is discovered. Further tests on RGD1 dataset confirm its strong generalization ability on unseen molecules and reaction types, highlighting its potential for facilitating reaction exploration.

</details>


### [40] [FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble](https://arxiv.org/abs/2511.17249)
*Riccardo Tedoldi,Ola Engkvist,Patrick Bryant,Hossein Azizpour,Jon Paul Janet,Alessandro Tibo*

Main category: cs.LG

TL;DR: FlexiFlow是一种新颖的架构，扩展了流匹配模型，能够联合采样分子及其多个构象，在分子生成任务中实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的3D从头设计模型仅限于生成单一构象，但分子的构象景观决定了其可观测性质和与蛋白质靶标的结合能力。通过生成一组低能量构象代表，可以更直接评估这些性质并改进生成具有所需热力学可观测值分子的能力。

Method: FlexiFlow扩展了流匹配模型，允许联合采样分子及其多个构象，同时保持等变性和置换不变性。

Result: 在QM9和GEOM Drugs数据集上，FlexiFlow能够生成有效、无应变、独特且新颖的分子，具有对训练数据分布的高保真度，同时捕捉分子的构象多样性。模型生成的构象集合在推理时间的一小部分内提供了与最先进物理方法相似的覆盖范围。

Conclusion: FlexiFlow可以成功转移到蛋白质条件配体生成任务，即使数据集仅包含静态口袋而没有伴随构象。

Abstract: Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.

</details>


### [41] [Enforcing governing equation constraints in neural PDE solvers via training-free projections](https://arxiv.org/abs/2511.17258)
*Omer Rochman,Gilles Louppe*

Main category: cs.LG

TL;DR: 本文提出了两种无需训练的投影方法来修正神经PDE求解器违反约束的问题：非线性优化投影和局部线性化投影，能显著减少约束违反并提高精度。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器在科学模拟中经常违反控制方程约束，特别是非线性约束和时间相关的长程依赖问题难以处理。

Method: 使用两种后处理投影方法：基于非线性优化的投影和基于局部线性化的投影（利用Jacobian-vector和vector-Jacobian乘积）。

Result: 两种投影方法都能显著减少约束违反，并在多个代表性PDE上比物理信息基线方法提高了精度。

Conclusion: 提出的投影方法能有效修正神经PDE求解器的约束违反问题，为处理非线性约束和时间相关约束提供了有效解决方案。

Abstract: Neural PDE solvers used for scientific simulation often violate governing equation constraints. While linear constraints can be projected cheaply, many constraints are nonlinear, complicating projection onto the feasible set. Dynamical PDEs are especially difficult because constraints induce long-range dependencies in time. In this work, we evaluate two training-free, post hoc projections of approximate solutions: a nonlinear optimization-based projection, and a local linearization-based projection using Jacobian-vector and vector-Jacobian products. We analyze constraints across representative PDEs and find that both projections substantially reduce violations and improve accuracy over physics-informed baselines.

</details>


### [42] [Automobile demand forecasting: Spatiotemporal and hierarchical modeling, life cycle dynamics, and user-generated online information](https://arxiv.org/abs/2511.17275)
*Tom Nahrendorf,Stefan Minner,Helfried Binder,Richard Zinck*

Main category: cs.LG

TL;DR: 该研究针对德国高端汽车制造商的多产品、多市场、多层次需求预测问题，提出结合LightGBM集成模型、分位数回归和混合整数线性规划调和的综合方法，重点解决了时空依赖性和整数预测偏差问题。


<details>
  <summary>Details</summary>
Motivation: 高端汽车制造商面临产品种类繁多、变体级别数据稀疏和市场动态波动等复杂预测挑战，需要开发能够同时满足战略和运营规划需求的预测方法。

Method: 结合点预测和概率预测，使用LightGBM集成模型与池化训练集、分位数回归，以及混合整数线性规划调和方法，在多层次层次结构中进行需求预测。

Result: 研究发现时空依赖性和四舍五入偏差显著影响预测准确性，强调了整数预测对运营可行性的重要性。Shapley分析显示短期需求受生命周期成熟度、自回归动量和运营信号影响，而中期需求则反映在线参与度、规划目标和竞争指标等前瞻性驱动因素。

Conclusion: 在线行为数据显著提高了细分层面的预测准确性，该方法为高端汽车制造商的多层次需求预测提供了有效的解决方案。

Abstract: Premium automotive manufacturers face increasingly complex forecasting challenges due to high product variety, sparse variant-level data, and volatile market dynamics. This study addresses monthly automobile demand forecasting across a multi-product, multi-market, and multi-level hierarchy using data from a German premium manufacturer. The methodology combines point and probabilistic forecasts across strategic and operational planning levels, leveraging ensembles of LightGBM models with pooled training sets, quantile regression, and a mixed-integer linear programming reconciliation approach. Results highlight that spatiotemporal dependencies, as well as rounding bias, significantly affect forecast accuracy, underscoring the importance of integer forecasts for operational feasibility. Shapley analysis shows that short-term demand is reactive, shaped by life cycle maturity, autoregressive momentum, and operational signals, whereas medium-term demand reflects anticipatory drivers such as online engagement, planning targets, and competitive indicators, with online behavioral data considerably improving accuracy at disaggregated levels.

</details>


### [43] [SAVeD: Semantic Aware Version Discovery](https://arxiv.org/abs/2511.17298)
*Artem Frenk,Roee Shraga*

Main category: cs.LG

TL;DR: SAVeD是一个基于对比学习的框架，用于识别结构化数据集的版本，无需依赖元数据、标签或集成假设。


<details>
  <summary>Details</summary>
Motivation: 解决数据科学中由于难以识别相似工作或数据集转换而导致的重复劳动问题。

Method: 采用改进的SimCLR流程，通过随机转换生成增强表视图，使用自定义transformer编码器嵌入，并在潜在空间中进行对比以优化语义相似性。

Result: 在五个标准数据集上的实验显示，SAVeD在完全未见过的表上实现了显著更高的准确率和分离分数，能够有效区分语义改变的版本。

Conclusion: SAVeD在无监督数据集版本检测方面表现出色，优于未训练的基线和现有最先进的数据集发现方法。

Abstract: Our work introduces SAVeD (Semantically Aware Version Detection), a contrastive learning-based framework for identifying versions of structured datasets without relying on metadata, labels, or integration-based assumptions. SAVeD addresses a common challenge in data science of repeated labor due to a difficulty of similar work or transformations on datasets. SAVeD employs a modified SimCLR pipeline, generating augmented table views through random transformations (e.g., row deletion, encoding perturbations). These views are embedded via a custom transformer encoder and contrasted in latent space to optimize semantic similarity. Our model learns to minimize distances between augmented views of the same dataset and maximize those between unrelated tables. We evaluate performance using validation accuracy and separation, defined respectively as the proportion of correctly classified version/non-version pairs on a hold-out set, and the difference between average similarities of versioned and non-versioned tables (defined by a benchmark, and not provided to the model). Our experiments span five canonical datasets from the Semantic Versioning in Databases Benchmark, and demonstrate substantial gains post-training. SAVeD achieves significantly higher accuracy on completely unseen tables in, and a significant boost in separation scores, confirming its capability to distinguish semantically altered versions. Compared to untrained baselines and prior state-of-the-art dataset-discovery methods like Starmie, our custom encoder achieves competitive or superior results.

</details>


### [44] [Self-supervised denoising of raw tomography detector data for improved image reconstruction](https://arxiv.org/abs/2511.17312)
*Israt Jahan Tulin,Sebastian Starke,Dominic Windisch,André Bieberle,Peter Steinbach*

Main category: cs.LG

TL;DR: 比较了两种自监督深度学习方法和一种非学习方法对超快电子束X射线CT噪声数据的去噪效果，发现深度学习方法在信噪比和重建图像质量方面表现更好


<details>
  <summary>Details</summary>
Motivation: 超快电子束X射线CT由于测量时间短导致数据噪声大，产生重建伪影，限制了图像质量

Method: 研究并比较了两种自监督深度学习方法和一种非学习方法的去噪性能

Result: 深度学习方法能够提高探测器数据的信噪比，并在重建图像质量上实现一致改进，优于非学习方法

Conclusion: 自监督深度学习方法在超快电子束X射线CT数据去噪方面具有优势，能够有效提升图像质量

Abstract: Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.

</details>


### [45] [ReBaPL: Repulsive Bayesian Prompt Learning](https://arxiv.org/abs/2511.17339)
*Yassir Bendou,Omar Ezzahir,Eduardo Fernandes Montesuma,Gabriel Mahuas,Victoria Shevchenko,Mike Gartrell*

Main category: cs.LG

TL;DR: 提出ReBaPL方法，通过贝叶斯推理框架优化提示学习，结合循环步长调度和SGHMC算法，在表示空间引入排斥力来增强探索性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统提示学习方法容易过拟合且泛化能力不足，贝叶斯提示学习通过概率推理提高鲁棒性，但需要更有效地探索复杂的多模态后验分布。

Method: 结合循环步长调度和SGHMC算法进行探索与利用的交替，在表示空间基于概率度量（MMD和Wasserstein距离）引入排斥力防止模式坍塌。

Result: 在多个基准数据集上表现出优于现有最先进提示学习方法的性能。

Conclusion: ReBaPL提供了模块化的贝叶斯扩展方案，能更全面地刻画提示后验分布，显著提升泛化能力。

Abstract: Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.

</details>


### [46] [R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability](https://arxiv.org/abs/2511.17367)
*Runyu Lu,Ruochuan Shi,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.LG

TL;DR: 本文提出了首个在部分可观测性下的最坏情况鲁棒实时追捕策略（R2PS）方法，通过信念保持机制和交叉图强化学习，实现了对未见图结构的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法如EPG和Grasper仅限于完全信息场景，且未考虑逃避者能预测追捕者行动的情况。现实中的追逃游戏往往存在部分可观测性，需要开发能在这种条件下实时应用的鲁棒追捕策略。

Method: 1. 证明传统动态规划算法在异步移动下保持最优性；2. 提出逃避者可能位置的信念保持机制，将DP追捕策略扩展到部分可观测设置；3. 将信念保持嵌入EPG框架，通过交叉图强化学习对抗异步移动DP逃避策略来学习实时追捕策略。

Result: 强化学习后，策略实现了对未见真实世界图结构的鲁棒零样本泛化，并且始终优于现有游戏RL方法直接在测试图上训练的策略。

Conclusion: R2PS是首个在部分可观测性下实现最坏情况鲁棒实时追捕策略的方法，通过信念保持和交叉图学习，显著提升了策略的泛化能力和鲁棒性。

Abstract: Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.

</details>


### [47] [A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias](https://arxiv.org/abs/2511.17378)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 本文开发了一个线性稳定性框架来分析SGD、随机扰动和SAM在两层ReLU网络中的行为，通过一致性度量揭示梯度曲率在数据点间的对齐方式，解释为何某些最小值在训练中更稳定且被偏好。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习优化的动态性对模型扩展很重要。虽然SGD及其变体能可靠找到泛化良好的解，但驱动这种泛化的机制仍不清楚。这些算法通常偏好更平坦或更简单的极小值，特别是在过参数化设置中。

Method: 开发线性稳定性框架，分析SGD、随机扰动和SAM在两层ReLU网络中的行为，引入一致性度量来量化梯度曲率在数据点间的对齐程度。

Result: 一致性度量揭示了梯度曲率在数据点间的对齐方式，解释了为何某些最小值在训练中更稳定且被偏好。

Conclusion: 该框架为理解数据结构、优化动态和学习解性质之间的联系提供了统一的理论基础。

Abstract: Understanding the dynamics of optimization in deep learning is increasingly important as models scale. While stochastic gradient descent (SGD) and its variants reliably find solutions that generalize well, the mechanisms driving this generalization remain unclear. Notably, these algorithms often prefer flatter or simpler minima, particularly in overparameterized settings. Prior work has linked flatness to generalization, and methods like Sharpness-Aware Minimization (SAM) explicitly encourage flatness, but a unified theory connecting data structure, optimization dynamics, and the nature of learned solutions is still lacking. In this work, we develop a linear stability framework that analyzes the behavior of SGD, random perturbations, and SAM, particularly in two layer ReLU networks. Central to our analysis is a coherence measure that quantifies how gradient curvature aligns across data points, revealing why certain minima are stable and favored during training.

</details>


### [48] [Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes](https://arxiv.org/abs/2511.17399)
*Wei-Kai Chang,Rajiv Khanna*

Main category: cs.LG

TL;DR: 提出一种基于后验采样的核心集选择框架，通过连接后验采样与损失函数，解决梯度方法在核心集选择中的局限性，实现更快的训练和更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模扩大，计算需求增加，需要有效的核心集选择技术来加速训练。梯度方法虽然理论基础强，但面临SGD基线强和代表性随时间退化的问题。

Method: 建立后验采样与损失函数之间的联系，引入基于模型权重后验采样的平滑损失函数，增强稳定性和泛化能力，同时保持计算效率。

Result: 通过大量实验证明，该方法在多个数据集上比现有技术实现更快的训练速度和更好的泛化性能。

Conclusion: 提出的基于后验采样的核心集选择框架有效解决了梯度方法的局限性，在数据预算有限的情况下提供了稳健且高效的核心集选择方案。

Abstract: As deep learning models continue to scale, the growing computational demands have amplified the need for effective coreset selection techniques. Coreset selection aims to accelerate training by identifying small, representative subsets of data that approximate the performance of the full dataset. Among various approaches, gradient based methods stand out due to their strong theoretical underpinnings and practical benefits, particularly under limited data budgets. However, these methods face challenges such as naive stochastic gradient descent (SGD) acting as a surprisingly strong baseline and the breakdown of representativeness due to loss curvature mismatches over time.
  In this work, we propose a novel framework that addresses these limitations. First, we establish a connection between posterior sampling and loss landscapes, enabling robust coreset selection even in high data corruption scenarios. Second, we introduce a smoothed loss function based on posterior sampling onto the model weights, enhancing stability and generalization while maintaining computational efficiency. We also present a novel convergence analysis for our sampling-based coreset selection method. Finally, through extensive experiments, we demonstrate how our approach achieves faster training and enhanced generalization across diverse datasets than the current state of the art.

</details>


### [49] [Self-Supervised Learning by Curvature Alignment](https://arxiv.org/abs/2511.17426)
*Benyamin Ghojogh,M. Hadi Sepanj,Paul Fieguth*

Main category: cs.LG

TL;DR: CurvSSL是一个曲率正则化的自监督学习框架，通过在标准冗余减少损失基础上添加曲率正则化项，显式地塑造表示的局部几何结构。


<details>
  <summary>Details</summary>
Motivation: 现有的非对比自监督学习方法主要关注表示的一阶和二阶统计特性，但忽略了底层数据流形的局部几何结构。

Method: 保留标准双视图编码器-投影器架构，在投影特征上使用Barlow Twins风格的冗余减少损失，但增加基于曲率的正则化器。通过最近邻的余弦交互计算离散曲率得分，并在增强视图间对齐和去相关。

Result: 在MNIST和CIFAR-10数据集上使用ResNet-18骨干网络的实验表明，曲率正则化自监督学习相比Barlow Twins和VICReg具有竞争性或改进的线性评估性能。

Conclusion: 显式塑造局部几何结构是对纯统计自监督学习正则化器的简单有效补充。

Abstract: Self-supervised learning (SSL) has recently advanced through non-contrastive methods that couple an invariance term with variance, covariance, or redundancy-reduction penalties. While such objectives shape first- and second-order statistics of the representation, they largely ignore the local geometry of the underlying data manifold. In this paper, we introduce CurvSSL, a curvature-regularized self-supervised learning framework, and its RKHS extension, kernel CurvSSL. Our approach retains a standard two-view encoder-projector architecture with a Barlow Twins-style redundancy-reduction loss on projected features, but augments it with a curvature-based regularizer. Each embedding is treated as a vertex whose $k$ nearest neighbors define a discrete curvature score via cosine interactions on the unit hypersphere; in the kernel variant, curvature is computed from a normalized local Gram matrix in an RKHS. These scores are aligned and decorrelated across augmentations by a Barlow-style loss on a curvature-derived matrix, encouraging both view invariance and consistency of local manifold bending. Experiments on MNIST and CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL yields competitive or improved linear evaluation performance compared to Barlow Twins and VICReg. Our results indicate that explicitly shaping local geometry is a simple and effective complement to purely statistical SSL regularizers.

</details>


### [50] [Towards fully differentiable neural ocean model with Veros](https://arxiv.org/abs/2511.17427)
*Etienne Meunier,Said Ouala,Hugo Frezat,Julien Le Sommer,Ronan Fablet*

Main category: cs.LG

TL;DR: 将VEROS海洋模型扩展为可微分版本，使其能够通过JAX自动微分框架进行梯度计算，并展示了在海洋状态修正和物理参数校准中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统海洋模型缺乏可微分性，限制了基于梯度的优化方法在海洋建模中的应用，如状态修正和参数校准。

Method: 对VEROS海洋模型进行修改，使其与JAX自动微分框架完全兼容，保持数值一致性。

Result: 成功实现了可微分海洋模型，能够通过梯度优化方法修正初始海洋状态和校准未知物理参数。

Conclusion: 可微分编程能够促进海洋建模中的端到端学习和参数调优，为海洋科学研究提供了新的工具。

Abstract: We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.

</details>


### [51] [Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems](https://arxiv.org/abs/2511.17435)
*Zengyu Zou,Jingyuan Wang,Yixuan Huang,Junjie Wu*

Main category: cs.LG

TL;DR: 提出了基于序列到序列的多智能体指针变换器(MAPT)框架，用于解决具有随机请求的多车辆动态取送货问题，在8个数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 经典运筹学方法在处理大规模动态问题时面临计算复杂度和时间效率瓶颈，现有强化学习方法存在联合动作分布建模困难、实体间关系捕获不足、联合动作空间指数级增长等问题。

Method: 使用Transformer编码器提取实体表示，结合Transformer解码器和指针网络以自回归方式生成联合动作序列，引入关系感知注意力模块捕获实体间关系，并使用信息先验指导模型决策。

Result: 在8个数据集上的实验表明，MAPT在性能上显著优于现有基线方法，相比经典运筹学方法具有显著的计算时间优势。

Conclusion: MAPT框架有效解决了多车辆动态取送货问题中的关键挑战，为大规模动态路由优化问题提供了高效的端到端解决方案。

Abstract: This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.

</details>


### [52] [Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry](https://arxiv.org/abs/2511.17446)
*Kyle M. Regan,Michael McLoughlin,Wayne A. Bryden,Gonzalo R. Arce*

Main category: cs.LG

TL;DR: MS-DGFormer是一个基于Transformer的数据驱动框架，能够直接从原始、最小化处理的质谱数据中识别病原体，特别适用于单次光谱检测的气溶胶MALDI-MS系统。


<details>
  <summary>Details</summary>
Motivation: 传统MALDI-MS技术依赖繁琐的样品制备和多光谱平均，限制了其在实时环境监测中的应用，特别是在新兴的气溶胶MALDI-MS系统中，自主采样会产生噪声光谱，需要单次检测能力。

Method: 采用Transformer架构捕捉时间序列光谱的长程依赖关系，并引入基于奇异值分解(SVD)的字典编码器来整合去噪光谱信息，增强特征提取能力。

Result: 该方法能够从单次光谱中稳健地识别关键生物分子模式，实现气溶胶样本中病原体的优越识别性能。

Conclusion: 通过消除广泛预处理需求，该方法释放了便携式、可部署MALDI-MS平台的潜力，革新了环境病原体检测和生物威胁快速响应能力。

Abstract: Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [53] [Stable diffusion models reveal a persisting human and AI gap in visual creativity](https://arxiv.org/abs/2511.16814)
*Silvia Rondini,Claudia Alvarez-Martin,Paula Angermair-Barkai,Olivier Penacchio,M. Paz,Matthew Pelowski,Dan Dediu,Antoni Rodriguez-Fornells,Xim Cerda-Company*

Main category: cs.AI

TL;DR: 研究发现人类视觉艺术家在图像生成创意方面表现最佳，其次是普通人，而AI生成图像（特别是低人类指导条件下）创意最低。人类指导能显著提升AI的创意表现。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在发散思维任务中能与人类匹敌，但视觉创意领域尚未充分探索。本研究旨在比较人类和AI在图像生成中的创意表现。

Method: 比较人类参与者（视觉艺术家和普通人）与AI图像生成模型（两种提示条件：高人类输入的人类启发条件和低人类输入的自导条件）的图像生成。由255名人类评估者和GPT4o评估创意性。

Result: 发现明显的创意梯度：视觉艺术家最具创意，其次是普通人，然后是受人类启发的生成AI，最后是自导生成AI。增加人类指导能显著提升AI的创意输出，使其接近普通人的水平。人类和AI评估者在创意判断模式上存在显著差异。

Conclusion: 与语言中心任务不同，生成AI模型在视觉领域面临独特挑战，因为视觉创意依赖于感知细微差别和情境敏感性，这些是人类特有的能力，可能不容易从语言模型转移。

Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.

</details>


### [54] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC是一种基于BASIC风格的提示语言和模型内解释器，可将大型语言模型的推理过程结构化，形成明确的逐步执行轨迹。


<details>
  <summary>Details</summary>
Motivation: 受复古BASIC语言简洁性的启发，旨在为LLM推理创建可解释的认知控制层，使多步推理过程更加透明。

Method: 使用编号行和简单命令作为认知控制层，通过自然语言解释器文件定义命令语义、内存更新和日志行为，开发了心智模型解释器来提取知识和检测矛盾。

Result: 在三个LLM上的基准测试显示，所有模型都能执行Cognitive BASIC程序，整体表现强劲但存在差异。

Conclusion: Cognitive BASIC能够有效结构化LLM推理，实现透明的多步推理过程，在知识提取、冲突检测和推理任务中表现良好。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [55] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一个系统性的基准测试修订框架，利用响应模式的统计分析来标记潜在无效问题，结合LLM法官初审以减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 基准测试对AI进步至关重要，但无效的基准问题会破坏其可靠性。手动从数千个问题中识别和修正错误既不可行，也是可靠评估的关键瓶颈。

Method: 基于AI评估中常用的核心假设——平均分足以总结模型性能，通过统计分析响应模式来识别统计值超出预期范围的问题项，并引入LLM法官进行初步审查。

Result: 在九个广泛使用的基准测试中，该方法指导专家审查识别问题问题的精确度高达84%。

Conclusion: 该框架为系统性的基准测试修订提供了高效且可扩展的解决方案，显著减少了人工工作量。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [56] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 提出混合差分奖励机制解决多车协同驾驶中传统奖励函数梯度信号弱的问题，通过时间差分奖励和动作梯度奖励的组合显著提升算法收敛速度和策略稳定性。


<details>
  <summary>Details</summary>
Motivation: 多车协同驾驶任务中，传统基于状态的奖励函数存在奖励差异消失问题，导致策略梯度信噪比低，严重影响算法收敛和性能提升。

Method: 提出混合差分奖励机制，包含基于全局势函数的时间差分奖励和直接测量动作边际效用的动作梯度奖励，在多智能体部分可观测马尔可夫博弈框架下实现。

Result: 实验表明HDR机制显著提高了收敛速度和策略稳定性，引导智能体学习到平衡交通效率和安全的高质量协同策略。

Conclusion: HDR机制有效解决了多车协同驾驶中的奖励信号弱化问题，为高频率连续控制任务提供了有效的奖励设计方法。

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [57] [Comparing verbal, visual and combined explanations for Bayesian Network inferences](https://arxiv.org/abs/2511.16961)
*Erik P. Nyberg,Steven Mascaro,Ingrid Zukerman,Michael Wybrow,Duc-Minh Vo,Ann Nicholson*

Main category: cs.AI

TL;DR: 本文设计了贝叶斯网络界面的语言和视觉扩展，通过用户研究发现这些扩展能帮助用户更好地理解推理模式，且语言和视觉结合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管贝叶斯网络被认为是透明模型，但用户仍难以理解其推理过程，现有用户界面未能清晰展示其推理逻辑。

Method: 设计了语言和视觉扩展的用户界面，并与基线界面进行对比用户研究，评估三种扩展方式（语言、视觉、组合）的效果。

Result: 所有三种扩展界面在观察影响、影响路径和观察间相互作用等问题上都优于基线界面；语言和视觉组合在某些问题类型上优于单独使用任一模式。

Conclusion: 贝叶斯网络界面可以通过语言和视觉扩展来改善用户理解，多模态组合能提供更好的推理支持。

Abstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.
  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.

</details>


### [58] [MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists](https://arxiv.org/abs/2511.16997)
*Qingbin Zeng,Bingbing Fan,Zhiyu Chen,Sijian Ren,Zhilun Zhou,Xuhua Zhang,Yuanyi Zhen,Fengli Xu,Yong Li,Tie-Yan Liu*

Main category: cs.AI

TL;DR: MirrorMind是一个分层认知架构，通过整合个体认知轨迹和集体学科记忆，实现更接近人类科学发现的社会历史特性的AI科学家系统。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学家方法将科学发现视为孤立的优化过程，忽视了知识生产的社会性和历史性本质。人类科学洞察来自个体认知轨迹和集体学科记忆两个相互关联的来源。

Method: 提出三层框架：个体层面构建研究者的认知模型（情景、语义、人格记忆）；领域层面映射集体知识为结构化学科概念图；跨学科层面作为正交编排引擎。采用记忆存储与智能执行分离的架构。

Result: 在四个综合任务中评估：作者级认知模拟、互补推理、跨学科协作促进、多智能体科学问题解决。结果显示MirrorMind超越了简单事实检索，实现了结构化、个性化和洞察生成的科学推理。

Conclusion: 通过整合个体认知深度与集体学科广度，MirrorMind推动了AI科学家从简单事实检索向结构性、个性化、洞察生成型科学推理的转变。

Abstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.

</details>


### [59] [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://arxiv.org/abs/2511.17006)
*Tengxiao Liu,Zifeng Wang,Jin Miao,I-Hung Hsu,Jun Yan,Jiefeng Chen,Rujun Han,Fangyuan Xu,Yanfei Chen,Ke Jiang,Samira Daruki,Yi Liang,William Yang Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 本文研究了工具增强型智能体在明确工具调用预算下的有效扩展方法，提出了预算跟踪器和BATS框架，通过预算感知实现更好的成本-性能权衡。


<details>
  <summary>Details</summary>
Motivation: 研究发现简单增加工具调用预算无法提升智能体性能，因为智能体缺乏"预算意识"，需要研究如何在预算约束下有效扩展工具增强型智能体。

Method: 提出了预算跟踪器插件提供持续预算意识，并开发了BATS框架，利用预算意识动态调整规划和验证策略，决定是深入探索还是转向新路径。

Result: 预算感知方法产生了更有利的扩展曲线，推动了成本-性能的帕累托前沿，提供了对工具增强型智能体扩展的更透明和原则性理解。

Conclusion: 通过预算感知机制，工具增强型智能体可以在预算约束下实现更有效的扩展，为智能体的成本-性能优化提供了系统性的解决方案。

Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only "thinking" in tokens but also "acting" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack "budget awareness" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to "dig deeper" on a promising lead or "pivot" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.

</details>


### [60] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 论文重新解释了扩散模型在逆问题求解中的作用，提出DAPS++方法，将扩散阶段与数据驱动优化解耦，实现更高效的计算和鲁棒的重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯视角下基于分数的扩散方法在解决逆问题时，先验提供的指导有限，重建主要受测量一致性项驱动，与扩散动力学基本解耦。需要澄清这种结构并改进推理过程。

Method: 将扩散重新解释为EM框架中的初始化阶段，提出DAPS++方法，使似然项能更直接地指导推理，同时保持数值稳定性，减少函数评估次数和测量优化步骤。

Result: DAPS++在多种图像恢复任务中实现了高计算效率和鲁棒的重建性能，需要更少的函数评估和优化步骤。

Conclusion: 扩散在逆问题求解中的作用应被视为初始化阶段，DAPS++通过解耦扩散和数据驱动优化，提供了更有效的推理框架，解释了为什么统一扩散轨迹在实践中仍然有效。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [61] [Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks](https://arxiv.org/abs/2511.17056)
*Paloma Rabaey,Adrick Tench,Stefan Heytens,Thomas Demeester*

Main category: cs.AI

TL;DR: 提出了一种多模态患者信息提取方法，结合结构化EHR数据和临床文本，通过贝叶斯网络和一致性节点实现可解释的概率融合。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中既有结构化信息也有非结构化文本，需要整合这两种数据源来构建透明的临床决策支持系统。

Method: 使用专家指导的贝叶斯网络处理结构化EHR特征，神经网络分类器处理临床文本，通过虚拟证据和一致性节点进行概率融合。

Result: 在SimSUM模拟基准数据集上验证，一致性节点相比单独使用虚拟证据能改善预测校准，更好地处理缺失信息和解决数据矛盾。

Conclusion: 该方法能够有效整合多模态EHR数据，提供可解释且校准良好的预测，适合高风险临床应用。

Abstract: Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.

</details>


### [62] [The Belief-Desire-Intention Ontology for modelling mental reality and agency](https://arxiv.org/abs/2511.17162)
*Sara Zuppiroli,Carmelo Fabio Longo,Anna Sofia Lippolis,Rocco Paolillo,Lorenzo Giammei,Miguel Ceriani,Francesco Poggi,Antonio Zinilli,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: 本文提出了一个形式化的BDI本体论，作为模块化本体设计模式，用于表示智能体的信念、欲望和意图及其动态关系。通过结合大语言模型和语义推理平台进行实验验证。


<details>
  <summary>Details</summary>
Motivation: BDI模型是人工智能和认知科学中表示理性智能体的基石，但其与结构化、语义可互操作的知识表示的整合仍然有限。

Method: 设计了一个模块化的BDI本体论模式，与基础本体对齐确保语义精确性和可重用性。通过两种实验验证：1) 与LLMs结合使用逻辑增强生成；2) 集成到Semas推理平台实现RDF三元组与智能体心理状态的双向转换。

Result: 实验表明BDI本体论在声明性和程序性智能之间起到了概念和操作桥梁的作用，支持认知基础、可解释和语义可互操作的多智能体和神经符号系统。

Conclusion: 该BDI本体论为在数据网络中运行的认知基础、可解释和语义可互操作的多智能体和神经符号系统铺平了道路。

Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.

</details>


### [63] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 本文提出了一种名为MIR的互惠内在奖励方法，用于解决多智能体强化学习中稀疏奖励（特别是情节奖励）的挑战，通过激励智能体探索影响队友的行为来改善团队探索效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中情节奖励面临两个主要挑战：(1) 随着探索空间扩大，导致奖励的联合动作轨迹呈指数级稀疏；(2) 现有方法往往忽略能够影响团队状态的联合动作。

Method: 提出了MIR（互惠内在奖励）方法，激励个体智能体探索能够影响队友的动作，并与原始策略结合来刺激团队探索。同时创建了MiniGrid-MA环境用于多智能体强化学习验证。

Result: 在MiniGrid-MA环境中与最先进方法进行比较，实验结果表明MIR方法表现出优越的性能。

Conclusion: MIR是一种简单而有效的增强策略，能够有效解决多智能体强化学习中稀疏奖励问题，显著提升算法性能。

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [64] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: 提出了基于层次任务抽象机制(HTAM)的多智能体框架EarthAgent，专门用于解决遥感等专业领域中结构化工作流程的挑战，显著优于现有单智能体和多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 通用智能体框架(如ReAct或角色扮演)在需要严格结构化工作流程的专业领域(如遥感)中表现不佳，这些领域需要专业工具和多步骤程序。

Method: 引入层次任务抽象机制(HTAM)，将多智能体系统构建为反映领域内在任务依赖图的逻辑层次结构，通过任务中心架构确保程序正确性，将复杂问题分解为顺序层。

Result: 在GeoPlan-bench基准测试中，EarthAgent在工具选择、路径相似性和逻辑完整性等指标上显著优于现有系统。

Conclusion: 将智能体架构与领域内在任务结构对齐是构建稳健可靠的专业自主系统的关键步骤。

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [65] [Agentifying Agentic AI](https://arxiv.org/abs/2511.17332)
*Virginia Dignum,Frank Dignum*

Main category: cs.AI

TL;DR: 本文主张将AAMAS社区开发的BDI架构、通信协议、机制设计和制度建模等概念工具作为实现智能AI系统的基础，通过将自适应数据驱动方法与结构化推理协调模型相结合，构建能力强大、灵活、透明、协作且可问责的智能系统。


<details>
  <summary>Details</summary>
Motivation: 智能AI系统需要具备持续自主性、推理和交互能力，这需要明确的认知、协作和治理模型来补充其关于智能体的假设。

Method: 利用AAMAS社区开发的概念工具，包括BDI架构、通信协议、机制设计和制度建模，将自适应数据驱动方法与结构化推理协调模型相结合。

Result: 提出了一个连接形式理论和实践自主性的智能体视角，为构建透明、协作和可问责的智能系统奠定了基础。

Conclusion: 通过整合AAMAS社区的概念工具与数据驱动方法，可以构建不仅能力强且灵活，而且透明、协作和可问责的智能系统，实现形式理论与实践自主性的桥梁。

Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.

</details>


### [66] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 评估使用合成和偏离策略数据对LLM行为探针泛化能力的影响，发现响应生成策略显著影响探针性能，且同域偏离策略数据比异域策略数据更可靠


<details>
  <summary>Details</summary>
Motivation: 由于许多LLM行为的自然示例稀少，研究者不得不依赖合成或偏离策略的LLM响应来训练探针，需要系统评估这些数据对探针泛化的影响

Method: 在八种不同LLM行为上测试线性和注意力探针，比较不同响应生成策略下探针的性能，评估从偏离策略数据到策略数据的泛化能力

Result: 响应生成策略显著影响探针性能，成功从偏离策略数据泛化到测试集可预测策略数据的泛化成功，训练数据域偏移导致更大性能下降

Conclusion: 在缺乏策略数据时，使用同域偏离策略数据比异域策略数据产生更可靠的探针，强调需要更好处理LLM监控中分布偏移的方法

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [67] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 提出SRA-CP框架，通过风险感知的选择性协作感知，在保持安全关键物体检测精度的同时，大幅降低通信带宽需求


<details>
  <summary>Details</summary>
Motivation: 现有通用协作感知方法传输大量与驾驶安全无关的感知数据，超出可用通信带宽，且依赖预定义的通信伙伴，不适合动态交通环境

Method: 去中心化协议，车辆持续广播轻量级感知覆盖摘要，仅在检测到风险相关盲区时启动针对性协作。包含感知风险识别模块和选择性信息交换融合模块

Result: 相比通用CP方法，安全关键物体平均精度损失小于1%，仅使用20%通信带宽；相比现有选择性CP方法，感知性能提升15%

Conclusion: SRA-CP框架有效解决了协作感知中的通信带宽和动态环境适应性问题，实现了高效的风险感知选择性协作

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [68] [Optimal management of the vaccination process in SIRD epidemic models under constraints](https://arxiv.org/abs/2511.16763)
*Bogdan Norkin,Vladimir Norkin*

Main category: math.OC

TL;DR: 该论文研究了SIR模型中在医疗资源约束下的最优疫苗接种控制问题，使用参数化策略方法解决传统最优控制方法面临的困难。


<details>
  <summary>Details</summary>
Motivation: 传统最优控制方法（动态规划和庞特里亚金最大值原理）在SIR疫苗接种控制模型中面临困难：贝尔曼函数可能不光滑，庞特里亚金方法需要解决具有不连续控制的边值问题。

Method: 采用参数化策略方法，将原始最优控制问题转化为关于未知参数的有限维优化问题。

Result: 提出了一种避免传统方法困难的新方法，将无限维控制问题简化为有限维优化问题。

Conclusion: 参数化策略方法为SIR模型中的疫苗接种控制问题提供了一种有效的替代解决方案，克服了传统最优控制方法的局限性。

Abstract: The paper considers the problems of optimal vaccination control in the classical SIR model under constraints on the resource capabilities of the insurance medical system, in particular under constraints on the possible absolute rate of vaccination of the population and the limitation on the available number of vaccines. The application of classical optimal control methods, the dynamic programming method and the Pontryagin maximum principle for such a model encounters difficulties associated with the possible non-smoothness of the Bellman function, and in the Pontryagin method the problem is to solve a boundary value problem with discontinuous control. Therefore, in the paper, optimal control is sought in the class of the so-called parametric strategies, which reduces the original problem to a finite-dimensional optimization problem with respect to unknown parameters.

</details>


### [69] [Efficient Penalty-Based Bilevel Methods: Improved Analysis, Novel Updates, and Flatness Condition](https://arxiv.org/abs/2511.16796)
*Liuyuan Jiang,Quan Xiao,Lisha Chen,Tianyi Chen*

Main category: math.OC

TL;DR: 本文提出了一种新的惩罚方法来解耦双层优化问题中的上下层变量，改善了光滑性分析，使得能够使用更大的步长和降低迭代复杂度。提出了两种算法：ALT-PBGD和PBGD-Free，后者是完全单循环算法。还引入了一种新的曲率条件来放松上层Lipschitz要求。


<details>
  <summary>Details</summary>
Motivation: 传统的基于惩罚的双层优化方法需要内层循环来求解下层问题，并且由于大惩罚项导致的光滑性增加，需要使用小的外层步长，导致次优复杂度。本文旨在解决这些问题。

Method: 1. 提出新的惩罚重构方法解耦上下层变量；2. 开发ALT-PBGD算法（交替惩罚梯度下降）；3. 提出PBGD-Free完全单循环算法；4. 引入新的曲率条件描述上层目标对下层变量的"平坦度"。

Result: 方法改善了光滑性常数分析，允许使用更大步长，降低了迭代复杂度。PBGD-Free避免了内层循环，对于有耦合约束的问题，内层循环复杂度显著降低。

Conclusion: 所提出的方法在支持向量机超参数优化和大语言模型微调等任务中验证了有效性，提供了严格的收敛分析，为双层优化问题提供了更高效的解决方案。

Abstract: Penalty-based methods have become popular for solving bilevel optimization (BLO) problems, thanks to their effective first-order nature. However, they often require inner-loop iterations to solve the lower-level (LL) problem and small outer-loop step sizes to handle the increased smoothness induced by large penalty terms, leading to suboptimal complexity. This work considers the general BLO problems with coupled constraints (CCs) and leverages a novel penalty reformulation that decouples the upper- and lower-level variables. This yields an improved analysis of the smoothness constant, enabling larger step sizes and reduced iteration complexity for Penalty-Based Gradient Descent algorithms in ALTernating fashion (ALT-PBGD). Building on the insight of reduced smoothness, we propose PBGD-Free, a novel fully single-loop algorithm that avoids inner loops for the uncoupled constraint BLO. For BLO with CCs, PBGD-Free employs an efficient inner-loop with substantially reduced iteration complexity. Furthermore, we propose a novel curvature condition describing the "flatness" of the upper-level objective with respect to the LL variable. This condition relaxes the traditional upper-level Lipschitz requirement, enables smaller penalty constant choices, and results in a negligible penalty gradient term during upper-level variable updates. We provide rigorous convergence analysis and validate the method's efficacy through hyperparameter optimization for support vector machines and fine-tuning of large language models.

</details>


### [70] [Phase Retrieval Based on DC and DnCNN](https://arxiv.org/abs/2511.16913)
*Xueming Li,Bing Guo*

Main category: math.OC

TL;DR: 增强prDeep架构，通过DC函数和DnCNN去噪正则化实现噪声鲁棒相位恢复，提出prDeep-DC和prDeep-L2两种新算法。


<details>
  <summary>Details</summary>
Motivation: 研究噪声鲁棒相位恢复问题，旨在提高在噪声环境下的相位恢复性能。

Method: 在prDeep架构基础上，引入DC（凸差函数）和基于DnCNN的去噪正则化技术，开发了prDeep-DC和prDeep-L2两种算法。

Result: 通过大量数值实验验证，两种新算法在定量和视觉性能方面都表现出色。

Conclusion: 提出的prDeep-DC和prDeep-L2算法能够有效实现噪声鲁棒相位恢复，具有优异的性能表现。

Abstract: This paper investigates noise-robust phase retrieval by enhancing the prDeep architecture with difference of convex functions (DC) and DnCNN-based denoising regularization. This research introduces two novel algorithms, prDeep-DC and prDeep-L2, which demonstrably achieve excellent quantitative and visual performance, as confirmed by extensive numerical experiments.

</details>


### [71] [On Solving Chance-Constrained Models with Gaussian Mixture Distribution](https://arxiv.org/abs/2511.16960)
*Shibshankar Dey,Sanjay Mehrotra,Anirudh Subramanyam*

Main category: math.OC

TL;DR: 提出了基于分段线性近似的混合整数二次规划方法，用于求解高斯混合分布系数的线性机会约束问题，在保证τ精度的同时实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统样本平均近似方法在处理高斯混合分布的机会约束问题时效果不佳，需要开发更有效的求解方法。

Method: 使用标准正态累积分布函数的分段线性近似构建混合整数二次规划，提供机会约束的内外近似。

Result: 在18小时内可求解包含1000个随机系数和15个高斯混合分量的近最优解，满足高达0.999的约束满足概率；100个系数的问题可在1分钟内求解。

Conclusion: 该方法显著优于样本平均近似，能够高效处理大规模高斯混合分布的机会约束优化问题。

Abstract: We study linear chance-constrained problems where the coefficients follow a Gaussian mixture distribution. We provide mixed-binary quadratic programs that give inner and outer approximations of the chance constraint based on piecewise linear approximations of the standard normal cumulative density function. We show that $O\left(\sqrt{\ln(1/τ)/τ} \right)$ pieces are sufficient to attain $τ$-accuracy in the chance constraint. We also show that any desired optimality gap can be achieved under a constraint qualification condition by controlling the approximation accuracy. Extensive computations using a commercial solver show that problems with up to one thousand random coefficients specified with up to fifteen Gaussian mixture components, generated under diverse settings, can be solved to near optimality within 18 hours, while satisfying chance constraint satisfaction probabilities of up to $0.999$. The solution times are significantly lower for problems with fewer random coefficients and mixture terms. For example, problems with one hundred random coefficients, ten mixture terms, and a constraint satisfaction probability of $0.999$ can be solved in a minute or less. Sample average approximations fail to provide meaningful solutions even for the smaller problems.

</details>


### [72] [Contextual Quantile Minimization for Two-Stage Stochastic Programs](https://arxiv.org/abs/2511.17020)
*Man Yiu Tsang,Tony Sit,Hoi Ying Wong*

Main category: math.OC

TL;DR: 本文提出了一种新的风险规避型上下文随机优化问题，采用分位数目标替代传统期望目标，并开发了具有收敛保证的随机不精确约束生成方法来解决计算难题。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要关注最小化随机损失的期望，但在许多应用中，风险规避的决策者可能更倾向于最小化特定分位数作为更谨慎的替代方案。

Method: 提出风险规避型上下文随机优化问题，通过用通用估计器替换变分表征中的条件期望来建模条件分位数，并开发了随机不精确约束生成方法。

Result: 在两组温和的正则条件下，推导了最优解和最优值到其真实对应项的渐近几乎必然收敛和概率收敛。数值实验验证了方法的计算性能和操作性能。

Conclusion: 结果表明，将有用的上下文信息和决策者的风险态度纳入优化模型具有重要意义。

Abstract: Contextual stochastic optimization is an advanced methodology to model uncertainty in the presence of contextual information during decision planning processes. Although classical methodologies focus on minimizing the expectation of a random loss, in many applications, risk-averse decision-makers may be interested in minimizing a specific quantile as a more prudent alternative. In this paper, we propose a new risk-averse contextual stochastic optimization problem with a quantile objective for general two-stage problems. Given historical data on the model's random parameters and contextual information, we model the conditional quantile by replacing the conditional expectation in its variational characterization with a generic estimator. Under two sets of mild regularity conditions, we derive the asymptotic almost-sure convergence and convergence in probability of the optimal solution and the optimal value of the associated optimization problem to their true counterparts. Optimization problems with a quantile objective is usually non-convex, which are generally regarded as challenging to solve. To address the computational difficulties, we propose a new stochastic inexact constraint generation method with convergence guarantee. Finally, through numerical experiments on a single-server appointment scheduling problem, we study the computational performance of our proposed solution method as well as operational performance of our proposed methodology. Our results demonstrate the importance of incorporating useful contextual information and decision-maker's risk attitude into the optimization model.

</details>


### [73] [Infinite Horizon Linear Quadratic Mean Field Problems with Common Noise and Regime Switching via Conditional McKean-Vlasov FBSDEs](https://arxiv.org/abs/2511.17023)
*Qingmeng Wei,Yaqi Xu*

Main category: math.OC

TL;DR: 该论文研究具有共同噪声和机制转换的无限时域线性二次平均场问题，涵盖控制和博弈两种形式。通过分析具有马尔可夫转换的条件McKean-Vlasov型完全耦合前向-后向随机微分方程，建立了理论框架，并推导了控制问题中开环最优控制和博弈问题中平均场纳什均衡的充要条件。


<details>
  <summary>Details</summary>
Motivation: 研究具有共同噪声和机制转换的无限时域线性二次平均场问题，为这类复杂随机系统建立理论框架，解决控制和博弈问题中的最优性和均衡性分析。

Method: 首先分析具有马尔可夫转换的条件McKean-Vlasov型完全耦合前向-后向随机微分方程，在广义支配-单调性条件下建立其适定性。基于此可解性结果，推导控制问题和博弈问题的充要条件。

Result: 建立了具有共同噪声和机制转换的线性二次平均场问题的理论框架，证明了相关随机微分方程的适定性，并获得了开环最优控制和平均场纳什均衡的充要条件。

Conclusion: 成功构建了具有共同噪声和机制转换的无限时域线性二次平均场问题的完整理论框架，为这类复杂随机系统的控制和博弈分析提供了数学基础。

Abstract: This paper studies infinite horizon linear quadratic (LQ) mean field problems with common noise and regime switching, covering both control and game formulations. To establish a theoretical foundation for the LQ framework, we first analyze fully coupled forward-backward stochastic differential equations (FBSDEs) of conditional McKean-Vlasov type with Markovian switching and establish its well-posedness under a generalized domination-monotonicity condition. Building upon this solvability result, we then derive necessary and sufficient conditions for both the open-loop optimal control in the control problem and the mean-field Nash equilibria in the game problem.

</details>


### [74] [Carathéodory number of homogeneous convex cones](https://arxiv.org/abs/2511.17051)
*Chek Beng Chua*

Main category: math.OC

TL;DR: 本文通过谱面体表示研究齐次凸锥的Carathéodory数，给出了秩与Carathéodory数相等的齐次凸锥的特征，并证明齐次凸锥自对偶当且仅当其闭包和对偶锥的秩与Carathéodory数匹配，且稀疏谱面体锥中只有齐次弦图描述的才是齐次凸锥。


<details>
  <summary>Details</summary>
Motivation: 研究齐次凸锥的Carathéodory数与其谱面体表示之间的关系，探索齐次凸锥的结构特性。

Method: 通过谱面体表示分析齐次凸锥，建立秩与Carathéodory数的等价条件，并应用于自对偶性和稀疏谱面体锥的齐次性研究。

Result: 给出了齐次凸锥秩等于Carathéodory数的充要条件，证明了自对偶性的等价刻画，确定了稀疏谱面体锥中齐次凸锥的图论特征。

Conclusion: 齐次凸锥的Carathéodory数与其谱面体表示密切相关，自对偶性可通过秩与Carathéodory数的关系来刻画，且齐次稀疏谱面体锥对应于齐次弦图。

Abstract: We study the Carathéodory number of homogeneous convex cones via their spectrahedral representations. A characterization of homogeneous convex cones whose ranks match their Carathéodory numbers is given. This characterization is then used to show that a homogeneous convex cone is selfdual if and only if its rank matches the Carathéodory numbers of both its closure and its dual cone. It is further used to show that the only sparse spectrahedral cones that are homogeneous convex cones are those described by homogeneous chordal graphs.

</details>


### [75] [Robustness of optimal control for controlled regime-switching diffusions with incorrect models](https://arxiv.org/abs/2511.17121)
*Somnath Pradhan,Dinesh Rathia*

Main category: math.OC

TL;DR: 该论文研究了受控体制切换扩散的随机最优控制的鲁棒性，考虑了扩散和切换组件的模型失配问题，并在统一框架下分析了四种经典成本函数，证明了值函数和最优控制的连续性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是将扩散过程的鲁棒性框架扩展到具有交互连续和离散动态的混合系统，解决体制切换扩散模型中的模型失配问题。

Method: 通过分析相关的弱耦合HJB系统的正则性及其随机表示，研究近似体制切换模型收敛到真实模型时值函数和最优策略的收敛性。

Result: 证明了当近似体制切换模型序列收敛到真实模型时，相关的值函数和最优策略也会收敛，确保性能损失趋近于零。

Conclusion: 该研究成功地将鲁棒性框架从扩散过程扩展到更广泛的具有交互连续和离散动态的混合系统类别。

Abstract: This paper investigates the robustness of stochastic optimal control for controlled regime switching diffusions. We consider systems driven by both continuous fluctuations and discrete regime changes, allowing for model misspecification in both the diffusion and switching components. Within a unified framework, we study four classical cost formulations finite horizon, infinite-horizon discounted and ergodic costs, and the exit time cost, and establish continuity of value functions and robustness of optimal controls. Specifically, we show that as a sequence of approximating regime switching models converges to the true model, the associated value functions and optimal policies converge as well, ensuring vanishing performance loss. The analysis relies on the regularity of the solution to the associated weakly coupled HJB systems, and their stochastic representation. The results extend the robustness framework developed for diffusion processes to a significantly broader class of hybrid systems with interacting continuous and discrete dynamics.

</details>


### [76] [An efficient branch-and-cut algorithm for the multiple probabilistic covering location problem](https://arxiv.org/abs/2511.17128)
*Yan-Ru Wang,Wei-Kun Chen,Ivana Ljubić*

Main category: math.OC

TL;DR: 提出了一个针对多概率覆盖位置问题(MPCLP)的高效分支割平面算法，该算法使用子模和外逼近不等式，变量数量比现有算法少一个数量级，并能解决57个之前未解决的基准实例。


<details>
  <summary>Details</summary>
Motivation: 多概率覆盖位置问题旨在在联合概率覆盖设置下，通过开设固定数量的设施来最大化覆盖的客户需求。现有算法存在变量数量过多的问题，需要更高效的求解方法。

Method: 提出了新的混合整数非线性规划(MINLP)模型，开发了基于线性规划的分支割平面算法，使用子模和外逼近不等式替换非线性约束，并提出了增强外逼近和提升次可加不等式来加强LP松弛。

Result: 在240个基准实例上的计算实验表明，该算法在运行时间、搜索树节点数和求解实例数量方面显著优于现有算法，并在1小时内解决了57个之前未解决的实例。

Conclusion: 所提出的分支割平面算法由于问题规模小和LP松弛强，能够高效求解多概率覆盖位置问题，显著提升了求解性能。

Abstract: In this paper, we consider the multiple probabilistic covering location problem (MPCLP), which attempts to open a fixed number of facilities to maximize the total covered customer demand under a joint probabilistic coverage setting. We present a new mixed integer nonlinear programming (MINLP) formulation, and develop an efficient linear programming (LP) based branch-and-cut (B&C) algorithm where submodular and outer-approximation inequalities are used to replace the nonlinear constraints and are separated at the nodes of the search tree. One key advantage of the proposed B&C algorithm is that the number of variables in the underlying formulation grows only linearly with the number of customers and facility locations and is one-order of magnitude smaller than that in the underlying formulation of a state-of-the-art B&C algorithm in the literature. Moreover, we propose two new families of strong valid inequalities, called enhanced outer-approximation and lifted subadditive inequalities, to strengthen the LP relaxation and speed up the convergence of the proposed B&C algorithm. In extensive computational experiments on a testbed of 240 benchmark MPCLP instances, we show that, thanks to the small problem size and the strong LP relaxation of the underlying formulation, the proposed B&C algorithm significantly outperforms a state-of-the-art B&C algorithm in terms of running time, number of nodes in the search tree, and number of solved instances. In particular, using the proposed B&C algorithm, we are able to provide optimal solutions for 57 previously unsolved benchmark instances within a time limit of one hour.

</details>


### [77] [The Güler-type acceleration for proximal gradient, linearized augmented Lagrangian and linearized alternating direction method of multipliers](https://arxiv.org/abs/2511.17157)
*Bin Zhou,Liusheng Hou,Xingju Cai,Hailin Sun*

Main category: math.OC

TL;DR: 本文提出了基于Güler型加速技术的三种算法：GPGM、GLALM和GLADMM，通过利用负项信息设计外推步骤，实现了对偶变量的同时加速，并在数值实验中表现出优于现有方法的效率。


<details>
  <summary>Details</summary>
Motivation: 现有加速算法未能充分利用负项信息，本文旨在探索如何将Güler加速技术应用于梯度类算法，构建统一简洁的加速框架。

Method: 提出三种Güler型加速算法：GPGM（加速近端梯度法）、GLALM（加速线性化增广拉格朗日法）和GLADMM（加速线性化交替方向乘子法），核心思想是利用负项‖x^k-x̂^{k-1}‖²设计外推步骤。

Result: GPGM和GLALM达到O(1/k²)收敛速率，GLADMM总收敛速率保持O(1/N)但部分收敛速率从O(1/N^{3/2})提升到O(1/N²)，数值实验在ℓ₁正则化逻辑回归、二次规划和压缩感知问题上均优于现有方法。

Conclusion: Güler加速技术可有效应用于梯度类算法，所提算法框架统一简洁，在统计、机器学习和数据挖掘等领域具有应用潜力。

Abstract: In this paper, we introduce the Güler-type acceleration technique and utilize it to propose three acceleration algorithms: the Güler-type accelerated proximal gradient method (GPGM), the Güler-type accelerated linearized augmented Lagrangian method (GLALM) and the Güler-type accelerated linearized alternating direction method of multipliers (GLADMM). The key idea behind these algorithms is to fully leverage the information of negative term \bm{$-\|x^k-\hat{x}^{k-1}\|^2$} in order to design the extrapolation step. This concept of using negative terms to improve acceleration can be extended to other algorithms as well. Moreover, the proposed GLALM and GLADMM enable simultaneous acceleration of both primal and dual variables. Additionally, GPGM and GLALM achieve the same convergence rate of $O(\frac{1}{k^2})$ with some existing results. Although GLADMM achieves the same total convergence rate of $O(\frac{1}{N})$ as in existing results, the partial convergence rate is improved from $O(\frac{1}{N^{3/2}})$ to $O(\frac{1}{N^2})$. To validate the effectiveness of our algorithms, we conduct numerical experiments on various problem instances, including the $\ell_1$ regularized logistic regression, quadratic programming, and compressive sensing. The experimental results indicate that our algorithms outperform existing methods in terms of efficiency. This also demonstrates the potential of the stochastic algorithmic versions of these algorithms in application areas such as statistics, machine learning, and data mining. Finally, it is worth noting that this paper aims to introduce how Güler's acceleration technique can be applied to gradient-based algorithms and to provide a unified and concise framework for their construction.

</details>


### [78] [Quadratic Mean-Field BSDEs and Exponential Utility Maximization](https://arxiv.org/abs/2511.17214)
*Yining Ding,Kihun Nam,Jiaqiang Wen3*

Main category: math.OC

TL;DR: 本文研究了具有二次增长生成器的实值平均场倒向随机微分方程(BSDEs)，在分离二次增长条件下证明了强BMO解的存在唯一性，并推广到完全耦合二次情形，应用于平均场指数效用最大化问题。


<details>
  <summary>Details</summary>
Motivation: 填补Cheridito和Nam(2017)与Hao等人(2025)在二次BSDE结果之间的空白，将经典效用最大化框架推广到完全耦合二次平均场情形。

Method: 结合Malliavin微积分与精细的BMO和稳定性估计，先在Lipschitz设置下获得Z的一致界，然后通过逼近方法处理二次情形。

Result: 在分离二次增长条件下证明了强BMO解的存在唯一性；在完全耦合二次情形下，在终端变量满足小性条件时建立了解的存在唯一性。

Conclusion: 成功填补了二次BSDE理论的空白，并将经典效用最大化问题推广到更一般的平均场框架中。

Abstract: We study real-valued mean-field backward stochastic differential equations (BSDEs) of the form \[ Y_t = ξ+ \int_t^T \widetilde{\mathbb E}\, g(s, Z_s, \tilde Z_s)\, ds - \int_t^T Z_s \, dW_s, \] where $\tilde Z$ denotes an independent copy of $Z$ and $\widetilde{\mathbb E}$ the expectation with respect to $\tilde Z$. Under a \emph{separately quadratic} growth assumption (H\textsubscript{q}) on the generator $g$ in $(Z,\tilde Z)$, together with a bounded terminal condition, we prove existence and uniqueness of solutions in $\mathbb S^\infty \times \mathbb H^2_{\mathrm{BMO}}$. Our approach departs from classical fixed-point arguments and instead combines Malliavin calculus with refined BMO and stability estimates: we first obtain uniform $\mathbb S^\infty$-bounds for $Z$ in a Lipschitz setting with bounded Malliavin derivative, and then pass to the quadratic case by approximation, using a stability result in $\mathbb S^2\times\mathbb H^2$. This closes the gap between the quadratic BSDE results of Cheridito and Nam (2017) and Hao et al. (2025).
  In the second part of the paper, we extend the framework to generators of the form $g(t,z,\tilde z,\bar z)$ satisfying a \emph{fully coupled quadratic} condition (H\textsubscript{q}$'$). In this general regime we establish existence and uniqueness under a smallness condition on the centered terminal variable. As an application, we solve a mean-field exponential utility maximization problem with a collective liability, thereby generalizing the classical utility maximization framework of Hu et al. (2005) to a fully coupled quadratic mean-field setting.

</details>


### [79] [Lyapunov and Riccati Equations from a Positive System Perspective](https://arxiv.org/abs/2511.17243)
*Dongjun Wu,Yankai Lin*

Main category: math.OC

TL;DR: 本文从正系统理论的角度重新解释Lyapunov和Riccati方程，通过构造相关的正系统来证明解的存在唯一性。


<details>
  <summary>Details</summary>
Motivation: 传统方法分析Lyapunov和Riccati方程较为复杂，希望通过正系统理论提供新的分析视角和证明方法。

Method: 构造与Lyapunov方程相关的严格正线性系统，以及与代数Riccati方程相关的齐次严格正系统。

Result: 对于Lyapunov方程，在可观测性假设下，系统在Hilbert度量下指数收敛到Perron-Frobenius向量；对于Riccati方程，只能获得渐近收敛。

Conclusion: 正系统理论为Lyapunov和Riccati方程的分析提供了新的框架，能够证明解的存在唯一性，但收敛性质有所不同。

Abstract: This paper presents a new interpretation of the Lyapunov and Riccati equations from the perspective of positive system theory. We show it is possible to construct positive systems related to these equations, and then certain conclusions -- such as the existence and uniqueness of solutions -- can be drawn from positive systems theory. Specifically, under standard observability assumptions, a strictly positive linear system can be constructed for Lyapunov equations, leading to exponential convergence in Hilbert metric to the Perron-Frobenius vector -- closely related to the solution of the Lyapunov equation. For algebraic Riccati equations, homogeneous strictly positive systems can be constructed, which exhibit more complex dynamical behaviors. While the existence and uniqueness of the solution can still be proven, only asymptotic convergence can be obtained.

</details>


### [80] [Chance constrained optimization of energy intensive production as beneficial power units](https://arxiv.org/abs/2511.17252)
*Johannes Nicklaus,Lea Brass,Gunnar Schubert*

Main category: math.OC

TL;DR: 研究工业能源系统中考虑风险的线性策略近似方法，该系统包含不确定的风电、变化的电力需求和高温热输出，采用机会约束优化来限制关键约束违反概率。


<details>
  <summary>Details</summary>
Motivation: 工业能源系统面临风电不确定性、需求波动和高温热输出等挑战，需要开发风险意识的操作策略来平衡运行效率和可靠性。

Method: 采用线性策略近似和机会约束优化，通过参数修改的成本函数来近似风险结构，减少计算负担，在滚动预测框架下进行顺序决策。

Result: 数值案例研究验证了该方法在随机环境中运行效率与可靠性之间的权衡关系。

Conclusion: 提出的线性策略近似方法能够有效处理工业能源系统中的不确定性，在计算效率和风险控制之间取得良好平衡。

Abstract: We study linear policy approximations for the risk-conscious operation of an industrial energy system with uncertain wind power, significant and variable electricity demand, and high thermal output, as found in a modern foundry. The system incorporates thermal storage and operates under rolling forecasts, leading to a sequential decision-making framework. To address uncertainty in key parameters, we formulate chance-constrained optimization problems that limit the probability of critical constraint violations, such as unmet demand requirements or the exceedance of system boundaries. To reduce computational effort, we replace direct uncertainty handling with a parameter-modified cost function that approximates the underlying risk structure. We validate our method through a numerical case study, demonstrating the trade-offs between operational efficiency and reliability in a stochastic environment.

</details>


### [81] [On the Convergence of Constrained Gradient Method](https://arxiv.org/abs/2511.17430)
*Danqing Zhou,Hongmei Chen,Shiqian Ma,Junfeng Yang*

Main category: math.OC

TL;DR: 本文改进了约束梯度方法(CGM)在强凸优化和强单调变分不等式问题中的收敛性分析，在更弱且合理的假设下提供了严格的收敛保证。


<details>
  <summary>Details</summary>
Motivation: 现有文献对CGM的收敛性分析采用了较为严格且有时相互矛盾的假设，导致分析存在缺陷，需要更弱且合理的假设来建立严格的收敛保证。

Method: 采用约束梯度方法(CGM)来解决强凸优化和强单调变分不等式问题，并在更弱的假设条件下进行理论分析。

Result: 在更弱且合理的假设下，为CGM建立了严格的收敛保证，并通过初步数值实验验证了方法的有效性。

Conclusion: CGM在更弱的假设条件下仍能有效解决强凸优化和强单调变分不等式问题，填补了现有分析中的理论空白。

Abstract: The constrained gradient method (CGM) has recently been proposed to solve convex optimization and monotone variational inequality (VI) problems with general functional constraints. While existing literature has established convergence results for CGM, the assumptions employed therein are quite restrictive; in some cases, certain assumptions are mutually inconsistent, leading to gaps in the underlying analysis. This paper aims to derive rigorous and improved convergence guarantees for CGM under weaker and more reasonable assumptions, specifically in the context of strongly convex optimization and strongly monotone VI problems. Preliminary numerical experiments are provided to verify the validity of CGM and demonstrate its efficacy in addressing such problems.

</details>
